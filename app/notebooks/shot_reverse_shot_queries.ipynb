{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Labelled-Data\" data-toc-modified-id=\"Labelled-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Labelled Data</a></span></li><li><span><a href=\"#Building-Up-the-Query\" data-toc-modified-id=\"Building-Up-the-Query-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building Up the Query</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shots-with-faces\" data-toc-modified-id=\"Shots-with-faces-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Shots with faces</a></span></li><li><span><a href=\"#Shots-with-face-on-alternate-side-of-the-screen\" data-toc-modified-id=\"Shots-with-face-on-alternate-side-of-the-screen-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Shots with face on alternate side of the screen</a></span></li><li><span><a href=\"#Face-Probability-Threshold\" data-toc-modified-id=\"Face-Probability-Threshold-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Face Probability Threshold</a></span></li><li><span><a href=\"#3-Shot-Sequence\" data-toc-modified-id=\"3-Shot-Sequence-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>3-Shot Sequence</a></span></li><li><span><a href=\"#Identity-Labels\" data-toc-modified-id=\"Identity-Labels-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Identity Labels</a></span></li><li><span><a href=\"#Identity-Labels-with-Spatial-Constaint\" data-toc-modified-id=\"Identity-Labels-with-Spatial-Constaint-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Identity Labels with Spatial Constaint</a></span></li><li><span><a href=\"#Without-Identity-Labels\" data-toc-modified-id=\"Without-Identity-Labels-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Without Identity Labels</a></span></li></ul></li><li><span><a href=\"#Self-contained-Functions-for-Queries-in-this-Document\" data-toc-modified-id=\"Self-contained-Functions-for-Queries-in-this-Document-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Self-contained Functions for Queries in this Document</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shots-with-faces\" data-toc-modified-id=\"Shots-with-faces-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Shots with faces</a></span></li><li><span><a href=\"#Shot-sequences-with-faces-in-alternating-regions\" data-toc-modified-id=\"Shot-sequences-with-faces-in-alternating-regions-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Shot sequences with faces in alternating regions</a></span></li><li><span><a href=\"#Shot/Reverse-shot-with-faces-above-certain-probability\" data-toc-modified-id=\"Shot/Reverse-shot-with-faces-above-certain-probability-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Shot/Reverse shot with faces above certain probability</a></span></li><li><span><a href=\"#Shot/Reverse-shot-sequence-with-at-least-3-shots\" data-toc-modified-id=\"Shot/Reverse-shot-sequence-with-at-least-3-shots-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Shot/Reverse shot sequence with at least 3 shots</a></span></li><li><span><a href=\"#Shot/Reverse-shot-sequence-with-consistent-identities\" data-toc-modified-id=\"Shot/Reverse-shot-sequence-with-consistent-identities-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Shot/Reverse shot sequence with consistent identities</a></span></li><li><span><a href=\"#Shot/Reverse-shot-sequence-with-consistent-identities-in-alternating-regions\" data-toc-modified-id=\"Shot/Reverse-shot-sequence-with-consistent-identities-in-alternating-regions-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Shot/Reverse shot sequence with consistent identities in alternating regions</a></span></li><li><span><a href=\"#Shot/Reverse-shot-sequence-with-consistent-face-bounding-boxes\" data-toc-modified-id=\"Shot/Reverse-shot-sequence-with-consistent-face-bounding-boxes-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Shot/Reverse shot sequence with consistent face bounding boxes</a></span></li></ul></li><li><span><a href=\"#Scratchpad\" data-toc-modified-id=\"Scratchpad-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Scratchpad</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook describes how we gradually build up a increasing complex rekall query for shot/reverse shot sequences. \n",
    "\n",
    "Section 4 provides self-contained functions for various queries in this notebook. Section 1-3 needs to be run in order to work.\n",
    "\n",
    "The hidden cell below sets up the imports and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:09:02.623622Z",
     "start_time": "2018-12-17T01:09:02.520153Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from query.models import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import Interval, IntervalList\n",
    "from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "from rekall.payload_predicates import payload_satisfies\n",
    "from rekall.list_predicates import length_at_most\n",
    "from rekall.logical_predicates import and_pred, or_pred\n",
    "from rekall.spatial_predicates import scene_graph, make_region, _region_contains_bbox\n",
    "from rekall.temporal_predicates import before, after, overlaps, equal\n",
    "from rekall.merge_ops import payload_second, payload_plus, payload_first\n",
    "from rekall.bbox_predicates import height_at_least\n",
    "from esper.rekall import intrvllists_to_result, add_intrvllists_to_result, intrvllists_to_result_with_objects, bbox_to_result_object,intrvllists_to_result_bbox\n",
    "\n",
    "CINEMATIC_SHOTS_LABELLER = 64\n",
    "MAX_FRAME = 72000\n",
    "VIDEO_ID = 216\n",
    "\n",
    "# Wrap the payload in a list.\n",
    "def wrap_list(intvl):\n",
    "    intvl.payload = [intvl.payload]\n",
    "    return intvl\n",
    "\n",
    "# Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "# faces of a frame in the shot.\n",
    "def get_shots_with_face(shots, face_frames):\n",
    "    return shots.merge(\n",
    "    face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "    ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "# Returns precision, recall, precision_per_item, recall_per_item\n",
    "def compute_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    total_query_time = 0\n",
    "    total_query_segments = 0\n",
    "    total_ground_truth_time = 0\n",
    "    total_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        total_query_time += query_intrvllists[video].coalesce().get_total_time()\n",
    "        total_query_segments += query_intrvllists[video].size()\n",
    "    for video in ground_truth_intrvllists:\n",
    "        total_ground_truth_time += ground_truth_intrvllists[video].coalesce().get_total_time()\n",
    "        total_ground_truth_segments += ground_truth_intrvllists[video].size()\n",
    "        \n",
    "    total_overlap_time = 0\n",
    "    overlapping_query_segments = 0\n",
    "    overlapping_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        if video in ground_truth_intrvllists:\n",
    "            query_list = query_intrvllists[video]\n",
    "            gt_list = ground_truth_intrvllists[video]\n",
    "            \n",
    "            total_overlap_time += query_list.overlaps(gt_list).coalesce().get_total_time()\n",
    "            overlapping_query_segments += query_list.filter_against(gt_list, predicate=overlaps()).size()\n",
    "            overlapping_ground_truth_segments += gt_list.filter_against(query_list, predicate=overlaps()).size()\n",
    "    \n",
    "    if total_query_time == 0:\n",
    "        precision = 1.0\n",
    "        precision_per_item = 1.0\n",
    "    else:\n",
    "        precision = total_overlap_time / total_query_time\n",
    "        precision_per_item = overlapping_query_segments / total_query_segments\n",
    "    \n",
    "    if total_ground_truth_time == 0:\n",
    "        recall = 1.0\n",
    "        recall_per_item = 1.0\n",
    "    else:\n",
    "        recall = total_overlap_time / total_ground_truth_time\n",
    "        recall_per_item = overlapping_ground_truth_segments / total_ground_truth_segments\n",
    "    \n",
    "    return precision, recall, precision_per_item, recall_per_item\n",
    "\n",
    "def print_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    precision, recall, precision_per_item, recall_per_item = compute_statistics(\n",
    "        query_intrvllists, ground_truth_intrvllists)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision Per Item: \", precision_per_item)\n",
    "    print(\"Recall Per Item: \", recall_per_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Labelled Data\n",
    "\n",
    "I have manually labelled all shot/reverse shot sequences in the first 50min (~72000 frames) of Godfather Part III and will be using this as groundtruth for validation. The hidden cell below reads in my labels and visualizes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:09:05.723489Z",
     "start_time": "2018-12-17T01:09:05.647352Z"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d7b6e871b542edad15524d1ca43698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    (8757,9049),\n",
    "    (12750,13463),\n",
    "    (13683,14227),\n",
    "    (21357,22236),\n",
    "    (22294,22758),\n",
    "    (23147,25854),\n",
    "    (26007,26942),\n",
    "    (27620,28172),\n",
    "    (28382,28623),\n",
    "    (28785,29036),\n",
    "    (29904,31014),\n",
    "    (33936,35339),\n",
    "    (35421,36248),\n",
    "    (39388,40062),\n",
    "    (41675,42689),\n",
    "    (51246,52118),\n",
    "    (53117,54776), # One side is a long shot and face is too small to be detected.\n",
    "    (54895,55762),\n",
    "    (56819,59963),\n",
    "    (60253,61875),\n",
    "    (66533,67846),\n",
    "    (68729,69040),\n",
    "    (69421,70153),\n",
    "    (70285,71102)]\n",
    "intrvllist = IntervalList([Interval(start, end, payload=None) for (start,end) in data])\n",
    "shot_reverse_shot_labelled = {VIDEO_ID: intrvllist}\n",
    "\n",
    "def display_labelled_interval(indices):\n",
    "    return esper_widget(intrvllists_to_result_with_objects({VIDEO_ID: IntervalList([Interval(data[i][0], data[i][1], None) for i in indices])}, payload_to_objs=lambda p,v:[]))\n",
    "    \n",
    "esper_widget(intrvllists_to_result(shot_reverse_shot_labelled), crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Up the Query\n",
    "\n",
    "We take the approach of starting with a simple query with high rekall, and gradually refine it to weed out the false positives by adding more complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots with faces\n",
    "\n",
    "We start by trying to find all shots where at least one sampled frame has a face. The payload for each shot is a list, each element is a list of faces in a sampled frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:24:58.394792Z",
     "start_time": "2018-12-17T00:24:56.006971Z"
    }
   },
   "outputs": [],
   "source": [
    "shots = VideoIntervalCollection.from_django_qs(\n",
    "    Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER, max_frame__lte=MAX_FRAME),\n",
    "    with_payload=lambda obj:[]\n",
    ")\n",
    "# For each frame, payload is a list of faces\n",
    "face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, frame__number__lte=MAX_FRAME),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "shots_with_faces = get_shots_with_face(shots, face_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the result by rendering both the groundtruth shots (red) and our shots with faces (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:07.579846Z",
     "start_time": "2018-12-17T00:25:07.157613Z"
    }
   },
   "outputs": [],
   "source": [
    "result = intrvllists_to_result(shots_with_faces.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at our current recall and precision. We can see that it has high recall and low precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:12.804659Z",
     "start_time": "2018-12-17T00:25:12.756103Z"
    }
   },
   "outputs": [],
   "source": [
    "print_statistics(shots_with_faces.get_allintervals(), shot_reverse_shot_labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall is not 100% because some shots in groundtruth are long/extreme long shots and no faces were detected. Run the cell below to see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:19.226497Z",
     "start_time": "2018-12-17T00:25:19.172312Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "display_labelled_interval([16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots with face on alternate side of the screen\n",
    "\n",
    "In shot reverse shot sequences, adjacent shots usually have faces on different side of the screen. Many of the shots_with_faces are crowd shots with many faces that are small (run the cell below for an example). We want to focus on shots with small number of bigger faces that appear in alternating regions of the screen. We can hence build two sets of shots: one with faces on the left, and one with faces on the right. We use a few parameters to define the left and right regions, minimum face height and maximum number of faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:31.811480Z",
     "start_time": "2018-12-17T00:25:31.755647Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(shots_with_faces.filter(lambda intvl: intvl.start==11388).get_allintervals(), payload_to_objs=lambda p,v:[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:35.712725Z",
     "start_time": "2018-12-17T00:25:35.686339Z"
    }
   },
   "outputs": [],
   "source": [
    "RIGHT_HALF_MIN_X=0.45\n",
    "LEFT_HALF_MAX_X=0.55\n",
    "MAX_FACES_ON_SCREEN=2\n",
    "MIN_FACE_HEIGHT=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:38.054501Z",
     "start_time": "2018-12-17T00:25:37.496593Z"
    }
   },
   "outputs": [],
   "source": [
    "right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find sequence of two shots where the face positions alternate between left and right regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:42.514096Z",
     "start_time": "2018-12-17T00:25:42.478529Z"
    }
   },
   "outputs": [],
   "source": [
    "shot_reverse_shot = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2)\n",
    "    ).coalesce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualizes the result and see the evaluation numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:25:44.947215Z",
     "start_time": "2018-12-17T00:25:44.868788Z"
    }
   },
   "outputs": [],
   "source": [
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall is bad because some shot reverse shot has faces smaller than 40% of the screen, sometimes there are more than 2 faces and face can appear in the mid-section of the screen (Run cell below for false negative examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:01.682231Z",
     "start_time": "2018-12-17T00:26:01.627213Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "display_labelled_interval([6,14,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can relax the parameters to improve recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:13.095490Z",
     "start_time": "2018-12-17T00:26:13.067019Z"
    }
   },
   "outputs": [],
   "source": [
    "RIGHT_HALF_MIN_X=0.33\n",
    "LEFT_HALF_MAX_X=0.66\n",
    "MAX_FACES_ON_SCREEN=4\n",
    "MIN_FACE_HEIGHT=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:16.160251Z",
     "start_time": "2018-12-17T00:26:13.586170Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "shot_reverse_shot = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2)\n",
    "    ).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Probability Threshold\n",
    "\n",
    "Sometimes a non-face gets marked as a face (run cell below for an example), so we introduce a threshold for the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:23.679535Z",
     "start_time": "2018-12-17T00:26:23.610640Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import esper.stdlib\n",
    "esper_widget(esper.stdlib.qs_to_result(Face.objects.filter(frame__video__id=VIDEO_ID, frame__number=68664)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:27.473893Z",
     "start_time": "2018-12-17T00:26:27.446100Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_FACE_PROBABILITY=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:37.361917Z",
     "start_time": "2018-12-17T00:26:34.654839Z"
    }
   },
   "outputs": [],
   "source": [
    "face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(\n",
    "            video_id=VIDEO_ID, frame__number__lte=MAX_FRAME, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "shot_reverse_shot = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2)\n",
    "    ).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Shot Sequence\n",
    "\n",
    "So far the intervals we get only need to contain two shots, so any cut separating two shots with faces will be included (run cell below for a false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:46.760424Z",
     "start_time": "2018-12-17T00:26:46.697016Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(shot_reverse_shot.filter(lambda intvl: intvl.start==11388).get_allintervals(), payload_to_objs=lambda p,v:[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead look for sequences that are at least 3 shots long, either with left-right-left or right-left-right pattern, and take the union of the two sets of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:50.625439Z",
     "start_time": "2018-12-17T00:26:50.435373Z"
    }
   },
   "outputs": [],
   "source": [
    "shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Labels\n",
    "\n",
    "Some of the inaccuracies come from stitching together extra shots on different characters who happen to be at the right position on screen (run cell below for an example). Now that we have most faces labelled for Godfather III, we can add in identity constraints on our 3-shot sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:53.870861Z",
     "start_time": "2018-12-17T00:26:53.818478Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(shot_reverse_shot.filter(lambda intvl: intvl.start==12135).get_allintervals(), payload_to_objs=lambda p,v:[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:26:59.525491Z",
     "start_time": "2018-12-17T00:26:55.814465Z"
    }
   },
   "outputs": [],
   "source": [
    "face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(\n",
    "            video_id=VIDEO_ID, frame__number__lte=MAX_FRAME, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            merge_dict_parsers([\n",
    "                bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "                dict_payload_parser(VideoIntervalCollection.django_accessor, {\"face_id\": \"id\"})\n",
    "            ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "\n",
    "def share_face(int1, int2):\n",
    "    def get_identities_for_face_ids(ids):\n",
    "        return {face_identity.identity_id for face_identity in FaceIdentity.objects.filter(face_id__in=ids)}\n",
    "    def has_common_face(ids1, ids2):\n",
    "        identities1 = get_identities_for_face_ids(ids1)\n",
    "        identities2 = get_identities_for_face_ids(ids2)\n",
    "        return len(identities1.intersection(identities2)) > 0\n",
    "    faces1 = {face['face_id'] for faces in int1.payload for face in faces}\n",
    "    faces2 = {face['face_id'] for faces in int2.payload for face in faces}\n",
    "    return has_common_face(faces1, faces2)\n",
    "\n",
    "shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Labels with Spatial Constaint\n",
    "\n",
    "We can further restrict the identity matchings to be among faces in the desired left or right region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:27:09.583575Z",
     "start_time": "2018-12-17T00:27:06.022455Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_faces_to_region(region):\n",
    "    def fn(intvl):\n",
    "        intvl.payload = [face for face in intvl.payload if _region_contains_bbox(region, face)]\n",
    "        return intvl\n",
    "    return fn\n",
    "\n",
    "faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(right_half))\n",
    "\n",
    "faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(left_half))\n",
    "\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "\n",
    "shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Identity Labels\n",
    "\n",
    "If we do not have good identity labels, we can instead use the position of the largest face in each sampled frame as a proxy. If the position is stable throughout the shot, it is likely that it is the same person. Sometimes the person can move during the shot (run cell below for an example), so we can set a threshold on the maximum movement of the center point of the face between consecutive sampled frames, in order to allow some movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:27:15.076798Z",
     "start_time": "2018-12-17T00:27:15.022821Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "display_labelled_interval([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:27:19.043249Z",
     "start_time": "2018-12-17T00:27:19.016168Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_FACE_MOVEMENT=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:27:22.401567Z",
     "start_time": "2018-12-17T00:27:20.319811Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_highest_box(boxes):\n",
    "    def get_height(box):\n",
    "        return box['y2'] - box['y1']\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "    result = boxes[0]\n",
    "    best = get_height(result)\n",
    "    for i in range(1, len(boxes)):\n",
    "        h = get_height(boxes[i])\n",
    "        if h > best:\n",
    "            best = h\n",
    "            result= boxes[i]\n",
    "    return result\n",
    "\n",
    "def take_highest_in_frame(intvl):\n",
    "    result = []\n",
    "    for faces_in_frame in intvl.payload:\n",
    "        largest = find_highest_box(faces_in_frame)\n",
    "        if largest is not None:\n",
    "            result.append(largest)\n",
    "    intvl.payload = result\n",
    "    return intvl\n",
    "\n",
    "def movement_less_than(dist):\n",
    "    def get_center(box):\n",
    "        return ((box['x1'] + box['x2']) / 2, (box['y1']+box['y2']) / 2)\n",
    "    def get_distance(pt1, pt2):\n",
    "        return np.sqrt((pt1[0]-pt2[0])**2+(pt1[1]-pt2[1])**2)\n",
    "    def check(boxes):\n",
    "        for b1, b2 in zip(boxes, boxes[1:]):\n",
    "            if get_distance(get_center(b1), get_center(b2)) > dist:\n",
    "                return False\n",
    "        return True\n",
    "    return check\n",
    "\n",
    "shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right).map(take_highest_in_frame).filter(\n",
    "    payload_satisfies(movement_less_than(MAX_FACE_MOVEMENT)))\n",
    "shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left).map(take_highest_in_frame).filter(\n",
    "    payload_satisfies(movement_less_than(MAX_FACE_MOVEMENT)))\n",
    "\n",
    "shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "result = intrvllists_to_result(shot_reverse_shot.get_allintervals(), color='black')\n",
    "add_intrvllists_to_result(result, shot_reverse_shot_labelled, color='red')\n",
    "print_statistics(shot_reverse_shot.get_allintervals(), shot_reverse_shot_labelled)\n",
    "esper_widget(result, crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-contained Functions for Queries in this Document\n",
    "\n",
    "Parameters for each query are listed at the top of the definition in ALL_CAPS variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots with faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:10:20.917637Z",
     "start_time": "2018-12-17T01:10:16.737369Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.3602783388033325\n",
      "Recall:  0.9536398947500313\n",
      "Precision Per Item:  0.39036144578313253\n",
      "Recall Per Item:  1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928389a07a094a2ea65b24305a58f601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shots_with_faces():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.parsers import in_array, bbox_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second\n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "        \n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    shots_with_faces = get_shots_with_face(shots, face_frames)\n",
    "    return intrvllists_to_result_with_objects(shots_with_faces.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shots_with_faces())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot sequences with faces in alternating regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:11:08.371115Z",
     "start_time": "2018-12-17T01:11:03.344757Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.3723450218619843\n",
      "Recall:  0.8998454663158334\n",
      "Precision Per Item:  0.2830188679245283\n",
      "Recall Per Item:  1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ed2131be2c4506a9179f03ee1d1866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shots_with_faces_in_alternating_regions():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "    shot_reverse_shot = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2)\n",
    "    ).coalesce()\n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shots_with_faces_in_alternating_regions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot/Reverse shot with faces above certain probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:11:33.968724Z",
     "start_time": "2018-12-17T01:11:31.903863Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.4629832591924011\n",
      "Recall:  0.8998037004552479\n",
      "Precision Per Item:  0.3333333333333333\n",
      "Recall Per Item:  1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7e30a9f80e47c291870861b1bafcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shot_reverse_shot_with_probable_faces():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    MIN_FACE_PROBABILITY=0.99\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "        \n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "    shot_reverse_shot = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2)\n",
    "    ).coalesce()\n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shot_reverse_shot_with_probable_faces())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot/Reverse shot sequence with at least 3 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:12:04.602336Z",
     "start_time": "2018-12-17T01:12:02.284872Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0bbcba3be24fffa54084a0c250deef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shot_reverse_shot_three_shots():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    MIN_FACE_PROBABILITY=0.99\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "        \n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "    shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shot_reverse_shot_three_shots())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot/Reverse shot sequence with consistent identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:12:34.719746Z",
     "start_time": "2018-12-17T01:12:29.123836Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f701976b4d7145619218d652f5ffc656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shot_reverse_shot_consistent_identities():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    MIN_FACE_PROBABILITY=0.99\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second, payload_first\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "    # Check if the face id labels between the payloads have any in common\n",
    "    def share_face(int1, int2):\n",
    "        def get_identities_for_face_ids(ids):\n",
    "            return {face_identity.identity_id for face_identity in FaceIdentity.objects.filter(face_id__in=ids)}\n",
    "        def has_common_face(ids1, ids2):\n",
    "            identities1 = get_identities_for_face_ids(ids1)\n",
    "            identities2 = get_identities_for_face_ids(ids2)\n",
    "            return len(identities1.intersection(identities2)) > 0\n",
    "        faces1 = {face['face_id'] for faces in int1.payload for face in faces}\n",
    "        faces2 = {face['face_id'] for faces in int2.payload for face in faces}\n",
    "        return has_common_face(faces1, faces2)\n",
    "\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            merge_dict_parsers([\n",
    "                bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "                dict_payload_parser(VideoIntervalCollection.django_accessor, {\"face_id\": \"id\"})\n",
    "            ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    )\n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "\n",
    "    shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()    \n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shot_reverse_shot_consistent_identities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot/Reverse shot sequence with consistent identities in alternating regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:13:01.611494Z",
     "start_time": "2018-12-17T01:12:56.635664Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0929f925404743acaaf29d11dca9ff53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shot_reverse_shot_consistent_identities_in_alternating_regions():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    MIN_FACE_PROBABILITY=0.99\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second, payload_first\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph, _region_contains_bbox\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "    # Check if the face id labels between the payloads have any in common\n",
    "    def share_face(int1, int2):\n",
    "        def get_identities_for_face_ids(ids):\n",
    "            return {face_identity.identity_id for face_identity in FaceIdentity.objects.filter(face_id__in=ids)}\n",
    "        def has_common_face(ids1, ids2):\n",
    "            identities1 = get_identities_for_face_ids(ids1)\n",
    "            identities2 = get_identities_for_face_ids(ids2)\n",
    "            return len(identities1.intersection(identities2)) > 0\n",
    "        faces1 = {face['face_id'] for faces in int1.payload for face in faces}\n",
    "        faces2 = {face['face_id'] for faces in int2.payload for face in faces}\n",
    "        return has_common_face(faces1, faces2)\n",
    "    # Returns a function that transforms an interval by filtering out all faces outside of `region` in its payload.\n",
    "    def filter_faces_to_region(region):\n",
    "        def fn(intvl):\n",
    "            intvl.payload = [face for face in intvl.payload if _region_contains_bbox(region, face)]\n",
    "            return intvl\n",
    "        return fn\n",
    "\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            merge_dict_parsers([\n",
    "                bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "                dict_payload_parser(VideoIntervalCollection.django_accessor, {\"face_id\": \"id\"})\n",
    "            ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(right_half))\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(left_half))\n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right)\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left)\n",
    "\n",
    "    shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1),\n",
    "        payload_merge_op=payload_first\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=and_pred(before(max_dist=1),\n",
    "                           share_face,\n",
    "                           arity=2)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shot_reverse_shot_consistent_identities_in_alternating_regions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot/Reverse shot sequence with consistent face bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:13:22.630296Z",
     "start_time": "2018-12-17T01:13:20.158064Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb75373970dc44a48dba2324bf379c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'schema': [['Identity', ['id', 'name']], ['Genre', ['id', 'name']], ['Video', ['id', 'p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shot_reverse_shot_consistent_face_bbox():\n",
    "    VIDEO_ID=216\n",
    "    CINEMATIC_SHOTS_LABELLER=64\n",
    "    RIGHT_HALF_MIN_X=0.33\n",
    "    LEFT_HALF_MAX_X=0.66\n",
    "    MAX_FACES_ON_SCREEN=4\n",
    "    MIN_FACE_HEIGHT=0.2\n",
    "    MIN_FACE_PROBABILITY=0.99\n",
    "    MAX_FACE_MOVEMENT=0.15\n",
    "    \n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.bbox_predicates import height_at_least\n",
    "    from rekall.parsers import in_array, bbox_payload_parser\n",
    "    from rekall.merge_ops import payload_plus, payload_second\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    from rekall.spatial_predicates import make_region, scene_graph, _region_contains_bbox\n",
    "    from rekall.list_predicates import length_at_most\n",
    "    from rekall.logical_predicates import and_pred, or_pred\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    # Keep shots that overlaps with face_frames and each shot's payload is a list, each element is a list of\n",
    "    # faces of a frame in the shot.\n",
    "    def get_shots_with_face(shots, face_frames):\n",
    "        # Wrap the payload in a list.\n",
    "        def wrap_list(intvl):\n",
    "            intvl.payload = [intvl.payload]\n",
    "            return intvl\n",
    "        return shots.merge(\n",
    "            face_frames, predicate=overlaps(), payload_merge_op=payload_second\n",
    "        ).map(wrap_list).coalesce(payload_merge_op=payload_plus)\n",
    "    # Returns a function that transforms an interval by filtering out all faces outside of `region` in its payload.\n",
    "    def filter_faces_to_region(region):\n",
    "        def fn(intvl):\n",
    "            intvl.payload = [face for face in intvl.payload if _region_contains_bbox(region, face)]\n",
    "            return intvl\n",
    "        return fn\n",
    "    # Returns the highest bbox in `boxes`\n",
    "    def find_highest_box(boxes):\n",
    "        def get_height(box):\n",
    "            return box['y2'] - box['y1']\n",
    "        if len(boxes) == 0:\n",
    "            return None\n",
    "        result = boxes[0]\n",
    "        best = get_height(result)\n",
    "        for i in range(1, len(boxes)):\n",
    "            h = get_height(boxes[i])\n",
    "            if h > best:\n",
    "                best = h\n",
    "                result= boxes[i]\n",
    "        return result\n",
    "    # Transforms the interval's payload (list of bboxes) by picking the highest bbox\n",
    "    def take_highest_in_frame(intvl):\n",
    "        result = []\n",
    "        for faces_in_frame in intvl.payload:\n",
    "            largest = find_highest_box(faces_in_frame)\n",
    "            if largest is not None:\n",
    "                result.append(largest)\n",
    "        intvl.payload = result\n",
    "        return intvl\n",
    "    # Returns a function that checks if the distance between centers of consecutive boxes\n",
    "    # is within `dist`.\n",
    "    def movement_less_than(dist):\n",
    "        def get_center(box):\n",
    "            return ((box['x1'] + box['x2']) / 2, (box['y1']+box['y2']) / 2)\n",
    "        def get_distance(pt1, pt2):\n",
    "            return np.sqrt((pt1[0]-pt2[0])**2+(pt1[1]-pt2[1])**2)\n",
    "        def check(boxes):\n",
    "            for b1, b2 in zip(boxes, boxes[1:]):\n",
    "                if get_distance(get_center(b1), get_center(b2)) > dist:\n",
    "                    return False\n",
    "            return True\n",
    "        return check\n",
    "    \n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        Shot.objects.filter(video_id=VIDEO_ID, labeler_id=CINEMATIC_SHOTS_LABELLER),\n",
    "        with_payload=lambda obj:[]\n",
    "    )\n",
    "    # For each frame, payload is a list of faces\n",
    "    face_frames = VideoIntervalCollection.from_django_qs(\n",
    "        Face.objects.annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')).filter(video_id=VIDEO_ID, probability__gte=MIN_FACE_PROBABILITY),\n",
    "        with_payload=in_array(\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "    \n",
    "    right_half = make_region(RIGHT_HALF_MIN_X, 0.0, 1.0, 1.0)\n",
    "    left_half = make_region(0.0, 0.0, LEFT_HALF_MAX_X, 1.0)\n",
    "    graph = {\n",
    "        'nodes': [ { 'name': 'face', 'predicates': [ height_at_least(MIN_FACE_HEIGHT) ] } ],\n",
    "        'edges': []\n",
    "    }\n",
    "    faces_on_right = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=right_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(right_half))\n",
    "\n",
    "    faces_on_left = face_frames.filter(\n",
    "        and_pred(\n",
    "            payload_satisfies(length_at_most(MAX_FACES_ON_SCREEN)),\n",
    "            payload_satisfies(scene_graph(graph, region=left_half))\n",
    "        )\n",
    "    ).map(filter_faces_to_region(left_half))\n",
    "    \n",
    "    shots_with_faces_on_right = get_shots_with_face(shots, faces_on_right).map(take_highest_in_frame).filter(\n",
    "        payload_satisfies(movement_less_than(MAX_FACE_MOVEMENT)))\n",
    "    shots_with_faces_on_left = get_shots_with_face(shots, faces_on_left).map(take_highest_in_frame).filter(\n",
    "        payload_satisfies(movement_less_than(MAX_FACE_MOVEMENT)))\n",
    "    \n",
    "    shot_reverse_shot_1 = shots_with_faces_on_right.merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot_2 = shots_with_faces_on_left.merge(\n",
    "        shots_with_faces_on_right,\n",
    "        predicate=before(max_dist=1)\n",
    "    ).merge(\n",
    "        shots_with_faces_on_left,\n",
    "        predicate=before(max_dist=1)\n",
    "    )\n",
    "\n",
    "    shot_reverse_shot = shot_reverse_shot_1.set_union(shot_reverse_shot_2).coalesce()\n",
    "    return intrvllists_to_result_with_objects(shot_reverse_shot.get_allintervals(), payload_to_objs=lambda p,v:[])\n",
    "\n",
    "esper_widget(shot_reverse_shot_consistent_face_bbox())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T00:00:51.599857Z",
     "start_time": "2018-12-17T00:00:51.302080Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_height(box):\n",
    "    return box['y2'] - box['y1']\n",
    "\n",
    "def find_highest_box(boxes):\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "    result = boxes[0]\n",
    "    best = get_height(result)\n",
    "    for i in range(1, len(boxes)):\n",
    "        h = get_height(boxes[i])\n",
    "        if h > best:\n",
    "            best = h\n",
    "            result= boxes[i]\n",
    "    return result\n",
    "\n",
    "def take_highest_in_frame(intvl):\n",
    "    result = []\n",
    "    for faces_in_frame in intvl.payload:\n",
    "        largest = find_highest_box(faces_in_frame)\n",
    "        if largest is not None:\n",
    "            result.append(largest)\n",
    "    intvl.payload = result\n",
    "    return intvl\n",
    "\n",
    "def take_highest_in_region(x1,x2):\n",
    "    def fn(intvl):\n",
    "        filtered = []\n",
    "        for faces_in_frame in intvl.payload:\n",
    "            faces = [f for f in faces_in_frame if f['x1']>=x1 and f['x2']<=x2]\n",
    "            if len(faces) > 0:\n",
    "                filtered.append(faces)\n",
    "        intvl.payload = filtered\n",
    "        return take_highest_in_frame(intvl)\n",
    "    return fn\n",
    "\n",
    "shot_reverse_shot_with_faces = shots_with_faces_on_right.map(take_highest_in_region(RIGHT_HALF_MIN_X, 1.0)).merge(\n",
    "        shots_with_faces_on_left.map(take_highest_in_region(0, LEFT_HALF_MAX_X)),\n",
    "        predicate=or_pred(before(max_dist=1), after(max_dist=1), arity=2),\n",
    "        payload_merge_op=lambda p1, p2: (p1,p2)\n",
    "    ).coalesce()=\n",
    "\n",
    "def double_list_to_objects(p, v):\n",
    "    right_faces, left_faces = p\n",
    "    def to_obj(box, i):\n",
    "        obj = bbox_to_result_object(box, v)\n",
    "        obj['gender_id'] = i\n",
    "        return obj\n",
    "    return [to_obj(box, 1) for faces in left_faces for box in faces] + [to_obj(box, 2) for faces in right_faces for box in faces]\n",
    "\n",
    "def list_to_objects(p,v):\n",
    "    right_faces, left_faces = p\n",
    "    def to_obj(box, i):\n",
    "        obj = bbox_to_result_object(box, v)\n",
    "        obj['gender_id'] = i\n",
    "        return obj\n",
    "    return [to_obj(box, 1) for box in left_faces] + [to_obj(box, 2) for box in right_faces]\n",
    "\n",
    "esper_widget(intrvllists_to_result_with_objects(shot_reverse_shot_with_faces.filter(lambda intvl: True).get_allintervals(), payload_to_objs=list_to_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T01:07:45.302187Z",
     "start_time": "2018-12-17T01:07:44.511966Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
