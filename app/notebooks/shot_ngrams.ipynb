{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We would like to explore the grammar of film as a sequence of shots. More specifically, we will represent each shot as a set of categorical features, thus breaking the film down to a sequence of \"words\" where each word is a certain combination of these features. We will then explore the frequencies of ngrams formed by these words in our corpus and see if there are discriminative ngrams for each genre/director/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:27.161960Z",
     "start_time": "2019-01-04T07:57:25.787575Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from query.models import Video, Shot, Labeler, Face, PoseMeta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from django.db.models import Avg\n",
    "from tqdm import tqdm\n",
    "import esper.pose_wrapper as pw\n",
    "from esper.shot_scale import ShotScale as ShotScaleEnum\n",
    "import rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import IntervalList\n",
    "from rekall.merge_ops import payload_plus, payload_second\n",
    "from rekall.temporal_predicates import overlaps\n",
    "from esper.rekall import intrvllists_to_result_with_objects\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features of a shot\n",
    "\n",
    "We will use the following features to represent each shot:\n",
    "\n",
    "1. ShotScale: One of ExtremeLong, Long, MediumLong, Medium, MediumCloseUp, CloseUp, ExtremeCloseUp and Unknown (when the shot contains no people).\n",
    "    - From the scales of the sampled frames, we will ignore the unknown scales, and take the mode to be the scale of the shot. If all sampled frames have unknown scale, the shot will have unknown scale. Note that this can be problematic for shots where camera has lots of movement and changes framing.\n",
    "2. Number of people: We will use the number of poses detected in the shot. \n",
    "    - From the number of poses detected in sampled frames, we take the max to be the number of people in the shot.\n",
    "    - 5 or more people will be truncated at 5 to be consistent with James Cutting's analysis.\n",
    "3. Position of people: We will use the number of poses that overlap the left, mid and right third of the screen.\n",
    "    - We use the sampled frame with the max number of poses. Note that this can be problematic for a shot with moving subject.\n",
    "    - The counts will similarly be truncated at 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:27.238014Z",
     "start_time": "2019-01-04T07:57:27.167404Z"
    }
   },
   "outputs": [],
   "source": [
    "# `poses` is a list of poses with 18 keypoints\n",
    "def count_in_region(poses, region):\n",
    "    def in_region(pose):\n",
    "        # Take only detected keypoints\n",
    "        xs = pose[pose[:,2]>0,0]\n",
    "        result = (xs >= region[0]) & (xs <= region[1])\n",
    "        return np.any(result)\n",
    "    return len([pose for pose in poses if in_region(pose.pose_keypoints())])\n",
    "\n",
    "def truncate(val, maxval):\n",
    "    return val if val < maxval else maxval\n",
    "\n",
    "# Find the scale for shot from scales of sampled frames\n",
    "def scale_for_shot(scales):\n",
    "    scales = [scale for scale in scales if (scale != ShotScaleEnum.UNKNOWN)]\n",
    "    if len(scales) == 0:\n",
    "        return ShotScaleEnum.UNKNOWN\n",
    "    counter={}\n",
    "    for s in ShotScaleEnum:\n",
    "        counter[s]=0\n",
    "    for scale in scales:\n",
    "        counter[scale] += 1\n",
    "    best_c = 0\n",
    "    best = ShotScaleEnum.UNKNOWN\n",
    "    for s in ShotScaleEnum:\n",
    "        if counter[s] >= best_c:\n",
    "            best_c = counter[s]\n",
    "            best = s\n",
    "    return best\n",
    "\n",
    "# Find the poses for shot from pose_metas in sampled frames\n",
    "def poses_for_shot(pose_metas_for_frames):\n",
    "    pose_metas = max(pose_metas_for_frames, key=len)\n",
    "    return pw.get(pose_metas)\n",
    "\n",
    "class ShotFeatures():\n",
    "    MAX_COUNT = 5\n",
    "    REGIONS = [(0,1/3),(1/3,2/3),(2/3,1)]\n",
    "    def __init__(self, scale, poses):\n",
    "        self.scale = scale\n",
    "        self.n_people = truncate(len(poses), ShotFeatures.MAX_COUNT)\n",
    "        self.counts = tuple(truncate(count_in_region(poses, r), ShotFeatures.MAX_COUNT) for r in ShotFeatures.REGIONS)\n",
    "        self.pose_ids = [pose.id for pose in poses]\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ShotFeatures with Rekall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:27.987399Z",
     "start_time": "2019-01-04T07:57:27.905416Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_shots_with_features_for_vid(vid):\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video__id=vid,\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face')\n",
    "    ).all()\n",
    "    total = shots_qs.count()\n",
    "    print(\"Total shots:\", total)\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        with_payload=lambda row:[],\n",
    "        progress=True,\n",
    "        total=total\n",
    "    )\n",
    "\n",
    "    # Take all frames with known scale\n",
    "    frames_qs = Frame.objects.filter(video__id=vid).annotate(\n",
    "        numbermod=F('number')%12).filter(numbermod=0).annotate(scale=F(\"shot_scale__name\"))\n",
    "    total = frames_qs.count()\n",
    "    print(\"Total frames with scale:\", total)\n",
    "    shot_scales = VideoIntervalCollection.from_django_qs(\n",
    "        frames_qs,\n",
    "        schema={\n",
    "            \"start\": \"number\",\n",
    "            \"end\": \"number\",\n",
    "        },\n",
    "        with_payload=lambda f: [ShotScaleEnum[f.scale.upper()]],\n",
    "        progress=True, total=total)\n",
    "\n",
    "    # Take all poses\n",
    "    poses_qs = PoseMeta.objects.filter(frame__video__id=vid).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id')\n",
    "    )\n",
    "    total = poses_qs.count()\n",
    "    print(\"Total Poses:\", total)\n",
    "    poses = VideoIntervalCollection.from_django_qs(\n",
    "        poses_qs,\n",
    "        with_payload=lambda row: [row],\n",
    "        progress=True,\n",
    "        total=total\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    print(\"Merging scales into shots\")\n",
    "    # Merge scales into shots\n",
    "    shots_with_scale = shots.merge(\n",
    "        shot_scales,\n",
    "        payload_merge_op = payload_second,\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(\n",
    "        payload_merge_op=payload_plus\n",
    "    ).map(\n",
    "        lambda shot_interval: (shot_interval.get_start(), shot_interval.get_end(),\n",
    "                              {\"scale\": scale_for_shot(shot_interval.get_payload())})\n",
    "    )\n",
    "\n",
    "    print(\"Merging poses into shots\")\n",
    "    # Merge poses into shots\n",
    "    shots_with_poses = shots.merge(\n",
    "        poses.map(lambda shot_interval: (shot_interval.get_start(), shot_interval.get_end(), [shot_interval.get_payload()])),\n",
    "        payload_merge_op = payload_second,\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(\n",
    "        # Get a list of list of poses for each shot\n",
    "        payload_merge_op = payload_plus\n",
    "    ).map(lambda shot_interval: (shot_interval.get_start(), shot_interval.get_end(),\n",
    "                               {\"poses\": poses_for_shot(shot_interval.get_payload())}))\n",
    "                                 \n",
    "\n",
    "    print(\"Computing shot features\")\n",
    "    # Get shots with shot features\n",
    "    shots = shots_with_scale.merge(\n",
    "        shots_with_poses,\n",
    "        payload_merge_op = lambda d1, d2: {**d1,**d2},\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce().map(\n",
    "        lambda intv: (intv.get_start(), intv.get_end(), ShotFeatures(intv.get_payload()[\"scale\"], intv.get_payload()[\"poses\"])))\n",
    "    return shots_with_poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T22:26:36.555764Z",
     "start_time": "2019-01-03T21:26:23.518406Z"
    }
   },
   "source": [
    "We run `get_shots_with_features_for_vid` on all videos and save the interval lists to `../data/shot_features/{vid}_intervalllist.p`. See `/app/esper/shot_features.py` for the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring ShotFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:29.877916Z",
     "start_time": "2019-01-04T07:57:29.831833Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_features_to_string(f):\n",
    "    return \"{0}-{1}-{2}-{3}-{4}\".format(f.scale.name, f.n_people, f.counts[0], f.counts[1], f.counts[2])\n",
    "\n",
    "# Returns a dict of document name to list of words\n",
    "def get_documents(vids):\n",
    "    docs = {}\n",
    "    for vid in vids:\n",
    "        shots = pickle.load(open(\"../data/shot_features/{0:03d}_intervallist.p\".format(vid),\"rb\"))\n",
    "        docs[vid]=[shot_features_to_string(intvl.get_payload()) for intvl in shots.get_intervals()]\n",
    "    return docs\n",
    "\n",
    "# Returns a list of ngrams in document\n",
    "def expand_ngram(doc, ngram):\n",
    "    args = []\n",
    "    for i in range(ngram):\n",
    "        args.append(doc[i:])\n",
    "    return zip(*args)\n",
    "\n",
    "# Returns a set of words\n",
    "def get_vocabulary(docs, ngram=1):\n",
    "    return set((word for doc in docs.values() for word in expand_ngram(doc, ngram)))\n",
    "\n",
    "# Compute the frequencies of all ngrams, or just the ngrams in vocabulary.\n",
    "def get_all_frequencies(docs, vocab=None, ngram=1):\n",
    "    return Counter((word for doc in docs.values() for word in expand_ngram(\n",
    "            doc, ngram) if vocab is None or word in vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:44.586409Z",
     "start_time": "2019-01-04T07:57:39.050224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Movie 344 has bad pose data\n",
    "all_videos = Video.objects.filter(decode_errors=False).exclude(id=344).order_by('id').all()[:304]\n",
    "vids = [v.id for v in all_videos]\n",
    "docs = get_documents(vids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over all movies\n",
    "\n",
    "We plot the most frequent unigrams and bigrams in our overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:57:48.102432Z",
     "start_time": "2019-01-04T07:57:44.589711Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_histograms(docs, ngram, n):\n",
    "    total = sum([len(doc)-ngram+1 for doc in docs.values()])\n",
    "    v = get_vocabulary(docs, ngram)\n",
    "    c = get_all_frequencies(docs, v, ngram)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Top {0}-grams by frequency\".format(ngram))\n",
    "    data = c.most_common(n)\n",
    "    labels = [str(d[0]) for d in data]\n",
    "    counts = np.array([d[1] for d in data])\n",
    "    ax.barh(np.arange(n), counts)\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xticklabels(['{:,.2%}'.format(x) for x in ax.get_xticks()/total])\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "    return v, c\n",
    "    \n",
    "unigrams_v, unigrams_count = plot_histograms(docs, 1, 15)\n",
    "bigrams_v, bigrams_count = plot_histograms(docs, 2, 10)\n",
    "trigrams_v, trigrams_count = plot_histograms(docs, 3, 10)\n",
    "fourgrams_v, fourgrams_count = plot_histograms(docs, 4, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T05:15:13.623774Z",
     "start_time": "2019-01-04T05:15:13.593279Z"
    }
   },
   "source": [
    "## By Genre\n",
    "\n",
    "We now look at ngrams with top frequencies within each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T06:54:01.778937Z",
     "start_time": "2019-01-04T06:54:01.727589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print a list of genres\n",
    "genres = [g.name for g in Genre.objects.all()]\n",
    "# Get a map from genre to a list of videos in that genre\n",
    "genre_to_vids = {}\n",
    "for g in genres:\n",
    "    genre_to_vids[g]=[v.id for v in all_videos.filter(genres__name=g)]\n",
    "# Display a selection\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "w=widgets.Dropdown(options=genres, value=genres[0], description=\"Select Genre:\", disabled=False)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T06:53:16.503683Z",
     "start_time": "2019-01-04T06:53:16.445984Z"
    }
   },
   "outputs": [],
   "source": [
    "vids_in_genre = genre_to_vids[w.value]\n",
    "print(\"Number of movies: \", len(vids_in_genre))\n",
    "docs_in_genre = dict((vid, docs[vid]) for vid in vids_in_genre)\n",
    "unigrams_v, unigrams_count = plot_histograms(docs_in_genre, 1, 15)\n",
    "bigrams_v, bigrams_count = plot_histograms(docs_in_genre, 2, 10)\n",
    "trigrams_v, trigrams_count = plot_histograms(docs_in_genre, 3, 10)\n",
    "fourgrams_v, fourgrams_count = plot_histograms(docs_in_genre, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T06:25:52.486839Z",
     "start_time": "2019-01-04T06:25:52.448458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the shot indices for the starting shot of the matching n-grams.\n",
    "def find_indices(ngram_to_find, doc):\n",
    "    expanded_doc = expand_ngram(doc, len(ngram_to_find))\n",
    "    return [i for i, ngram in enumerate(expanded_doc) if ngram == ngram_to_find]\n",
    "\n",
    "def load_shots_for_ngram(ngram_to_find, docs):\n",
    "    vid_to_shot_indices = dict((vid, find_indices(ngram_to_find, docs[vid])) for vid in docs.keys())\n",
    "    results = {}\n",
    "    for vid, indices in vid_to_shot_indices.items():\n",
    "        if len(indices) > 0:\n",
    "            inds = set(indices)\n",
    "            shots = pickle.load(open(\"../data/shot_features/{0:03d}_intervallist.p\".format(vid),\"rb\"))\n",
    "            results[vid] = IntervalList([intvl for i, intvl in enumerate(shots.get_intervals()) if i in inds])\n",
    "    return results\n",
    "\n",
    "def display_ngrams_in_widget(ngram_to_find, docs):\n",
    "    return esper_widget(intrvllists_to_result_with_objects(load_shots_for_ngram(ngram_to_find, docs), payload_to_objs=lambda p,v:[]),\n",
    "            crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T06:33:08.726474Z",
     "start_time": "2019-01-04T06:33:08.610260Z"
    }
   },
   "outputs": [],
   "source": [
    "ngram_to_find = (\"UNKNOWN-0-0-0-0\",)\n",
    "display_ngrams_in_widget(ngram_to_find, docs_in_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T17:57:11.975410Z",
     "start_time": "2019-01-03T17:55:14.081648Z"
    }
   },
   "outputs": [],
   "source": [
    "poses=pw.get(PoseMeta.objects.filter(frame__video__id=216))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T18:37:17.011118Z",
     "start_time": "2019-01-03T18:37:16.978272Z"
    }
   },
   "outputs": [],
   "source": [
    "print(poses[1].pose_keypoints())\n",
    "f=ShotFeatures(ShotScaleEnum.CLOSE_UP, [poses[0].pose_keypoints(), poses[1].pose_keypoints()])\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T18:12:18.988879Z",
     "start_time": "2019-01-03T18:12:18.956989Z"
    }
   },
   "outputs": [],
   "source": [
    "ShotScaleEnum.UNKNOWN != ShotScaleEnum.CLOSE_UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T18:16:04.137290Z",
     "start_time": "2019-01-03T18:16:04.105149Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c=Counter([1,1,1,2,2,2,3])\n",
    "c.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T18:22:56.775705Z",
     "start_time": "2019-01-03T18:22:56.745258Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_for_shot([ShotScaleEnum.UNKNOWN, ShotScaleEnum.UNKNOWN, ShotScaleEnum.CLOSE_UP, ShotScaleEnum.MEDIUM, ShotScaleEnum.MEDIUM, ShotScaleEnum.CLOSE_UP, ShotScaleEnum.EXTREME_CLOSE_UP, ShotScaleEnum.EXTREME_CLOSE_UP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T18:28:27.399726Z",
     "start_time": "2019-01-03T18:28:24.557017Z"
    }
   },
   "outputs": [],
   "source": [
    "metas=PoseMeta.objects.filter(frame__video__id=216)\n",
    "metas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T21:21:40.291802Z",
     "start_time": "2019-01-03T21:21:40.257687Z"
    }
   },
   "outputs": [],
   "source": [
    "shots.get_intervallist(VIDS[0]).get_intervals()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T20:01:11.508945Z",
     "start_time": "2019-01-03T20:00:55.153058Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(shots_with_poses.get_allintervals(), payload_to_objs=lambda p,v:[esper.stdlib.pose_to_dict(pose) for pose in p['poses']]),\n",
    "             crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T20:31:35.785607Z",
     "start_time": "2019-01-03T20:31:35.748826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(shots, open(\"{0}.p\".format(VIDS[0]), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T21:25:17.358680Z",
     "start_time": "2019-01-03T21:25:16.989881Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pickle.load(open('shot_features/216.p', \"rb\"))\n",
    "esper_widget(intrvllists_to_result_with_objects({216:test}, payload_to_objs=lambda p,v:[]),\n",
    "             crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T23:54:14.898050Z",
     "start_time": "2019-01-03T23:54:14.392771Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.shot_features import ShotFeatures\n",
    "test=pickle.load(open(\"../data/shot_features/216_intervallist.p\",\"rb\"))\n",
    "esper_widget(intrvllists_to_result_with_objects({216:test}, payload_to_objs=lambda p,v:[]),\n",
    "             crop_bboxes=False, show_middle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T23:56:03.046966Z",
     "start_time": "2019-01-03T23:56:03.015122Z"
    }
   },
   "outputs": [],
   "source": [
    "test.filter(lambda i:i.get_start()==6849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T01:34:48.531544Z",
     "start_time": "2019-01-04T01:34:28.393559Z"
    }
   },
   "outputs": [],
   "source": [
    "all_videos = Video.objects.filter(decode_errors=False).order_by('id').all()\n",
    "vids = [v.id for v in all_videos]\n",
    "vids.remove(344)\n",
    "docs = get_documents(vids)\n",
    "v=get_vocabulary(docs, ngram=2)\n",
    "print(len(v))\n",
    "c=get_all_frequencies(docs, ngram=2)\n",
    "print(c.most_common(20))\n",
    "c=get_all_frequencies(docs, ngram=1)\n",
    "print(c.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T00:34:38.048809Z",
     "start_time": "2019-01-04T00:34:38.014969Z"
    }
   },
   "outputs": [],
   "source": [
    "Video.objects.filter(pk=344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T00:53:06.920825Z",
     "start_time": "2019-01-04T00:53:06.886628Z"
    }
   },
   "outputs": [],
   "source": [
    "pm=PoseMeta.objects.filter(frame__video_id=344, frame__number=1164)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T00:55:45.011492Z",
     "start_time": "2019-01-04T00:55:44.969684Z"
    }
   },
   "outputs": [],
   "source": [
    "pm1=PoseMeta.objects.filter(id=9562306)[0]\n",
    "pm2=PoseMeta.objects.filter(id=9590175)[0]\n",
    "pm1.frame.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T00:55:49.017976Z",
     "start_time": "2019-01-04T00:55:48.984156Z"
    }
   },
   "outputs": [],
   "source": [
    "pm2.frame.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T01:03:36.769000Z",
     "start_time": "2019-01-04T01:03:36.732920Z"
    }
   },
   "outputs": [],
   "source": [
    "pw._POSE_DATA.get([9562306, 9590175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T04:27:09.189230Z",
     "start_time": "2019-01-04T04:27:07.874004Z"
    }
   },
   "outputs": [],
   "source": [
    "FaceGender.objects.all().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T04:27:14.538101Z",
     "start_time": "2019-01-04T04:27:13.233770Z"
    }
   },
   "outputs": [],
   "source": [
    "Face.objects.all().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T04:51:03.721172Z",
     "start_time": "2019-01-04T04:51:03.678817Z"
    }
   },
   "outputs": [],
   "source": [
    "list(Genre.objects.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:05:49.145266Z",
     "start_time": "2019-01-04T07:05:47.081960Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Frame.objects.count())\n",
    "Frame.objects.exclude(shot_scale__name=\"unknown\")[123].number % 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T07:05:44.485719Z",
     "start_time": "2019-01-04T07:05:44.446250Z"
    }
   },
   "outputs": [],
   "source": [
    "unks = [v for v in unigrams_v if v[0].startswith(\"UNKNOWN\")]\n",
    "cc = len(list(unigrams_count.elements()))\n",
    "max([unigrams_count[unk]/cc for unk in unks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
