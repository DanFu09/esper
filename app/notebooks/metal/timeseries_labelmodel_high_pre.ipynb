{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, pickle, csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "sys.path.append('/lfs/1/danfu/metal')\n",
    "sys.path.append('/lfs/1/danfu/sequential_ws')\n",
    "from metal.metrics import metric_score\n",
    "from torch.nn.functional import normalize\n",
    "from DP.label_model import *\n",
    "import pandas as pd\n",
    "from metal.label_model.baselines import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/L_train_100_windows_high_pre.npz'\n",
    "L_dev_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/L_dev_windows_high_pre.npz'\n",
    "Y_dev_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/Y_dev_windows_high_pre.npy'\n",
    "\n",
    "stride = 1\n",
    "L_train_raw = sp.sparse.load_npz(L_train_path).todense()[::stride]\n",
    "L_dev_raw = sp.sparse.load_npz(L_dev_path).todense()\n",
    "Y_dev_raw = np.load(Y_dev_path)\n",
    "\n",
    "T = 5\n",
    "\n",
    "L_train = torch.FloatTensor(L_train_raw[:L_train_raw.shape[0] - (L_train_raw.shape[0] % T)]).to(device)\n",
    "L_dev = torch.FloatTensor(L_dev_raw[:L_dev_raw.shape[0] - (L_dev_raw.shape[0] % T)]).to(device)\n",
    "Y_dev = torch.FloatTensor(Y_dev_raw[:Y_dev_raw.shape[0] - (Y_dev_raw.shape[0] % T)]).to(device)\n",
    "m_per_task = L_train.size(1)\n",
    "n_frames_train = L_train.size(0)\n",
    "n_patients_train = n_frames_train//T\n",
    "n_frames_dev = L_dev.size(0)\n",
    "n_patients_dev = n_frames_dev//T\n",
    "\n",
    "# MRI_data_naive = {'Li_train': (L_train.unsqueeze(2) == torch.FloatTensor([-1,1,0]).to(device).unsqueeze(0).unsqueeze(0)).argmax(2),\n",
    "#                   'Li_dev': (L_dev.unsqueeze(2) == torch.FloatTensor([-1,1,0]).to(device).unsqueeze(0).unsqueeze(0)).argmax(2),\n",
    "#                   'R_dev': (Y_dev.unsqueeze(1) == torch.FloatTensor([-1,1]).to(device).unsqueeze(0)).argmax(1),\n",
    "#                   'm':m_per_task, 'T':1,\n",
    "#                  }\n",
    "\n",
    "# don't need to transform the raw data\n",
    "MRI_data_naive = {'Li_train': L_train.long().to(device),\n",
    "                  'Li_dev': L_dev.long().to(device),\n",
    "                  'R_dev': Y_dev.long().to(device),\n",
    "                  'm':m_per_task, 'T':1,\n",
    "                 }\n",
    "MRI_data_naive['class_balance'] = normalize((MRI_data_naive['R_dev'].unsqueeze(1)==torch.arange(2, device=device).unsqueeze(0)).sum(0).float(), \n",
    "                                            dim=0, p=1)\n",
    "MRI_data_temporal = {'Li_train': MRI_data_naive['Li_train'].view(n_patients_train, (m_per_task*T)),\n",
    "                     'Li_dev': MRI_data_naive['Li_dev'].view(n_patients_dev, (m_per_task*T)),\n",
    "                     'R_dev': MRI_data_naive['R_dev']*(2**T-1),\n",
    "                     'm': m_per_task * T, 'T': T,\n",
    "                    } \n",
    "MRI_data_temporal['class_balance'] = normalize((MRI_data_temporal['R_dev'].unsqueeze(1)==torch.arange(2**T, device=device).unsqueeze(0)).sum(0).float(), \n",
    "                                                dim=0, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'l2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-028ff73269cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                            seed=0)\n\u001b[1;32m     10\u001b[0m optimize(naive_model, L_hat=MRI_data_naive['Li_train'], num_iter=10000,\n\u001b[0;32m---> 11\u001b[0;31m          lr=4.087885261759692e-05, momentum=0.9, clamp=True, seed=123, l2=7.938453589700949e-05)\n\u001b[0m",
      "\u001b[0;32m/lfs/1/danfu/sequential_ws/DP/label_model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, O_hat, L_hat, num_iter, print_count, lr, clamp, seed, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mO_hat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mO_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_O_hat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'l2'"
     ]
    }
   ],
   "source": [
    "naive_model = DPLabelModel(m=m_per_task, \n",
    "                           T=1,\n",
    "                           edges=[],\n",
    "                           coverage_sets=[[0,]]*m_per_task,\n",
    "                           mu_sharing=[[i,] for i in range(m_per_task)],\n",
    "                           phi_sharing=[],\n",
    "                           device=device,\n",
    "                           class_balance=torch.tensor([0.4, 0.6]).to(device), \n",
    "                           seed=0)\n",
    "optimize(naive_model, L_hat=MRI_data_naive['Li_train'], num_iter=10000,\n",
    "         lr=4.087885261759692e-05, momentum=0.9, clamp=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.394\n",
      "F1: 0.143\n",
      "Recall: 0.288\n",
      "Precision: 0.095\n"
     ]
    }
   ],
   "source": [
    "R_pred = naive_model.predict(MRI_data_naive['Li_dev']) + 1\n",
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(MRI_data_naive['R_dev'].cpu(), R_pred.cpu(), metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred_flipped = torch.where(torch.tensor(R_pred.cpu())==2.,torch.tensor(1.),torch.tensor(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 2., 2., 2.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred_flipped[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.606\n",
      "F1: 0.389\n",
      "Recall: 0.712\n",
      "Precision: 0.268\n"
     ]
    }
   ],
   "source": [
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(MRI_data_naive['R_dev'].cpu(), R_pred_flipped, metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.923\n",
      "F1: 0.778\n",
      "Recall: 0.772\n",
      "Precision: 0.785\n"
     ]
    }
   ],
   "source": [
    "mv = MajorityLabelVoter(seed=123)\n",
    "mv_pred = mv.predict(MRI_data_naive['Li_dev'])\n",
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(MRI_data_naive['R_dev'].cpu(), mv_pred, metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.335\n",
      "F1: 0.146\n",
      "Recall: 0.322\n",
      "Precision: 0.094\n",
      "\n",
      "Accuracy: 0.610\n",
      "F1: 0.316\n",
      "Recall: 0.511\n",
      "Precision: 0.228\n",
      "\n",
      "Accuracy: 0.545\n",
      "F1: 0.239\n",
      "Recall: 0.407\n",
      "Precision: 0.170\n",
      "\n",
      "Accuracy: 0.418\n",
      "F1: 0.212\n",
      "Recall: 0.446\n",
      "Precision: 0.139\n",
      "\n",
      "Accuracy: 0.364\n",
      "F1: 0.222\n",
      "Recall: 0.517\n",
      "Precision: 0.142\n",
      "\n",
      "Accuracy: 0.471\n",
      "F1: 0.236\n",
      "Recall: 0.464\n",
      "Precision: 0.158\n",
      "\n",
      "Accuracy: 0.546\n",
      "F1: 0.327\n",
      "Recall: 0.628\n",
      "Precision: 0.221\n",
      "\n",
      "Accuracy: 0.288\n",
      "F1: 0.191\n",
      "Recall: 0.477\n",
      "Precision: 0.119\n",
      "\n",
      "Accuracy: 0.448\n",
      "F1: 0.201\n",
      "Recall: 0.395\n",
      "Precision: 0.135\n",
      "\n",
      "Accuracy: 0.497\n",
      "F1: 0.236\n",
      "Recall: 0.442\n",
      "Precision: 0.161\n",
      "\n",
      "10\n",
      "Accuracy: 0.449\n",
      "F1: 0.184\n",
      "Recall: 0.354\n",
      "Precision: 0.125\n",
      "\n",
      "Accuracy: 0.376\n",
      "F1: 0.247\n",
      "Recall: 0.583\n",
      "Precision: 0.157\n",
      "\n",
      "Accuracy: 0.473\n",
      "F1: 0.206\n",
      "Recall: 0.387\n",
      "Precision: 0.140\n",
      "\n",
      "Accuracy: 0.578\n",
      "F1: 0.318\n",
      "Recall: 0.560\n",
      "Precision: 0.222\n",
      "\n",
      "Accuracy: 0.528\n",
      "F1: 0.229\n",
      "Recall: 0.398\n",
      "Precision: 0.160\n",
      "\n",
      "Accuracy: 0.615\n",
      "F1: 0.242\n",
      "Recall: 0.349\n",
      "Precision: 0.185\n",
      "\n",
      "Accuracy: 0.518\n",
      "F1: 0.068\n",
      "Recall: 0.100\n",
      "Precision: 0.052\n",
      "\n",
      "Accuracy: 0.586\n",
      "F1: 0.163\n",
      "Recall: 0.230\n",
      "Precision: 0.127\n",
      "\n",
      "Accuracy: 0.522\n",
      "F1: 0.135\n",
      "Recall: 0.213\n",
      "Precision: 0.099\n",
      "\n",
      "Accuracy: 0.482\n",
      "F1: 0.271\n",
      "Recall: 0.548\n",
      "Precision: 0.180\n",
      "\n",
      "50\n",
      "Accuracy: 0.574\n",
      "F1: 0.273\n",
      "Recall: 0.455\n",
      "Precision: 0.195\n",
      "\n",
      "Accuracy: 0.361\n",
      "F1: 0.278\n",
      "Recall: 0.700\n",
      "Precision: 0.174\n",
      "\n",
      "Accuracy: 0.542\n",
      "F1: 0.338\n",
      "Recall: 0.665\n",
      "Precision: 0.227\n",
      "\n",
      "Accuracy: 0.591\n",
      "F1: 0.366\n",
      "Recall: 0.671\n",
      "Precision: 0.252\n",
      "\n",
      "Accuracy: 0.362\n",
      "F1: 0.209\n",
      "Recall: 0.478\n",
      "Precision: 0.133\n",
      "\n",
      "Accuracy: 0.489\n",
      "F1: 0.101\n",
      "Recall: 0.164\n",
      "Precision: 0.073\n",
      "\n",
      "Accuracy: 0.531\n",
      "F1: 0.098\n",
      "Recall: 0.145\n",
      "Precision: 0.074\n",
      "\n",
      "Accuracy: 0.644\n",
      "F1: 0.305\n",
      "Recall: 0.444\n",
      "Precision: 0.232\n",
      "\n",
      "Accuracy: 0.560\n",
      "F1: 0.185\n",
      "Recall: 0.283\n",
      "Precision: 0.137\n",
      "\n",
      "Accuracy: 0.590\n",
      "F1: 0.285\n",
      "Recall: 0.465\n",
      "Precision: 0.206\n",
      "\n",
      "100\n",
      "Accuracy: 0.560\n",
      "F1: 0.230\n",
      "Recall: 0.373\n",
      "Precision: 0.166\n",
      "\n",
      "Accuracy: 0.445\n",
      "F1: 0.306\n",
      "Recall: 0.695\n",
      "Precision: 0.196\n",
      "\n",
      "Accuracy: 0.607\n",
      "F1: 0.388\n",
      "Recall: 0.707\n",
      "Precision: 0.267\n",
      "\n",
      "Accuracy: 0.565\n",
      "F1: 0.287\n",
      "Recall: 0.497\n",
      "Precision: 0.202\n",
      "\n",
      "Accuracy: 0.387\n",
      "F1: 0.221\n",
      "Recall: 0.494\n",
      "Precision: 0.142\n",
      "\n",
      "Accuracy: 0.361\n",
      "F1: 0.066\n",
      "Recall: 0.128\n",
      "Precision: 0.044\n",
      "\n",
      "Accuracy: 0.606\n",
      "F1: 0.389\n",
      "Recall: 0.712\n",
      "Precision: 0.268\n",
      "\n",
      "Accuracy: 0.454\n",
      "F1: 0.122\n",
      "Recall: 0.215\n",
      "Precision: 0.085\n",
      "\n",
      "Accuracy: 0.401\n",
      "F1: 0.136\n",
      "Recall: 0.268\n",
      "Precision: 0.091\n",
      "\n",
      "Accuracy: 0.411\n",
      "F1: 0.223\n",
      "Recall: 0.481\n",
      "Precision: 0.145\n",
      "\n",
      "500\n",
      "Accuracy: 0.613\n",
      "F1: 0.365\n",
      "Recall: 0.631\n",
      "Precision: 0.256\n",
      "\n",
      "Accuracy: 0.603\n",
      "F1: 0.381\n",
      "Recall: 0.694\n",
      "Precision: 0.263\n",
      "\n",
      "Accuracy: 0.612\n",
      "F1: 0.381\n",
      "Recall: 0.677\n",
      "Precision: 0.265\n",
      "\n",
      "Accuracy: 0.389\n",
      "F1: 0.158\n",
      "Recall: 0.326\n",
      "Precision: 0.104\n",
      "\n",
      "Accuracy: 0.610\n",
      "F1: 0.386\n",
      "Recall: 0.697\n",
      "Precision: 0.267\n",
      "\n",
      "Accuracy: 0.402\n",
      "F1: 0.205\n",
      "Recall: 0.439\n",
      "Precision: 0.134\n",
      "\n",
      "Accuracy: 0.611\n",
      "F1: 0.379\n",
      "Recall: 0.674\n",
      "Precision: 0.263\n",
      "\n",
      "Accuracy: 0.513\n",
      "F1: 0.264\n",
      "Recall: 0.495\n",
      "Precision: 0.180\n",
      "\n",
      "Accuracy: 0.609\n",
      "F1: 0.377\n",
      "Recall: 0.673\n",
      "Precision: 0.262\n",
      "\n",
      "Accuracy: 0.393\n",
      "F1: 0.177\n",
      "Recall: 0.370\n",
      "Precision: 0.116\n",
      "\n",
      "1000\n",
      "Accuracy: 0.834\n",
      "F1: 0.175\n",
      "Recall: 0.100\n",
      "Precision: 0.705\n",
      "\n",
      "Accuracy: 0.608\n",
      "F1: 0.371\n",
      "Recall: 0.656\n",
      "Precision: 0.258\n",
      "\n",
      "Accuracy: 0.613\n",
      "F1: 0.377\n",
      "Recall: 0.665\n",
      "Precision: 0.263\n",
      "\n",
      "Accuracy: 0.816\n",
      "F1: 0.110\n",
      "Recall: 0.064\n",
      "Precision: 0.371\n",
      "\n",
      "Accuracy: 0.812\n",
      "F1: 0.207\n",
      "Recall: 0.140\n",
      "Precision: 0.399\n",
      "\n",
      "Accuracy: 0.613\n",
      "F1: 0.184\n",
      "Recall: 0.248\n",
      "Precision: 0.147\n",
      "\n",
      "Accuracy: 0.611\n",
      "F1: 0.379\n",
      "Recall: 0.674\n",
      "Precision: 0.263\n",
      "\n",
      "Accuracy: 0.616\n",
      "F1: 0.090\n",
      "Recall: 0.108\n",
      "Precision: 0.077\n",
      "\n",
      "Accuracy: 0.612\n",
      "F1: 0.377\n",
      "Recall: 0.668\n",
      "Precision: 0.263\n",
      "\n",
      "Accuracy: 0.393\n",
      "F1: 0.179\n",
      "Recall: 0.375\n",
      "Precision: 0.117\n",
      "\n",
      "5000\n",
      "Accuracy: 0.833\n",
      "F1: 0.266\n",
      "Recall: 0.172\n",
      "Precision: 0.583\n",
      "\n",
      "Accuracy: 0.833\n",
      "F1: 0.255\n",
      "Recall: 0.162\n",
      "Precision: 0.592\n",
      "\n",
      "Accuracy: 0.834\n",
      "F1: 0.255\n",
      "Recall: 0.162\n",
      "Precision: 0.601\n",
      "\n",
      "Accuracy: 0.615\n",
      "F1: 0.089\n",
      "Recall: 0.106\n",
      "Precision: 0.076\n",
      "\n",
      "Accuracy: 0.836\n",
      "F1: 0.238\n",
      "Recall: 0.145\n",
      "Precision: 0.656\n",
      "\n",
      "Accuracy: 0.603\n",
      "F1: 0.113\n",
      "Recall: 0.144\n",
      "Precision: 0.093\n",
      "\n",
      "Accuracy: 0.837\n",
      "F1: 0.272\n",
      "Recall: 0.173\n",
      "Precision: 0.637\n",
      "\n",
      "Accuracy: 0.612\n",
      "F1: 0.083\n",
      "Recall: 0.099\n",
      "Precision: 0.071\n",
      "\n",
      "Accuracy: 0.824\n",
      "F1: 0.000\n",
      "Recall: 0.000\n",
      "Precision: 0.000\n",
      "\n",
      "Accuracy: 0.621\n",
      "F1: 0.080\n",
      "Recall: 0.093\n",
      "Precision: 0.069\n",
      "\n",
      "[100, 6, DPLabelModel(), 0.6062798634812286, 0.38898305084745766, 0.7121799844840963, 0.26756047799475374]\n",
      "CPU times: user 4h 42min 19s, sys: 4min, total: 4h 46min 20s\n",
      "Wall time: 4h 46min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best = None\n",
    "for iterations in [1, 10, 50, 100, 500, 1000, 5000]:\n",
    "    print(iterations)\n",
    "    max_seed = 10\n",
    "    temporal_models = [None,]*max_seed\n",
    "    for seed in range(max_seed):\n",
    "        markov_model = DPLabelModel(m=m_per_task*T, \n",
    "                                    T=T,\n",
    "                                    edges=[(i,i+m_per_task) for i in range((T-1)*m_per_task)],\n",
    "                                    coverage_sets=[[t,] for t in range(T) for _ in range(m_per_task)],\n",
    "                                    mu_sharing=[[t*m_per_task+i for t in range(T)] for i in range(m_per_task)],\n",
    "                                    phi_sharing=[[(t*m_per_task+i, (t+1)*m_per_task+i)\n",
    "                                                  for t in range(T-1)] for i in range(m_per_task)],\n",
    "                                    device=device,\n",
    "                                    # class_balance=MRI_data_temporal['class_balance'],\n",
    "                                    seed=seed)\n",
    "        optimize(markov_model, L_hat=MRI_data_temporal['Li_train'], num_iter=iterations,\n",
    "                 lr=1e-5, momentum=0.8, clamp=True, \n",
    "                 verbose=False, seed=seed)\n",
    "        temporal_models[seed] = markov_model\n",
    "    \n",
    "    for seed, model in enumerate(temporal_models):\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "        R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "        R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "        scores = [iterations, seed, model]\n",
    "        for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "            score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "            print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "            \n",
    "            scores.append(score)\n",
    "        \n",
    "        if best == None or scores[4] > best[4]:\n",
    "            best = scores\n",
    "        print()\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPLabelModel()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.606\n",
      "F1: 0.389\n",
      "Recall: 0.712\n",
      "Precision: 0.268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = best[2]\n",
    "Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "#find sequence label config. with highest prob.\n",
    "config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "R_pred_config = model.feasible_y[config_index]\n",
    "R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "#for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "for idx in range(R_pred_config.shape[0]):\n",
    "    R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "R_pred_probs = R_pred_probs.numpy()\n",
    "R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "#find sequence label config. with highest prob.\n",
    "config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "R_pred_config = model.feasible_y[config_index]\n",
    "R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "#for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "for idx in range(R_pred_config.shape[0]):\n",
    "    R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "R_pred_probs = R_pred_probs.numpy()\n",
    "R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "scores = [iterations, seed, model]\n",
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "if best == None or scores[4] > best[4]:\n",
    "    best = scores\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred_frame_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred_frame_label_flipped = torch.where(torch.tensor(R_pred_frame_label)==2.,torch.tensor(1.),torch.tensor(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 1., 1., 2., 2., 1., 1., 2., 2., 2., 2., 1., 1., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 1., 1., 2., 1., 1., 2., 2., 1., 1., 2., 1., 1., 2.,\n",
       "        1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        1., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 1., 1., 2., 2., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1465, 32])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred_frame.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -1, -1, -1, -1],\n",
       "        [-1,  1, -1, -1, -1],\n",
       "        [ 1, -1, -1, -1, -1],\n",
       "        [ 1,  1, -1, -1, -1],\n",
       "        [-1, -1,  1, -1, -1],\n",
       "        [-1,  1,  1, -1, -1],\n",
       "        [ 1, -1,  1, -1, -1],\n",
       "        [ 1,  1,  1, -1, -1],\n",
       "        [-1, -1, -1,  1, -1],\n",
       "        [-1,  1, -1,  1, -1],\n",
       "        [ 1, -1, -1,  1, -1],\n",
       "        [ 1,  1, -1,  1, -1],\n",
       "        [-1, -1,  1,  1, -1],\n",
       "        [-1,  1,  1,  1, -1],\n",
       "        [ 1, -1,  1,  1, -1],\n",
       "        [ 1,  1,  1,  1, -1],\n",
       "        [-1, -1, -1, -1,  1],\n",
       "        [-1,  1, -1, -1,  1],\n",
       "        [ 1, -1, -1, -1,  1],\n",
       "        [ 1,  1, -1, -1,  1],\n",
       "        [-1, -1,  1, -1,  1],\n",
       "        [-1,  1,  1, -1,  1],\n",
       "        [ 1, -1,  1, -1,  1],\n",
       "        [ 1,  1,  1, -1,  1],\n",
       "        [-1, -1, -1,  1,  1],\n",
       "        [-1,  1, -1,  1,  1],\n",
       "        [ 1, -1, -1,  1,  1],\n",
       "        [ 1,  1, -1,  1,  1],\n",
       "        [-1, -1,  1,  1,  1],\n",
       "        [-1,  1,  1,  1,  1],\n",
       "        [ 1, -1,  1,  1,  1],\n",
       "        [ 1,  1,  1,  1,  1]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feasible_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2., 2., 2., 2., 2., 2., 2., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Model Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_target = Y_dev.long()\n",
    "T = 5\n",
    "\n",
    "feasible_y = np.array([[-1, -1, -1, -1, -1],\n",
    "        [-1,  1, -1, -1, -1],\n",
    "        [ 1, -1, -1, -1, -1],\n",
    "        [ 1,  1, -1, -1, -1],\n",
    "        [-1, -1,  1, -1, -1],\n",
    "        [-1,  1,  1, -1, -1],\n",
    "        [ 1, -1,  1, -1, -1],\n",
    "        [ 1,  1,  1, -1, -1],\n",
    "        [-1, -1, -1,  1, -1],\n",
    "        [-1,  1, -1,  1, -1],\n",
    "        [ 1, -1, -1,  1, -1],\n",
    "        [ 1,  1, -1,  1, -1],\n",
    "        [-1, -1,  1,  1, -1],\n",
    "        [-1,  1,  1,  1, -1],\n",
    "        [ 1, -1,  1,  1, -1],\n",
    "        [ 1,  1,  1,  1, -1],\n",
    "        [-1, -1, -1, -1,  1],\n",
    "        [-1,  1, -1, -1,  1],\n",
    "        [ 1, -1, -1, -1,  1],\n",
    "        [ 1,  1, -1, -1,  1],\n",
    "        [-1, -1,  1, -1,  1],\n",
    "        [-1,  1,  1, -1,  1],\n",
    "        [ 1, -1,  1, -1,  1],\n",
    "        [ 1,  1,  1, -1,  1],\n",
    "        [-1, -1, -1,  1,  1],\n",
    "        [-1,  1, -1,  1,  1],\n",
    "        [ 1, -1, -1,  1,  1],\n",
    "        [ 1,  1, -1,  1,  1],\n",
    "        [-1, -1,  1,  1,  1],\n",
    "        [-1,  1,  1,  1,  1],\n",
    "        [ 1, -1,  1,  1,  1],\n",
    "        [ 1,  1,  1,  1,  1]])\n",
    "\n",
    "feasible_y[feasible_y==-1] = 0\n",
    "feasible_y = feasible_y.tolist()\n",
    "possibilities = list(map(lambda l : ''.join(map(str,l)), feasible_y))\n",
    "\n",
    "class_balance = np.empty(2 ** T)\n",
    "#compute class balance from dev set and use laplace smoothing\n",
    "\n",
    "valid_target_copy = np.copy(valid_target)\n",
    "valid_target_copy[valid_target_copy == 2] = 0\n",
    "\n",
    "assert len(valid_target_copy) % T == 0\n",
    "num_windows = len(valid_target_copy) / T\n",
    "\n",
    "freq = {}\n",
    "for i in range(0, len(valid_target_copy), T):\n",
    "    s = ''.join(map(str,valid_target_copy[i:i+T]))\n",
    "    if s in freq:\n",
    "        freq[s] += 1\n",
    "    else:\n",
    "        freq[s] = 1\n",
    "\n",
    "for i in range(len(class_balance)):\n",
    "    if possibilities[i] in freq and freq[possibilities[i]] > 5:\n",
    "        class_balance[i] = (freq[possibilities[i]] + 1) / (num_windows + len(possibilities))\n",
    "    else:\n",
    "        class_balance[i] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11000': 95,\n",
       " '00001': 91,\n",
       " '10000': 96,\n",
       " '00000': 792,\n",
       " '11001': 8,\n",
       " '01101': 16,\n",
       " '10011': 12,\n",
       " '00110': 91,\n",
       " '01100': 97,\n",
       " '00011': 94,\n",
       " '01111': 10,\n",
       " '11011': 5,\n",
       " '00111': 10,\n",
       " '01110': 4,\n",
       " '11111': 6,\n",
       " '11100': 11,\n",
       " '10001': 13,\n",
       " '10111': 1,\n",
       " '11110': 6,\n",
       " '10110': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52972612, 0.        , 0.06479626, 0.06412826, 0.        ,\n",
       "       0.06546426, 0.        , 0.00801603, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.06145625, 0.        , 0.00534402,\n",
       "       0.00467602, 0.06145625, 0.        , 0.00935204, 0.00601202,\n",
       "       0.        , 0.01135605, 0.        , 0.        , 0.06346025,\n",
       "       0.        , 0.00868403, 0.        , 0.00734803, 0.00734803,\n",
       "       0.        , 0.00467602])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.605\n",
      "F1: 0.308\n",
      "Recall: 0.500\n",
      "Precision: 0.223\n",
      "\n",
      "Accuracy: 0.684\n",
      "F1: 0.319\n",
      "Recall: 0.421\n",
      "Precision: 0.257\n",
      "\n",
      "Accuracy: 0.695\n",
      "F1: 0.356\n",
      "Recall: 0.479\n",
      "Precision: 0.283\n",
      "\n",
      "Accuracy: 0.781\n",
      "F1: 0.421\n",
      "Recall: 0.453\n",
      "Precision: 0.394\n",
      "\n",
      "Accuracy: 0.545\n",
      "F1: 0.225\n",
      "Recall: 0.375\n",
      "Precision: 0.161\n",
      "\n",
      "Accuracy: 0.426\n",
      "F1: 0.230\n",
      "Recall: 0.487\n",
      "Precision: 0.150\n",
      "\n",
      "Accuracy: 0.569\n",
      "F1: 0.218\n",
      "Recall: 0.342\n",
      "Precision: 0.160\n",
      "\n",
      "Accuracy: 0.421\n",
      "F1: 0.237\n",
      "Recall: 0.512\n",
      "Precision: 0.155\n",
      "\n",
      "Accuracy: 0.512\n",
      "F1: 0.130\n",
      "Recall: 0.207\n",
      "Precision: 0.095\n",
      "\n",
      "Accuracy: 0.666\n",
      "F1: 0.309\n",
      "Recall: 0.425\n",
      "Precision: 0.243\n",
      "\n",
      "10\n",
      "Accuracy: 0.705\n",
      "F1: 0.509\n",
      "Recall: 0.868\n",
      "Precision: 0.360\n",
      "\n",
      "Accuracy: 0.738\n",
      "F1: 0.542\n",
      "Recall: 0.879\n",
      "Precision: 0.391\n",
      "\n",
      "Accuracy: 0.694\n",
      "F1: 0.440\n",
      "Recall: 0.683\n",
      "Precision: 0.325\n",
      "\n",
      "Accuracy: 0.812\n",
      "F1: 0.594\n",
      "Recall: 0.779\n",
      "Precision: 0.479\n",
      "\n",
      "Accuracy: 0.731\n",
      "F1: 0.430\n",
      "Recall: 0.576\n",
      "Precision: 0.343\n",
      "\n",
      "Accuracy: 0.598\n",
      "F1: 0.371\n",
      "Recall: 0.673\n",
      "Precision: 0.256\n",
      "\n",
      "Accuracy: 0.610\n",
      "F1: 0.394\n",
      "Recall: 0.720\n",
      "Precision: 0.271\n",
      "\n",
      "Accuracy: 0.567\n",
      "F1: 0.348\n",
      "Recall: 0.657\n",
      "Precision: 0.237\n",
      "\n",
      "Accuracy: 0.557\n",
      "F1: 0.346\n",
      "Recall: 0.667\n",
      "Precision: 0.234\n",
      "\n",
      "Accuracy: 0.747\n",
      "F1: 0.542\n",
      "Recall: 0.853\n",
      "Precision: 0.397\n",
      "\n",
      "50\n",
      "Accuracy: 0.714\n",
      "F1: 0.455\n",
      "Recall: 0.680\n",
      "Precision: 0.342\n",
      "\n",
      "Accuracy: 0.722\n",
      "F1: 0.390\n",
      "Recall: 0.506\n",
      "Precision: 0.317\n",
      "\n",
      "Accuracy: 0.630\n",
      "F1: 0.354\n",
      "Recall: 0.577\n",
      "Precision: 0.256\n",
      "\n",
      "Accuracy: 0.814\n",
      "F1: 0.581\n",
      "Recall: 0.732\n",
      "Precision: 0.481\n",
      "\n",
      "Accuracy: 0.735\n",
      "F1: 0.390\n",
      "Recall: 0.483\n",
      "Precision: 0.328\n",
      "\n",
      "Accuracy: 0.746\n",
      "F1: 0.260\n",
      "Recall: 0.254\n",
      "Precision: 0.267\n",
      "\n",
      "Accuracy: 0.631\n",
      "F1: 0.304\n",
      "Recall: 0.458\n",
      "Precision: 0.227\n",
      "\n",
      "Accuracy: 0.536\n",
      "F1: 0.278\n",
      "Recall: 0.508\n",
      "Precision: 0.192\n",
      "\n",
      "Accuracy: 0.684\n",
      "F1: 0.157\n",
      "Recall: 0.168\n",
      "Precision: 0.148\n",
      "\n",
      "Accuracy: 0.780\n",
      "F1: 0.541\n",
      "Recall: 0.735\n",
      "Precision: 0.428\n",
      "\n",
      "100\n",
      "Accuracy: 0.724\n",
      "F1: 0.449\n",
      "Recall: 0.639\n",
      "Precision: 0.346\n",
      "\n",
      "Accuracy: 0.625\n",
      "F1: 0.269\n",
      "Recall: 0.392\n",
      "Precision: 0.204\n",
      "\n",
      "Accuracy: 0.732\n",
      "F1: 0.463\n",
      "Recall: 0.656\n",
      "Precision: 0.357\n",
      "\n",
      "Accuracy: 0.769\n",
      "F1: 0.480\n",
      "Recall: 0.606\n",
      "Precision: 0.398\n",
      "\n",
      "Accuracy: 0.706\n",
      "F1: 0.358\n",
      "Recall: 0.465\n",
      "Precision: 0.291\n",
      "\n",
      "Accuracy: 0.611\n",
      "F1: 0.189\n",
      "Recall: 0.258\n",
      "Precision: 0.149\n",
      "\n",
      "Accuracy: 0.714\n",
      "F1: 0.348\n",
      "Recall: 0.434\n",
      "Precision: 0.290\n",
      "\n",
      "Accuracy: 0.434\n",
      "F1: 0.288\n",
      "Recall: 0.652\n",
      "Precision: 0.185\n",
      "\n",
      "Accuracy: 0.650\n",
      "F1: 0.139\n",
      "Recall: 0.161\n",
      "Precision: 0.123\n",
      "\n",
      "Accuracy: 0.774\n",
      "F1: 0.515\n",
      "Recall: 0.681\n",
      "Precision: 0.414\n",
      "\n",
      "500\n",
      "Accuracy: 0.614\n",
      "F1: 0.156\n",
      "Recall: 0.203\n",
      "Precision: 0.127\n",
      "\n",
      "Accuracy: 0.642\n",
      "F1: 0.011\n",
      "Recall: 0.012\n",
      "Precision: 0.011\n",
      "\n",
      "Accuracy: 0.801\n",
      "F1: 0.482\n",
      "Recall: 0.527\n",
      "Precision: 0.445\n",
      "\n",
      "Accuracy: 0.660\n",
      "F1: 0.096\n",
      "Recall: 0.103\n",
      "Precision: 0.091\n",
      "\n",
      "Accuracy: 0.644\n",
      "F1: 0.076\n",
      "Recall: 0.084\n",
      "Precision: 0.070\n",
      "\n",
      "Accuracy: 0.692\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.725\n",
      "F1: 0.386\n",
      "Recall: 0.491\n",
      "Precision: 0.318\n",
      "\n",
      "Accuracy: 0.649\n",
      "F1: 0.006\n",
      "Recall: 0.006\n",
      "Precision: 0.006\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.662\n",
      "F1: 0.094\n",
      "Recall: 0.099\n",
      "Precision: 0.089\n",
      "\n",
      "1000\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.803\n",
      "F1: 0.481\n",
      "Recall: 0.521\n",
      "Precision: 0.448\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.692\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.781\n",
      "F1: 0.470\n",
      "Recall: 0.552\n",
      "Precision: 0.409\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.663\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "5000\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.665\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.757\n",
      "F1: 0.002\n",
      "Recall: 0.002\n",
      "Precision: 0.004\n",
      "\n",
      "Accuracy: 0.664\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.661\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.665\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.757\n",
      "F1: 0.002\n",
      "Recall: 0.002\n",
      "Precision: 0.004\n",
      "\n",
      "Accuracy: 0.667\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.664\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "Accuracy: 0.667\n",
      "F1: 0.001\n",
      "Recall: 0.001\n",
      "Precision: 0.001\n",
      "\n",
      "[1000, 6, DPLabelModel(), 0.7810238907849829, 0.47027741083223246, 0.552366175329713, 0.4094307073030477]\n",
      "CPU times: user 4h 37min 53s, sys: 4min 3s, total: 4h 41min 57s\n",
      "Wall time: 4h 41min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_class_balance = None\n",
    "for iterations in [1, 10, 50, 100, 500, 1000, 5000]:\n",
    "    print(iterations)\n",
    "    max_seed = 10\n",
    "    temporal_models = [None,]*max_seed\n",
    "    for seed in range(max_seed):\n",
    "        markov_model = DPLabelModel(m=m_per_task*T, \n",
    "                                    T=T,\n",
    "                                    edges=[(i,i+m_per_task) for i in range((T-1)*m_per_task)],\n",
    "                                    coverage_sets=[[t,] for t in range(T) for _ in range(m_per_task)],\n",
    "                                    mu_sharing=[[t*m_per_task+i for t in range(T)] for i in range(m_per_task)],\n",
    "                                    phi_sharing=[[(t*m_per_task+i, (t+1)*m_per_task+i)\n",
    "                                                  for t in range(T-1)] for i in range(m_per_task)],\n",
    "                                    device=device,\n",
    "                                    class_balance=torch.tensor(class_balance).float().to(device),\n",
    "                                    seed=seed)\n",
    "        optimize(markov_model, L_hat=MRI_data_temporal['Li_train'], num_iter=iterations,\n",
    "                 lr=1e-5, momentum=0.8, clamp=True, \n",
    "                 verbose=False, seed=seed)\n",
    "        temporal_models[seed] = markov_model\n",
    "    \n",
    "    for seed, model in enumerate(temporal_models):\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "        R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "        R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "        scores = [iterations, seed, model]\n",
    "        for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "            score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "            print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "            \n",
    "            scores.append(score)\n",
    "        \n",
    "        if best_class_balance == None or scores[4] > best[4]:\n",
    "            best_class_balance = scores\n",
    "        print()\n",
    "\n",
    "print(best_class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_best = best_class_balance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
