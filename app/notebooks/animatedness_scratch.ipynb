{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "from query.datasets.tvnews.shot_detect import shot_detect, shot_stitch\n",
    "from query.datasets.tvnews.face_detect import face_detect\n",
    "from query.datasets.tvnews.face_embed import face_embed\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "from query.datasets.tvnews.identity_detect import identity_detect\n",
    "from query.datasets.tvnews.animatedness import shot_frame_to_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "dims = json.load(open('/app/dims.json'))\n",
    "videos = list(tqdm(Video.objects.all()))\n",
    "def foo(video):\n",
    "    item = video.path.split('/')[-1].replace('.mp4', '')\n",
    "    if item in dims:\n",
    "        video.height = dims[item]\n",
    "        video.save()\n",
    "par_for(foo, videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos():\n",
    "    log.debug('Fetching videos')\n",
    "    return list(Video.objects.annotate(\n",
    "        c=Subquery(\n",
    "            Shot.objects.filter(video=OuterRef('pk')).values('video') \\\n",
    "            .annotate(c=Count('video')).values('c')\n",
    "        )).filter(c__isnull=False).order_by('id'))\n",
    "\n",
    "videos_with_shots = pcache.get('videos_with_shots', load_videos, method='pickle')\n",
    "videos = videos_with_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D 18-01-13 15:02:40 prelude.py:225] -- START: Detecting shots\n",
      "D 18-01-13 15:03:58 prelude.py:232] -- END: Detecting shots -- 00:01:17\n"
     ]
    }
   ],
   "source": [
    "with Timer('Detecting shots'):\n",
    "    all_shots = shot_detect(videos)\n",
    "    face_frame_per_shot = [[shot_frame_to_detect(shot) for shot in vid_shots]\n",
    "                           for vid_shots in all_shots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D 18-01-13 15:03:58 prelude.py:225] -- START: Detecting sparse face\n",
      "D 18-01-13 15:04:47 prelude.py:232] -- END: Detecting sparse face -- 00:00:48\n"
     ]
    }
   ],
   "source": [
    "with Timer('Detecting sparse face'):\n",
    "    all_faces = face_detect(videos, face_frame_per_shot)\n",
    "    filtered_videos, filtered_frames, filtered_faces, filtered_shots = unzip(\n",
    "        [(video, vid_frames, vid_faces, vid_shots)\n",
    "         for video, vid_frames, vid_faces, vid_shots in zip(videos, face_frame_per_shot, all_faces, all_shots)\n",
    "         if vid_faces is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_bboxes = pickle.load(open('/app/bboxes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filtered_videos[2].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Timer('Embedding faces'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30471/30471 [00:01<00:00, 22465.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def output_name(video, frames):\n",
    "    return video.path + '_embeddings_' + str(hash(tuple(frames)))\n",
    "\n",
    "with make_scanner_db() as db:\n",
    "    db._load_db_metadata()\n",
    "    \n",
    "filter2_videos, filter2_frames, filter2_faces, filter2_shots, embed_tables = unzip(\n",
    "    [(video, frames, faces, shots, db.table(output_name(video, frames)))\n",
    "          for (video, frames, faces, shots) in tqdm(zip(filtered_videos, filtered_frames, filtered_faces, filtered_shots))\n",
    "          if db.has_table(output_name(video, frames)) and db.table(output_name(video, frames)).committed()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D 18-01-12 18:12:50 prelude.py:221] -- START: Embedding faces\n",
      "D 18-01-12 18:31:44 prelude.py:228] -- END: Embedding faces -- 00:18:45\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Embedding faces\"):\n",
    "    def load_embs():\n",
    "        log.debug('Loading embs')\n",
    "        EMBEDDING_SIZE = 128\n",
    "        def load((t, vid_faces)):\n",
    "            embs = list(t.column('embeddings').load())\n",
    "            arrays = [np.frombuffer(emb, dtype=np.float32) if emb is not None else [] for _, emb in embs]\n",
    "            return [np.split(a, len(a) / 128) if len(a) > 0 else [] for a in arrays]\n",
    "        return par_for(load, zip(embed_tables, filter2_faces), workers=8)\n",
    "\n",
    "    #all_embs = pcache.get('all_embs', load_embs, method='pickle')\n",
    "\n",
    "# from query.datasets.tvnews.embed_kernel import EmbedFaceKernel\n",
    "# import query.datasets.tvnews.embed_kernel\n",
    "# reload(query.datasets.tvnews.embed_kernel)\n",
    "\n",
    "# from scannerpy.stdlib import writers\n",
    "# import cv2\n",
    "# img = cv2.imread(\"/app/test.jpg\")\n",
    "# bboxes = [\n",
    "#     db.protobufs.BoundingBox(x1=0, y1=0, x2=img.shape[1] - 1, y2=img.shape[0] - 1)\n",
    "# ]\n",
    "\n",
    "# kernel = query.datasets.tvnews.embed_kernel.EmbedFaceKernel(None, db.protobufs)\n",
    "# [emb] = kernel.execute(\n",
    "#     [cv2.cvtColor(img, cv2.COLOR_RGB2BGR),\n",
    "#      writers.bboxes([bboxes], db.protobufs)[0]])\n",
    "# exemplar_vector = np.frombuffer(emb, dtype=np.float32)\n",
    "# print(exemplar_vector.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "serializers = {}\n",
    "type_hashes = {}\n",
    "def serializer(ty):\n",
    "    def register_class(cls):\n",
    "        serializers[ty] = cls\n",
    "        type_hashes[hash(ty)] = ty\n",
    "        return cls\n",
    "    return register_class\n",
    "\n",
    "def serialize(v):\n",
    "    ty = type(v)\n",
    "    if ty in serializers:\n",
    "        serializer = serializers[ty]\n",
    "        hsh = hash(ty)\n",
    "    else:\n",
    "        serializer = DefaultSerializer\n",
    "        hsh = 0\n",
    "    return '{}{}'.format(struct.pack('=i', hsh), serializer.serialize(v))\n",
    "\n",
    "def _deserialize(s):\n",
    "    hsh, s = struct.unpack('=i', s[:4])[0], s[4:]\n",
    "    serializer = serializers[type_hashes[hsh]]\n",
    "    return serializer.deserialize(s)\n",
    "\n",
    "def deserialize(s):\n",
    "    return _deserialize(s)[0]\n",
    "    \n",
    "class DefaultSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return serialize(pickle.dumps(v))\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        ps, s = _deserialize(s)\n",
    "        return pickle.loads(ps), s\n",
    "    \n",
    "type_hashes[0] = 0    \n",
    "serializers[0] = DefaultSerializer    \n",
    "\n",
    "@serializer(int)\n",
    "class IntSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return struct.pack('=q', v)\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        return struct.unpack('=q', s[:8])[0], s[8:]\n",
    "    \n",
    "@serializer(str)    \n",
    "class StringSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return '{}{}'.format(serialize(len(v)), v)\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        n, s = _deserialize(s)\n",
    "        return s[:n], s[n:]\n",
    "\n",
    "@serializer(np.array)    \n",
    "class NumpySerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        dtype = serialize(pi)\n",
    "        n = serialize(len(v))\n",
    "        return '{}{}{}'.format(dtype, n, v.tobytes())\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        dtype, s = _deserialize(s)\n",
    "        n, s = _deserialize(s)\n",
    "        return np.frombuffer(s[:n], dtype=dtype), s[n:]\n",
    "\n",
    "@serializer(list)    \n",
    "class ListSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        n = serialize(len(v))\n",
    "        return '{}{}'.format(\n",
    "            n, ''.join([serialize(x) for x in v])\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        n, s = _deserialize(s)\n",
    "        l = []\n",
    "        for _ in range(n):\n",
    "            x, s = _deserialize(s)\n",
    "            l.append(x)\n",
    "        return l, s\n",
    "\n",
    "def test(x):\n",
    "    assert(deserialize(serialize(x)) == x)\n",
    "\n",
    "test(1)\n",
    "test(\"hello\")\n",
    "test([1, \"hello\"])\n",
    "\n",
    "# with Timer('myser'):\n",
    "#     x = serialize(all_embs[:10])\n",
    "# with Timer('mydeser'):\n",
    "#     deserialize(x)\n",
    "# with Timer('pickleser'):\n",
    "#     x = pickle.dumps(all_embs[:10])\n",
    "# with Timer('pickledeser'):\n",
    "#     pickle.loads(x)\n",
    "\n",
    "#print(len(pickle.dumps(all_embs[0])))\n",
    "#print(sum([sum([e.nbytes for e in l]) for l in all_embs[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D 18-01-13 15:05:05 prelude.py:225] -- START: Stitching shots\n",
      "D 18-01-13 15:05:58 prelude.py:232] -- END: Stitching shots -- 00:00:51\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Stitching shots\"):\n",
    "    import query.datasets.prelude\n",
    "    reload(query.datasets.prelude)\n",
    "    def load_stitches():\n",
    "        log.debug('Computing stitches')\n",
    "        import query.datasets.tvnews.shot_detect\n",
    "        reload(query.datasets.tvnews.shot_detect)\n",
    "        return query.datasets.tvnews.shot_detect.shot_stitch(filter2_videos, filter2_shots, filter2_frames, filter2_faces, all_embs)\n",
    "    (stitched_shots, stitched_indices) = query.datasets.prelude.pcache.get('stitched_shots', load_stitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/30046 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 532/30046 [00:00<00:05, 5253.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 1116/30046 [00:00<00:05, 5544.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 1599/30046 [00:00<00:05, 5304.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 2155/30046 [00:00<00:05, 5307.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 2617/30046 [00:00<00:06, 4483.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 3171/30046 [00:00<00:05, 4636.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 3780/30046 [00:00<00:05, 4784.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 4411/30046 [00:00<00:05, 4955.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 4984/30046 [00:00<00:04, 5030.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 5516/30046 [00:01<00:05, 4698.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 6113/30046 [00:01<00:05, 4781.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 6716/30046 [00:01<00:04, 4871.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 7297/30046 [00:01<00:04, 4934.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 7917/30046 [00:01<00:04, 5013.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 8482/30046 [00:01<00:04, 4775.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 9104/30046 [00:01<00:04, 4852.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 9671/30046 [00:01<00:04, 4893.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 10295/30046 [00:02<00:03, 4958.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 10876/30046 [00:02<00:03, 4996.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 11445/30046 [00:02<00:03, 4842.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 12013/30046 [00:02<00:03, 4875.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 12636/30046 [00:02<00:03, 4914.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 13216/30046 [00:02<00:03, 4946.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 13799/30046 [00:02<00:03, 4810.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 14413/30046 [00:02<00:03, 4854.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 14983/30046 [00:03<00:03, 4881.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 15602/30046 [00:03<00:02, 4923.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 16200/30046 [00:03<00:02, 4955.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 16770/30046 [00:03<00:02, 4849.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 17332/30046 [00:03<00:02, 4871.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 17987/30046 [00:03<00:02, 4905.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 18541/30046 [00:03<00:02, 4932.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 19156/30046 [00:03<00:02, 4961.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 19724/30046 [00:04<00:02, 4871.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 20323/30046 [00:04<00:01, 4896.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 20917/30046 [00:04<00:01, 4921.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 21500/30046 [00:04<00:01, 4942.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 22097/30046 [00:04<00:01, 4964.67it/s]\u001b[A\u001b[A\n",
      "\u001b[AException in thread Thread-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python2.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 22664/30046 [00:04<00:01, 4867.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 23276/30046 [00:04<00:01, 4893.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 23841/30046 [00:04<00:01, 4909.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 24475/30046 [00:04<00:01, 4938.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 25038/30046 [00:05<00:01, 4854.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 25661/30046 [00:05<00:00, 4881.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 26237/30046 [00:05<00:00, 4897.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 26843/30046 [00:05<00:00, 4912.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 27432/30046 [00:05<00:00, 4930.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 27992/30046 [00:05<00:00, 4863.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 28563/30046 [00:05<00:00, 4877.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 29166/30046 [00:05<00:00, 4894.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 29843/30046 [00:06<00:00, 4925.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 30046/30046 [00:06<00:00, 4931.90it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "def gather(l, idx):\n",
    "    return [l[i] for i in idx]\n",
    "\n",
    "def gather2(l, idx):\n",
    "    return [l[i][j] for i, j in idx]\n",
    "\n",
    "(filter3_videos, filter3_frames, filter3_faces) = unzip([\n",
    "    (video, gather(frames, idxs), gather(faces, idxs))\n",
    "    for (video, frames, faces, idxs) in tqdm(zip(filter2_videos, filter2_frames, filter2_faces,  stitched_indices))\n",
    "])\n",
    "\n",
    "# (filter3_videos, filter3_frames, filter3_faces, filter3_embs) = unzip([\n",
    "#     (video, gather(frames, idxs), gather(faces, idxs), gather(embs, idxs))\n",
    "#     for (video, frames, faces, embs, idxs) in tqdm(zip(filter2_videos, filter2_frames, filter2_faces, all_embs, stitched_indices))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D 18-01-13 15:07:18 prelude.py:225] -- START: Detecting identities\n",
      "D 18-01-13 15:07:18 prelude.py:232] -- END: Detecting identities -- 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 40341)\n"
     ]
    }
   ],
   "source": [
    "show = Show.objects.get(name='The Rachel Maddow Show').id\n",
    "indices = [i for i, video in enumerate(filter3_videos) if video.show_id == show]\n",
    "\n",
    "with Timer('Detecting identities'):\n",
    "    def load_identities():\n",
    "        log.debug('Computing identities')\n",
    "        import query.datasets.tvnews.identity_detect\n",
    "        reload(query.datasets.tvnews.identity_detect)\n",
    "\n",
    "        return query.datasets.tvnews.identity_detect.identity_detect(\n",
    "           gather(filter3_videos, indices), \"/app/rachel-maddow.jpg\", gather(filter3_embs, indices))\n",
    "    \n",
    "    matching_indices = pcache.get('matching_indices', load_identities)\n",
    "    \n",
    "print(len(matching_indices), sum([len(l) for l in matching_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_indices_onelevel = [[j for j, k in l] for l in matching_indices]\n",
    "matching_videos, matching_shots, matching_frames, matching_faces = \\\n",
    "    (gather(filter3_videos, indices),      \n",
    "    [gather(shots, idxs) for (shots, idxs) in zip(gather(stitched_shots, indices), matching_indices_onelevel)],\n",
    "    [gather(frames, idxs) for (frames, idxs) in zip(gather(filter3_frames, indices), matching_indices_onelevel)],\n",
    "    [gather(faces, idxs) for (faces, idxs) in zip(gather(filter3_faces, indices), matching_indices_onelevel)])\n",
    "    \n",
    "#pose_blacklist = ['tvnews/videos/MSNBCW_20170708_010000_The_Rachel_Maddow_Show.mp4']    \n",
    "pose_blacklist = ['tvnews/videos/MSNBCW_20170506_040000_The_Rachel_Maddow_Show.mp4']\n",
    "    \n",
    "matching2_videos, matching2_shots, matching2_frames, matching2_faces = unzip([\n",
    "    (video, shots, frames, faces)\n",
    "    for video, shots, frames, faces in zip(matching_videos, matching_shots, matching_frames, matching_faces)\n",
    "    if len(shots) > 0 and video.path not in pose_blacklist\n",
    "])\n",
    "    \n",
    "TARGET_FPS = 10\n",
    "pose_frames = [\n",
    "    sum([list(range(s['min_frame'], s['max_frame'], int(round(video.fps / TARGET_FPS)))) for s in shots], [])\n",
    "    for (video, shots) in zip(matching2_videos, matching2_shots)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [00:38<00:00, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829, 879, 829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "\n",
    "all_poses = pose_detect(matching2_videos, pose_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-a508fafbe34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtvnews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_detect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpose_track\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpose_track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching2_videos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching2_shots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching2_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_poses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/app/query/datasets/tvnews/pose_detect.py\u001b[0m in \u001b[0;36mpose_track\u001b[0;34m(videos, all_shots, all_shot_faces, all_dense_poses, force)\u001b[0m\n\u001b[1;32m    180\u001b[0m         for (video, vid_shots, vid_shot_faces, vid_dense_poses) in zip(\n\u001b[1;32m    181\u001b[0m                 videos, all_shots, all_shot_faces, all_dense_poses):\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mpose_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvid_dense_poses\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finding tracks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/query/datasets/tvnews/pose_detect.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((l,))\u001b[0m\n\u001b[1;32m    180\u001b[0m         for (video, vid_shots, vid_shot_faces, vid_dense_poses) in zip(\n\u001b[1;32m    181\u001b[0m                 videos, all_shots, all_shot_faces, all_dense_poses):\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mpose_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvid_dense_poses\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finding tracks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_track\n",
    "\n",
    "pose_track(matching2_videos, matching2_frames, matching2_shots, matching2_faces, all_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    if len(matches) == 0:\n",
    "        print(video.path)\n",
    "        return\n",
    "    make_montage(\n",
    "        video,\n",
    "        [frames[j] for j, _ in matches],\n",
    "        '/tmp/montage{}.jpg'.format(i),\n",
    "        bboxes=[[faces[j][k]] for j, k in matches],\n",
    "        progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [01:08<1:52:30, 68.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [01:24<14:18,  9.43s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/100 [01:30<10:08,  6.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/100 [01:54<10:03,  7.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 17/100 [02:06<10:16,  7.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 20/100 [02:09<08:37,  6.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvnews/videos/MSNBCW_20150721_080000_The_Rachel_Maddow_Show.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 21/100 [02:14<08:26,  6.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 24/100 [02:38<08:22,  6.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 25/100 [02:41<08:04,  6.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 27/100 [02:44<07:25,  6.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 28/100 [02:50<07:17,  6.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 32/100 [03:03<06:29,  5.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 33/100 [03:15<06:36,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 35/100 [03:24<06:20,  5.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 36/100 [03:27<06:09,  5.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 38/100 [03:46<06:08,  5.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 40/100 [03:52<05:48,  5.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 41/100 [04:05<05:52,  5.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 42/100 [04:06<05:40,  5.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 43/100 [04:22<05:47,  6.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 45/100 [04:25<05:24,  5.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvnews/videos/MSNBCW_20160901_013100_The_Rachel_Maddow_Show.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 47/100 [04:26<05:00,  5.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 48/100 [04:39<05:02,  5.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvnews/videos/MSNBCW_20170527_230000_The_Rachel_Maddow_Show.mp4\n",
      "tvnews/videos/MSNBCW_20160813_010000_The_Rachel_Maddow_Show.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 49/100 [04:52<05:04,  5.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 51/100 [05:30<05:17,  6.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 60/100 [05:37<03:44,  5.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 61/100 [05:47<03:41,  5.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 63/100 [05:49<03:25,  5.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 64/100 [05:49<03:16,  5.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 65/100 [06:03<03:15,  5.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 66/100 [06:04<03:07,  5.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 67/100 [06:14<03:04,  5.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 68/100 [06:21<02:59,  5.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 70/100 [06:43<02:52,  5.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 72/100 [06:45<02:37,  5.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 73/100 [06:54<02:33,  5.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 75/100 [07:06<02:22,  5.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 76/100 [07:10<02:15,  5.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 77/100 [07:14<02:09,  5.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 79/100 [07:26<01:58,  5.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 80/100 [07:43<01:55,  5.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 83/100 [07:49<01:36,  5.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 84/100 [07:59<01:31,  5.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 86/100 [07:59<01:18,  5.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 87/100 [08:18<01:14,  5.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 89/100 [08:28<01:02,  5.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 91/100 [08:42<00:51,  5.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 92/100 [08:51<00:46,  5.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 96/100 [08:54<00:22,  5.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 97/100 [09:05<00:16,  5.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 98/100 [09:11<00:11,  5.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 99/100 [09:14<00:05,  5.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 100/100 [09:16<00:00,  5.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "\n",
    "# make_montage(filter3_videos[indices[i]], filter3_frames[indices[i]],\n",
    "#              '/app/montage.jpg', filter3_faces[indices[i]], workers=96, progress=True)\n",
    "\n",
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    try:\n",
    "        if len(matches) == 0:\n",
    "            print(video.path)\n",
    "            return\n",
    "        bbox_map = defaultdict(list, {j: [faces[j][k]] for j, k in matches})\n",
    "        make_montage(\n",
    "            video,\n",
    "            #[frames[j] for j, _ in matches],\n",
    "            frames,\n",
    "            '/tmp/montage{}.jpg'.format(i),\n",
    "            bboxes=[bbox_map[i] for i in range(len(frames))],\n",
    "            #bboxes=[[faces[j][k]] for j, k in matches],\n",
    "            progress=False)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        print(video.path)\n",
    "    \n",
    "_ = par_for(bbox_montage,\n",
    "        list(enumerate(zip(gather(filter3_videos, indices)[:100], gather(filter3_frames, indices), \n",
    "            gather(filter3_faces, indices), matching_indices))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "\n",
    "par_for(make_montage,\n",
    "        list(enumerate(zip(filter2_videos, [[s['min_frame'] for s in l] for l in stitched_shots][:100]))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shot.objects.bulk_create_copy({\n",
    "    'min_frame': shot['min_frame'], \n",
    "    'max_frame': shot['max_frame'], \n",
    "    'labeler_id': shot['labeler'],\n",
    "    'video_id': shot['video__id']\n",
    "} for shot_list in tqdm(stitched_shots) for shot in shot_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
