{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T20:35:23.463663Z",
     "start_time": "2019-03-05T20:35:23.411761Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from esper.prelude import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.temporal_predicates import *\n",
    "from esper.rekall import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import OrderedDict\n",
    "import scannertools as st\n",
    "\n",
    "import esper.shot_detection_torch.models.deepsbd_resnet as deepsbd_resnet\n",
    "import esper.shot_detection_torch.models.deepsbd_alexnet as deepsbd_alexnet\n",
    "import esper.shot_detection_torch.dataloaders.movies_deepsbd as movies_deepsbd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:46.451762Z",
     "start_time": "2019-03-04T06:51:46.410571Z"
    }
   },
   "outputs": [],
   "source": [
    "st.init_storage(os.environ['BUCKET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:47.164922Z",
     "start_time": "2019-03-04T06:51:47.123813Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct five folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:50.197617Z",
     "start_time": "2019-03-04T06:51:50.155561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load up all manually annotated shots\n",
    "shots_qs = Shot.objects.filter(labeler__name__contains='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:51.071373Z",
     "start_time": "2019-03-04T06:51:50.820736Z"
    }
   },
   "outputs": [],
   "source": [
    "shots = VideoIntervalCollection.from_django_qs(shots_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:51.991433Z",
     "start_time": "2019-03-04T06:51:51.946551Z"
    }
   },
   "outputs": [],
   "source": [
    "video_ids = sorted(list(shots.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:52.730837Z",
     "start_time": "2019-03-04T06:51:52.689715Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:54.224704Z",
     "start_time": "2019-03-04T06:51:54.184915Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly shuffle video IDs\n",
    "random.shuffle(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T00:14:05.892314Z",
     "start_time": "2019-02-26T00:14:05.849502Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct five folds\n",
    "total_shots = shots_qs.count()\n",
    "folds = []\n",
    "num_shots_in_folds = 0\n",
    "cur_fold = []\n",
    "for video_id in video_ids:\n",
    "    if num_shots_in_folds + shots.get_intervallist(video_id).size() > (len(folds) + 1) * total_shots / 5:\n",
    "        folds.append(cur_fold)\n",
    "        cur_fold = []\n",
    "    num_shots_in_folds += shots.get_intervallist(video_id).size()\n",
    "    cur_fold.append(video_id)\n",
    "folds.append(cur_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T00:16:31.786762Z",
     "start_time": "2019-02-26T00:16:31.750347Z"
    }
   },
   "outputs": [],
   "source": [
    "# store folds\n",
    "with open('/app/data/shot_detection_folds.pkl', 'wb') as f:\n",
    "    pickle.dump(folds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T20:56:47.633288Z",
     "start_time": "2019-03-05T20:56:47.593697Z"
    }
   },
   "outputs": [],
   "source": [
    "# or load folds from disk\n",
    "with open('/app/data/shot_detection_folds.pkl', 'rb') as f:\n",
    "    folds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:51:58.847540Z",
     "start_time": "2019-03-04T06:51:58.801883Z"
    }
   },
   "outputs": [],
   "source": [
    "# store shot intervals in pickle file\n",
    "with open('/app/data/manually_annotated_shots.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        video_id: [\n",
    "            (interval.start, interval.end, interval.payload)\n",
    "            for interval in shots.get_intervallist(video_id).get_intervals()\n",
    "        ]\n",
    "        for video_id in shots.get_allintervals()\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:54:35.362470Z",
     "start_time": "2019-03-04T06:54:35.315969Z"
    }
   },
   "outputs": [],
   "source": [
    "clips = shots.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T06:54:37.792811Z",
     "start_time": "2019-03-04T06:54:36.627337Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shots_qs = Shot.objects.filter(cinematic=True, video_id__in=video_ids).all()\n",
    "cinematic_shots = VideoIntervalCollection.from_django_qs(\n",
    "    cinematic_shots_qs,\n",
    "    progress = True\n",
    ").filter_against(clips, predicate=overlaps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:06:01.904479Z",
     "start_time": "2019-03-04T07:06:01.818764Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shot_boundaries = cinematic_shots.map(lambda i: (i.start, i.start, i.payload)).set_union(\n",
    "    cinematic_shots.map(lambda i: (i.end + 1, i.end + 1, i.payload))\n",
    ").coalesce()\n",
    "gt_shot_boundaries = shots.map(lambda i: (i.start, i.start, i.payload)).set_union(\n",
    "    shots.map(lambda i: (i.end + 1, i.end + 1, i.payload))\n",
    ").coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T07:06:03.914349Z",
     "start_time": "2019-03-04T07:06:03.636981Z"
    }
   },
   "outputs": [],
   "source": [
    "for fold in folds:\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for video_id in fold:\n",
    "        cine_sb = cinematic_shot_boundaries.get_intervallist(video_id)\n",
    "        gt_sb = gt_shot_boundaries.get_intervallist(video_id)\n",
    "        \n",
    "        accurate_sb = cine_sb.filter_against(gt_sb, predicate=overlaps())\n",
    "        inaccurate_sb = cine_sb.minus(accurate_sb)\n",
    "\n",
    "        found_human_sb = gt_sb.filter_against(cine_sb, predicate=overlaps())\n",
    "        missed_human_sb = gt_sb.minus(found_human_sb)\n",
    "        \n",
    "        tp += accurate_sb.size()\n",
    "        fp += inaccurate_sb.size()\n",
    "        fn += missed_human_sb.size()\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print('Precision: {}, {} out of {}'.format(\n",
    "        precision,\n",
    "        tp,\n",
    "        tp + fp\n",
    "    ))\n",
    "    print('Recall: {}, {} out of {}'.format(\n",
    "        recall,\n",
    "        tp,\n",
    "        tp + fn\n",
    "    ))\n",
    "    print('F1: {}'.format(2 * precision * recall / (precision + recall)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristics:\n",
    "* Fold 1:\n",
    "  * Precision: 0.8512396694214877, 103 out of 121\n",
    "  * Recall: 0.8373983739837398, 103 out of 123\n",
    "  * F1: 0.8442622950819672\n",
    "* Fold 2:\n",
    "  * Precision: 0.948051948051948, 73 out of 77\n",
    "  * Recall: 0.7448979591836735, 73 out of 98\n",
    "  * F1: 0.8342857142857143\n",
    "* Fold 3:\n",
    "  * Precision: 0.8829787234042553, 166 out of 188\n",
    "  * Recall: 0.9431818181818182, 166 out of 176\n",
    "  * F1: 0.9120879120879122\n",
    "* Fold 4:\n",
    "  * Precision: 0.8571428571428571, 78 out of 91\n",
    "  * Recall: 0.7878787878787878, 78 out of 99\n",
    "  * F1: 0.8210526315789474\n",
    "* Fold 5:\n",
    "  * Precision: 0.9090909090909091, 110 out of 121\n",
    "  * Recall: 0.8396946564885496, 110 out of 131\n",
    "  * F1: 0.873015873015873\n",
    "\n",
    "Average F1: .857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:20:42.334536Z",
     "start_time": "2019-03-04T23:20:42.280810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Heuristic, window version\n",
    "stride = 8\n",
    "window_size = 16\n",
    "clips_window = shots.dilate(1).coalesce().dilate(-1).map(\n",
    "    lambda intrvl: (\n",
    "        intrvl.start - stride - ((intrvl.start - stride) % stride),\n",
    "        intrvl.end + stride - ((intrvl.end - stride) % stride),\n",
    "        intrvl.payload\n",
    "    )\n",
    ").dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:25:27.375363Z",
     "start_time": "2019-03-04T23:25:25.682196Z"
    }
   },
   "outputs": [],
   "source": [
    "items_intrvls = {}\n",
    "for video_id in clips_window.get_allintervals():\n",
    "    items_intrvls[video_id] = []\n",
    "    for intrvl in clips_window.get_intervallist(video_id).get_intervals():\n",
    "        items_intrvls[video_id] += [\n",
    "            (f, f + window_size, 0)\n",
    "            for f in range(intrvl.start, intrvl.end - stride, stride)\n",
    "        ]\n",
    "items_col = VideoIntervalCollection(items_intrvls)\n",
    "\n",
    "items_w_gt_boundaries = items_col.filter_against(\n",
    "    gt_shot_boundaries,\n",
    "    predicate=during_inv()\n",
    ").map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.end, 2)\n",
    ")\n",
    "\n",
    "items_w_gt_labels = items_col.minus(\n",
    "    items_w_gt_boundaries, predicate=equal()\n",
    ").set_union(items_w_gt_boundaries)\n",
    "\n",
    "items_w_cinematic_boundaries = items_col.filter_against(\n",
    "    cinematic_shot_boundaries,\n",
    "    predicate=during_inv()\n",
    ").map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.end, 2)\n",
    ")\n",
    "\n",
    "items_w_cinematic_labels = items_col.minus(\n",
    "    items_w_cinematic_boundaries, predicate=equal()\n",
    ").set_union(items_w_cinematic_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:37:42.387075Z",
     "start_time": "2019-03-04T23:37:42.315513Z"
    }
   },
   "outputs": [],
   "source": [
    "for fold in folds:\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for video_id in fold:\n",
    "        cine_items = items_w_cinematic_labels.get_intervallist(video_id)\n",
    "        gt_items = items_w_gt_labels.get_intervallist(video_id)\n",
    "        \n",
    "        for cine_item, gt_item in zip(cine_items.get_intervals(), gt_items.get_intervals()):\n",
    "            if cine_item.payload == gt_item.payload:\n",
    "                if cine_item.payload == 2:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if cine_item.payload == 2:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print('Precision: {}, {} out of {}'.format(\n",
    "        precision,\n",
    "        tp,\n",
    "        tp + fp\n",
    "    ))\n",
    "    print('Recall: {}, {} out of {}'.format(\n",
    "        recall,\n",
    "        tp,\n",
    "        tp + fn\n",
    "    ))\n",
    "    print('F1: {}'.format(2 * precision * recall / (precision + recall)))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(tp, tn, fp, fn))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Precision: 0.8916666666666667, 214 out of 240\n",
    "Recall: 0.8629032258064516, 214 out of 248\n",
    "F1: 0.8770491803278689\n",
    "TP: 214 TN: 1321 FP: 26 FN: 34\n",
    "\n",
    "Precision: 0.972027972027972, 139 out of 143\n",
    "Recall: 0.7473118279569892, 139 out of 186\n",
    "F1: 0.844984802431611\n",
    "TP: 139 TN: 328 FP: 4 FN: 47\n",
    "\n",
    "Precision: 0.8919667590027701, 322 out of 361\n",
    "Recall: 0.9817073170731707, 322 out of 328\n",
    "F1: 0.9346879535558781\n",
    "TP: 322 TN: 2297 FP: 39 FN: 6\n",
    "\n",
    "Precision: 0.8802395209580839, 147 out of 167\n",
    "Recall: 0.8032786885245902, 147 out of 183\n",
    "F1: 0.84\n",
    "TP: 147 TN: 900 FP: 20 FN: 36\n",
    "\n",
    "Precision: 0.9184549356223176, 214 out of 233\n",
    "Recall: 0.852589641434263, 214 out of 251\n",
    "F1: 0.8842975206611571\n",
    "TP: 214 TN: 1148 FP: 19 FN: 37\n",
    "\n",
    "Average F1: 0.876\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSBD Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:56:00.802810Z",
     "start_time": "2019-02-26T23:56:00.703532Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions for deepsbd testing\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "\n",
    "    return n_correct_elems / batch_size\n",
    "\n",
    "def prf1_array(pos_label, neg_label, gt, preds):\n",
    "    tp = 0.\n",
    "    fp = 0.\n",
    "    tn = 0.\n",
    "    fn = 0.\n",
    "    \n",
    "    for truth, pred in zip(gt, preds):\n",
    "        if truth == pred:\n",
    "            if pred == pos_label:\n",
    "                tp += 1.\n",
    "            else:\n",
    "                tn += 1.\n",
    "        else:\n",
    "            if pred == pos_label:\n",
    "                fp += 1.\n",
    "            else:\n",
    "                fn += 1.\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "    \n",
    "    return (precision, recall, f1, tp, tn, fp, fn)\n",
    "\n",
    "def get_label(res_tensor):\n",
    "    res_numpy=res_tensor.data.cpu().numpy()\n",
    "    labels=[]\n",
    "    for row in res_numpy:\n",
    "        labels.append(np.argmax(row))\n",
    "    return labels\n",
    "\n",
    "def test_deepsbd(model, dataloader):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    outputs = []\n",
    "    for clip_tensor, l, _ in tqdm(dataloader):\n",
    "        o = model(clip_tensor.to(device))\n",
    "\n",
    "        preds += get_label(o)\n",
    "        labels += l.data.numpy().tolist()\n",
    "        outputs += o.cpu().data.numpy().tolist()\n",
    "    \n",
    "    preds = [2 if p == 2 else 0 for p in preds]\n",
    "        \n",
    "    precision, recall, f1, tp, tn, fp, fn = prf1_array(2, 0, labels, preds)\n",
    "    print(\"Precision: {}, Recall: {}, F1: {}\".format(precision, recall, f1))\n",
    "    print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(tp, tn, fp, fn))\n",
    "    \n",
    "    return preds, labels, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:10:05.580943Z",
     "start_time": "2019-02-26T23:56:02.633348Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load DeepSBD datasets for each fold\n",
    "deepsbd_datasets = []\n",
    "for fold in folds:\n",
    "    shots_in_fold_qs = Shot.objects.filter(\n",
    "        labeler__name__contains='manual',\n",
    "        video_id__in = fold\n",
    "    )\n",
    "    shots_in_fold = VideoIntervalCollection.from_django_qs(shots_in_fold_qs)\n",
    "    \n",
    "    data = movies_deepsbd_data.DeepSBDDataset(shots_in_fold, verbose=True)\n",
    "    deepsbd_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:10:40.062190Z",
     "start_time": "2019-02-27T00:10:39.978085Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset to hold multiple folds\n",
    "class DeepSBDTrainDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum(len(d) for d in self.datasets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for d in self.datasets:\n",
    "            if idx < len(d):\n",
    "                return d[idx]\n",
    "            else:\n",
    "                idx -= len(d)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def weights_for_balanced_classes(self):\n",
    "        labels = [\n",
    "            item[3]\n",
    "            for d in self.datasets\n",
    "            for item in d.items\n",
    "        ]\n",
    "        \n",
    "        class_counts = {}\n",
    "        for l in labels:\n",
    "            if l not in class_counts:\n",
    "                class_counts[l] = 1\n",
    "            else:\n",
    "                class_counts[l] += 1\n",
    "        \n",
    "        weights_per_class = {\n",
    "            l: len(labels) / class_counts[l]\n",
    "            for l in class_counts\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            weights_per_class[l]\n",
    "            for l in labels\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:13:34.230348Z",
     "start_time": "2019-02-27T00:13:31.847515Z"
    }
   },
   "outputs": [],
   "source": [
    "# models\n",
    "deepsbd_alexnet_model = deepsbd_alexnet.deepSBD()\n",
    "deepsbd_resnet_model = deepsbd_resnet.resnet18(num_classes=3,\n",
    "    sample_size=128,\n",
    "    sample_duration=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:24:52.857321Z",
     "start_time": "2019-02-26T23:24:51.310594Z"
    }
   },
   "outputs": [],
   "source": [
    "# alexnet deepSBD pre-trained on ClipShots\n",
    "alexnet_state_dict = torch.load('models/ClipShots-DeepSBD-Alexnet-final.pth')['state_dict']\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in alexnet_state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "deepsbd_alexnet_model.load_state_dict(new_state_dict)\n",
    "# deepsbd_alexnet_model = deepsbd_alexnet_model.to(device)\n",
    "# deepsbd_alexnet_model = deepsbd_alexnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:40.671868Z",
     "start_time": "2019-02-27T01:06:40.430232Z"
    }
   },
   "outputs": [],
   "source": [
    "# resnet deepSBD pre-trained on ClipShots\n",
    "resnet_state_dict = torch.load('models/ClipShots-DeepSBD-Resnet-18-final.pth')['state_dict']\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in resnet_state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "deepsbd_resnet_model.load_state_dict(new_state_dict)\n",
    "# deepsbd_resnet_model = deepsbd_resnet_model.to(device)\n",
    "deepsbd_resnet_model = deepsbd_resnet_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:42:51.007754Z",
     "start_time": "2019-02-26T23:42:50.133193Z"
    }
   },
   "outputs": [],
   "source": [
    "# resnet deepSBD pre-trained on Kinetics\n",
    "deepsbd_resnet_model_no_clipshots = deepsbd_resnet.resnet18(\n",
    "    num_classes=3,\n",
    "    sample_size=128,\n",
    "    sample_duration=16\n",
    ")\n",
    "deepsbd_resnet_model_no_clipshots.load_weights('models/resnet-18-kinetics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T19:01:29.065038Z",
     "start_time": "2019-02-26T19:01:27.125839Z"
    }
   },
   "outputs": [],
   "source": [
    "# alexnet deepSBD\n",
    "deepsbd_alexnet_model_no_clipshots = deepsbd_alexnet.deepSBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:42:54.692619Z",
     "start_time": "2019-02-26T23:42:54.613440Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model_no_clipshots = deepsbd_resnet_model_no_clipshots.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:53.271120Z",
     "start_time": "2019-02-27T01:06:53.231195Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset_fold1 = DeepSBDTrainDataset(deepsbd_datasets[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:54.415504Z",
     "start_time": "2019-02-27T01:06:54.374238Z"
    }
   },
   "outputs": [],
   "source": [
    "fold1_weights = torch.DoubleTensor(training_dataset_fold1.weights_for_balanced_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:54.981209Z",
     "start_time": "2019-02-27T01:06:54.942867Z"
    }
   },
   "outputs": [],
   "source": [
    "fold1_sampler = torch.utils.data.sampler.WeightedRandomSampler(fold1_weights, len(fold1_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:55.522403Z",
     "start_time": "2019-02-27T01:06:55.486707Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataloader_fold1 = DataLoader(\n",
    "    training_dataset_fold1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    sampler=fold1_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:56.197536Z",
     "start_time": "2019-02-27T01:06:56.158997Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:57.360665Z",
     "start_time": "2019-02-27T01:06:57.319320Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(deepsbd_resnet_model.parameters(), \n",
    "                      lr=.001, momentum=.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:06:58.190490Z",
     "start_time": "2019-02-27T01:06:58.151793Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:07:02.930245Z",
     "start_time": "2019-02-27T01:07:02.857572Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch, training_dataloader, model, criterion, optimizer, scheduler):\n",
    "    iter_len = len(training_dataloader)\n",
    "    training_iter = iter(training_dataloader)\n",
    "    \n",
    "    for i in range(iter_len):\n",
    "        clip_tensor, targets, _ = next(training_iter)\n",
    "        \n",
    "        outputs = model(clip_tensor.to(device))\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        acc = calculate_accuracy(outputs, targets)\n",
    "        preds = get_label(outputs)\n",
    "        preds = [2 if p == 2 else 0 for p in preds]\n",
    "        precision, recall, f1, tp, tn, fp, fn = prf1_array(\n",
    "            2, 0, targets.cpu().data.numpy().tolist(), preds)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Loss_conf {loss_c:.4f}\\t'\n",
    "              'acc {acc:.4f}\\t'\n",
    "              'pre {pre:.4f}\\t'\n",
    "              'rec {rec:.4f}\\t'\n",
    "              'f1 {f1: .4f}\\t'\n",
    "              'TP {tp} '\n",
    "              'TN {tn} '\n",
    "              'FP {fp} '\n",
    "              'FN {fn} '\n",
    "              .format(\n",
    "                  epoch, i + 1, iter_len, loss_c=loss.item(), acc=acc,\n",
    "                  pre=precision, rec=recall, f1=f1,\n",
    "                  tp=tp, tn=tn, fp=fp, fn=fn))\n",
    "    \n",
    "    save_file_path = os.path.join(\n",
    "        '/app/notebooks/learning/models/deepsbd_resnet_clipshots_pretrain_train_on_folds',\n",
    "        'fold5_{}_epoch.pth'.format(epoch)\n",
    "    )\n",
    "    states = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(states, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:37:18.535587Z",
     "start_time": "2019-02-26T23:37:18.319803Z"
    }
   },
   "outputs": [],
   "source": [
    "state = torch.load('models/deepsbd_resnet_train_on_folds/fold4_4_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:37:19.299560Z",
     "start_time": "2019-02-26T23:37:19.253950Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model_no_clipshots.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:15:12.317101Z",
     "start_time": "2019-02-27T01:07:05.506397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    train_epoch(i, training_dataloader_fold1, deepsbd_resnet_model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialize pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:38:13.338372Z",
     "start_time": "2019-02-26T23:38:12.164466Z"
    }
   },
   "outputs": [],
   "source": [
    "# test models on splits\n",
    "model = deepsbd_resnet_model.to(device).eval()\n",
    "per_fold_preds_labels_outputs = []\n",
    "for fold_dataset in deepsbd_datasets:\n",
    "    dataloader = DataLoader(fold_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    preds, labels, outputs = test_deepsbd(model, dataloader)\n",
    "    \n",
    "    per_fold_preds_labels_outputs.append((preds, labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T08:00:44.594063Z",
     "start_time": "2019-02-26T08:00:04.950514Z"
    }
   },
   "outputs": [],
   "source": [
    "# test models on splits\n",
    "model = deepsbd_alexnet_model.to(device).eval()\n",
    "per_fold_preds_labels_outputs_alexnet = []\n",
    "for fold_dataset in deepsbd_datasets:\n",
    "    dataloader = DataLoader(fold_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    preds, labels, outputs = test_deepsbd(model, dataloader)\n",
    "    \n",
    "    per_fold_preds_labels_outputs.append((preds, labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:16:18.567786Z",
     "start_time": "2019-02-27T01:16:06.256494Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = deepsbd_resnet_model.eval()\n",
    "per_fold_preds_labels_outputs_fold_training_only = []\n",
    "for fold_dataset in deepsbd_datasets[4:]:\n",
    "    dataloader = DataLoader(fold_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    preds, labels, outputs = test_deepsbd(model, dataloader)\n",
    "    \n",
    "    per_fold_preds_labels_outputs_fold_training_only.append((preds, labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T20:22:54.258954Z",
     "start_time": "2019-02-26T20:22:40.479084Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/resnet-18-kinetics.pth')\n",
    "per_fold_preds_labels_outputs_fold_training_only = []\n",
    "for fold_dataset in deepsbd_datasets[:1]:\n",
    "    dataloader = DataLoader(fold_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    preds, labels, outputs = test_deepsbd(model, dataloader)\n",
    "    \n",
    "    per_fold_preds_labels_outputs_fold_training_only.append((preds, labels, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSBD, ResNet18 backbone trained on ClipShots:\n",
    "* Fold 1\n",
    "  * Precision: 0.8636363636363636, Recall: 0.9620253164556962, F1: 0.9101796407185629\n",
    "  * TP: 228.0, TN: 1322.0, FP: 36.0, FN: 9.0\n",
    "* Fold 2\n",
    "  * Precision: 0.8934010152284264, Recall: 0.9617486338797814, F1: 0.9263157894736842\n",
    "  * TP: 176.0, TN: 314.0, FP: 21.0, FN: 7.0\n",
    "* Fold 3\n",
    "  * Precision: 0.7666666666666667, Recall: 0.8263473053892215, F1: 0.7953890489913544\n",
    "  * TP: 276.0, TN: 2246.0, FP: 84.0, FN: 58.0\n",
    "* Fold 4\n",
    "  * Precision: 0.8960396039603961, Recall: 1.0, F1: 0.9451697127937337\n",
    "  * TP: 181.0, TN: 901.0, FP: 21.0, FN: 0.0\n",
    "* Fold 5\n",
    "  * Precision: 0.8571428571428571, Recall: 0.9831932773109243, F1: 0.9158512720156555\n",
    "  * TP: 234.0, TN: 1141.0, FP: 39.0, FN: 4.0\n",
    "\n",
    "Average F1: .898\n",
    "\n",
    "DeepSBD, AlexNet backbone trained on ClipShots:\n",
    "* Fold 1\n",
    "  * Precision: 0.8507462686567164, Recall: 0.9620253164556962, F1: 0.902970297029703\n",
    "  * TP: 228.0, TN: 1318.0, FP: 40.0, FN: 9.0\n",
    "* Fold 2\n",
    "  * Precision: 0.912568306010929, Recall: 0.912568306010929, F1: 0.912568306010929\n",
    "  * TP: 167.0, TN: 319.0, FP: 16.0, FN: 16.0\n",
    "* Fold 3\n",
    "  * Precision: 0.7818696883852692, Recall: 0.8263473053892215, F1: 0.8034934497816594\n",
    "  * TP: 276.0, TN: 2253.0, FP: 77.0, FN: 58.0\n",
    "* Fold 4\n",
    "  * Precision: 0.9782608695652174, Recall: 0.994475138121547, F1: 0.9863013698630136\n",
    "  * TP: 180.0, TN: 918.0, FP: 4.0, FN: 1.0\n",
    "* Fold 5\n",
    "  * Precision: 0.8669201520912547, Recall: 0.957983193277311, F1: 0.9101796407185628\n",
    "  * TP: 228.0, TN: 1145.0, FP: 35.0, FN: 10.0\n",
    "  \n",
    "Average F1: .903\n",
    "  \n",
    "DeepSBD, ResNet18 backbone trained on folds only:\n",
    "* Fold 1\n",
    "  * Precision: 0.7737226277372263, Recall: 0.8945147679324894, F1: 0.8297455968688846\n",
    "  * TP: 212.0, TN: 1296.0, FP: 62.0, FN: 25.0\n",
    "* Fold 2\n",
    "  * Precision: 0.8165680473372781, Recall: 0.7540983606557377, F1: 0.7840909090909091\n",
    "  * TP: 138.0, TN: 304.0, FP: 31.0, FN: 45.0\n",
    "* Fold 3\n",
    "  * Precision: 0.7407407407407407, Recall: 0.718562874251497, F1: 0.7294832826747719\n",
    "  * TP: 240.0, TN: 2246.0, FP: 84.0, FN: 94.0\n",
    "* Fold 4\n",
    "  * Precision: 0.7990196078431373, Recall: 0.9005524861878453, F1: 0.8467532467532468\n",
    "  * TP: 163.0, TN: 881.0, FP: 41.0, FN: 18.0\n",
    "* Fold 5\n",
    "  * Precision: 0.8057851239669421, Recall: 0.819327731092437, F1: 0.8125\n",
    "  * TP: 195.0, TN: 1133.0, FP: 47.0, FN: 43.0\n",
    "  \n",
    "Average F1: .801\n",
    "\n",
    "DeepSBD, ResNet18 backbone pre-trained on ClipShots, and then trained on folds:\n",
    "* Fold 1\n",
    "  * Precision: 0.7482758620689656, Recall: 0.9156118143459916, F1: 0.823529411764706\n",
    "  * TP: 217.0, TN: 1285.0, FP: 73.0, FN: 20.0\n",
    "* Fold 2\n",
    "  * Precision: 0.8685714285714285, Recall: 0.8306010928961749, F1: 0.8491620111731845\n",
    "  * TP: 152.0, TN: 312.0, FP: 23.0, FN: 31.0\n",
    "* Fold 3\n",
    "  * Precision: 0.8092105263157895, Recall: 0.7365269461077845, F1: 0.7711598746081504\n",
    "  * TP: 246.0, TN: 2272.0, FP: 58.0, FN: 88.0\n",
    "* Fold 4\n",
    "  * Precision: 0.9344262295081968, Recall: 0.9447513812154696, F1: 0.9395604395604397\n",
    "  * TP: 171.0, TN: 910.0, FP: 12.0, FN: 10.0\n",
    "* Fold 5\n",
    "  * Precision: 0.8771186440677966, Recall: 0.8697478991596639, F1: 0.8734177215189872\n",
    "  * TP: 207.0, TN: 1151.0, FP: 29.0, FN: 31.0\n",
    "  \n",
    "Average F1: .851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:53:31.507055Z",
     "start_time": "2019-03-05T22:28:11.414875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load DeepSBD datasets for each fold\n",
    "deepsbd_datasets_logits = []\n",
    "for fold in folds:\n",
    "    shots_in_fold_qs = Shot.objects.filter(\n",
    "        labeler__name__contains='manual',\n",
    "        video_id__in = fold\n",
    "    )\n",
    "    shots_in_fold = VideoIntervalCollection.from_django_qs(shots_in_fold_qs)\n",
    "    \n",
    "    data = movies_deepsbd_data.DeepSBDDataset(shots_in_fold, verbose=True, preload=True, logits=True)\n",
    "    deepsbd_datasets_logits.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:53:44.372479Z",
     "start_time": "2019-03-05T22:53:44.215756Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_datasets_logits[0].items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:08:57.836593Z",
     "start_time": "2019-03-05T21:08:04.136533Z"
    }
   },
   "outputs": [],
   "source": [
    "# load weak labels\n",
    "with open('/app/data/shot_detection_weak_labels/noisy_labels_all_windows.npy', 'rb') as f:\n",
    "    weak_labels_windows = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:09:26.115512Z",
     "start_time": "2019-03-05T21:09:26.053519Z"
    }
   },
   "outputs": [],
   "source": [
    "weak_labels_windows[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:16:14.749900Z",
     "start_time": "2019-03-05T21:16:14.708743Z"
    }
   },
   "outputs": [],
   "source": [
    "weak_labels_windows[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:17:42.227095Z",
     "start_time": "2019-03-05T21:17:36.470452Z"
    }
   },
   "outputs": [],
   "source": [
    "weak_labels_collected = collect(\n",
    "    weak_labels_windows,\n",
    "    lambda row: row[0][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:22:20.539280Z",
     "start_time": "2019-03-05T21:21:42.654983Z"
    }
   },
   "outputs": [],
   "source": [
    "weak_labels_col = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (row[0][1] ,row[0][2], row[1])\n",
    "        for row in weak_labels_collected[video_id]\n",
    "    ]\n",
    "    for video_id in tqdm(list(weak_labels_collected.keys()))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:30:05.758111Z",
     "start_time": "2019-03-05T21:30:05.720363Z"
    }
   },
   "outputs": [],
   "source": [
    "def weak_payload_to_logits(weak_payload):\n",
    "    return (weak_payload[1], 0., weak_payload[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:54:04.460754Z",
     "start_time": "2019-03-05T22:54:03.375646Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_datasets_weak = []\n",
    "for dataset in deepsbd_datasets_logits:\n",
    "    items_collected = collect(\n",
    "        dataset.items,\n",
    "        lambda item: item[0]\n",
    "    )\n",
    "    items_col = VideoIntervalCollection({\n",
    "        video_id: [\n",
    "            (item[1], item[2], item[3])\n",
    "            for item in items_collected[video_id]\n",
    "        ]\n",
    "        for video_id in items_collected\n",
    "    })\n",
    "    \n",
    "    new_items = weak_labels_col.join(\n",
    "        items_col,\n",
    "        predicate=equal(),\n",
    "        working_window=1,\n",
    "        merge_op = lambda weak, item: [weak]\n",
    "    )\n",
    "    \n",
    "    dataset.items = [\n",
    "        (video_id, intrvl.start, intrvl.end, weak_payload_to_logits(intrvl.payload))\n",
    "        for video_id in sorted(list(new_items.get_allintervals().keys()))\n",
    "        for intrvl in new_items.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    deepsbd_datasets_weak.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:07.200785Z",
     "start_time": "2019-03-05T22:59:07.142613Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset to hold multiple folds for weak data\n",
    "class DeepSBDWeakTrainDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum(len(d) for d in self.datasets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for d in self.datasets:\n",
    "            if idx < len(d):\n",
    "                return d[idx]\n",
    "            else:\n",
    "                idx -= len(d)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def weights_for_balanced_classes(self):\n",
    "        labels = [\n",
    "            np.argmax(item[3])\n",
    "            for d in self.datasets\n",
    "            for item in d.items\n",
    "        ]\n",
    "        \n",
    "        class_counts = [\n",
    "            0\n",
    "            for i in range(len(self.datasets[0].items[0]))\n",
    "        ]\n",
    "        for l in labels:\n",
    "            class_counts[l] += 1\n",
    "        \n",
    "        weights_per_class = {\n",
    "            i: len(labels) / l if l != 0 else 0\n",
    "            for i, l in enumerate(class_counts)\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            weights_per_class[l]\n",
    "            for l in labels\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:39:30.365243Z",
     "start_time": "2019-03-05T21:39:28.152208Z"
    }
   },
   "outputs": [],
   "source": [
    "# resnet deepSBD pre-trained on Kinetics\n",
    "deepsbd_resnet_model_no_clipshots = deepsbd_resnet.resnet18(\n",
    "    num_classes=3,\n",
    "    sample_size=128,\n",
    "    sample_duration=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:57:36.176903Z",
     "start_time": "2019-03-05T22:57:35.997730Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model_no_clipshots.load_weights('models/resnet-18-kinetics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T21:40:05.181305Z",
     "start_time": "2019-03-05T21:40:00.799772Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model_no_clipshots = deepsbd_resnet_model_no_clipshots.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:12.251481Z",
     "start_time": "2019-03-05T22:59:12.228058Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset_fold1 = DeepSBDWeakTrainDataset(deepsbd_datasets_weak[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:12.983996Z",
     "start_time": "2019-03-05T22:59:12.869393Z"
    }
   },
   "outputs": [],
   "source": [
    "fold1_weights = torch.DoubleTensor(training_dataset_fold1.weights_for_balanced_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:13.795765Z",
     "start_time": "2019-03-05T22:59:13.757361Z"
    }
   },
   "outputs": [],
   "source": [
    "fold1_sampler = torch.utils.data.sampler.WeightedRandomSampler(fold1_weights, len(fold1_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:14.448903Z",
     "start_time": "2019-03-05T22:59:14.420416Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataloader_fold1 = DataLoader(\n",
    "    training_dataset_fold1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    sampler=fold1_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:25.267101Z",
     "start_time": "2019-03-05T22:59:25.229402Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:25.886540Z",
     "start_time": "2019-03-05T22:59:25.846121Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(deepsbd_resnet_model_no_clipshots.parameters(), \n",
    "                      lr=.001, momentum=.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T22:59:26.997811Z",
     "start_time": "2019-03-05T22:59:26.956722Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:13:52.833367Z",
     "start_time": "2019-03-05T23:13:52.747790Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions for deepsbd testing\n",
    "def calculate_accuracy_logits(outputs, targets):\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    _, target_preds = targets.topk(1, 1, True)\n",
    "    correct = pred.eq(target_preds.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "\n",
    "    return n_correct_elems / batch_size\n",
    "\n",
    "def prf1_array(pos_label, neg_label, gt, preds):\n",
    "    tp = 0.\n",
    "    fp = 0.\n",
    "    tn = 0.\n",
    "    fn = 0.\n",
    "    \n",
    "    for truth, pred in zip(gt, preds):\n",
    "        if truth == pred:\n",
    "            if pred == pos_label:\n",
    "                tp += 1.\n",
    "            else:\n",
    "                tn += 1.\n",
    "        else:\n",
    "            if pred == pos_label:\n",
    "                fp += 1.\n",
    "            else:\n",
    "                fn += 1.\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "    \n",
    "    return (precision, recall, f1, tp, tn, fp, fn)\n",
    "\n",
    "def get_label(res_tensor):\n",
    "    res_numpy=res_tensor.data.cpu().numpy()\n",
    "    labels=[]\n",
    "    for row in res_numpy:\n",
    "        labels.append(np.argmax(row))\n",
    "    return labels\n",
    "\n",
    "def test_deepsbd(model, dataloader):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    outputs = []\n",
    "    for clip_tensor, l, _ in tqdm(dataloader):\n",
    "        o = model(clip_tensor.to(device))\n",
    "        l = torch.transpose(torch.stack(l).to(device), 0, 1).float()\n",
    "\n",
    "        preds += get_label(o)\n",
    "        labels += get_label(l)\n",
    "        outputs += o.cpu().data.numpy().tolist()\n",
    "    \n",
    "    preds = [2 if p == 2 else 0 for p in preds]\n",
    "        \n",
    "    precision, recall, f1, tp, tn, fp, fn = prf1_array(2, 0, labels, preds)\n",
    "    print(\"Precision: {}, Recall: {}, F1: {}\".format(precision, recall, f1))\n",
    "    print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(tp, tn, fp, fn))\n",
    "    \n",
    "    return preds, labels, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:20:09.049207Z",
     "start_time": "2019-03-05T23:20:08.975654Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch, training_dataloader, model, criterion, optimizer, scheduler, fold_num=1):\n",
    "    iter_len = len(training_dataloader)\n",
    "    training_iter = iter(training_dataloader)\n",
    "    \n",
    "    for i in range(iter_len):\n",
    "        clip_tensor, targets, _ = next(training_iter)\n",
    "        \n",
    "        outputs = model(clip_tensor.to(device))\n",
    "        targets = torch.transpose(torch.stack(targets).to(device), 0, 1).float()\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        acc = calculate_accuracy_logits(outputs, targets)\n",
    "        preds = get_label(outputs)\n",
    "        preds = [2 if p == 2 else 0 for p in preds]\n",
    "        target_preds = get_label(targets)\n",
    "        precision, recall, f1, tp, tn, fp, fn = prf1_array(\n",
    "            2, 0, target_preds, preds)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Loss_conf {loss_c:.4f}\\t'\n",
    "              'acc {acc:.4f}\\t'\n",
    "              'pre {pre:.4f}\\t'\n",
    "              'rec {rec:.4f}\\t'\n",
    "              'f1 {f1: .4f}\\t'\n",
    "              'TP {tp} '\n",
    "              'TN {tn} '\n",
    "              'FP {fp} '\n",
    "              'FN {fn} '\n",
    "              .format(\n",
    "                  epoch, i + 1, iter_len, loss_c=loss.item(), acc=acc,\n",
    "                  pre=precision, rec=recall, f1=f1,\n",
    "                  tp=tp, tn=tn, fp=fp, fn=fn))\n",
    "    \n",
    "    save_file_path = os.path.join(\n",
    "        '/app/notebooks/learning/models/deepsbd_resnet_clipshots_pretrain_train_on_folds_weak',\n",
    "        'fold{}_{}_epoch.pth'.format(fold_num, epoch)\n",
    "    )\n",
    "    states = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(states, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:37:37.816521Z",
     "start_time": "2019-03-05T23:57:07.187206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train K folds\n",
    "for i in range(5):\n",
    "    training_datasets = DeepSBDWeakTrainDataset(\n",
    "        deepsbd_datasets_weak[:i] + deepsbd_datasets_weak[i+1:])\n",
    "    fold_weights = torch.DoubleTensor(training_datasets.weights_for_balanced_classes())\n",
    "    fold_sampler = torch.utils.data.sampler.WeightedRandomSampler(fold_weights, len(fold_weights))\n",
    "    \n",
    "    training_dataloader = DataLoader(\n",
    "        training_datasets,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        batch_size=16,\n",
    "        sampler=fold_sampler\n",
    "    )\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # reset model\n",
    "    deepsbd_resnet_model_no_clipshots.load_weights('models/resnet-18-kinetics.pth')\n",
    "    optimizer = optim.SGD(deepsbd_resnet_model_no_clipshots.parameters(), \n",
    "                          lr=.001, momentum=.9, weight_decay=1e-3)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=60000)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        train_epoch(\n",
    "            epoch, training_dataloader, \n",
    "            deepsbd_resnet_model_no_clipshots, \n",
    "            criterion, optimizer, scheduler, fold_num = i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:40:41.655756Z",
     "start_time": "2019-03-06T00:39:35.963252Z"
    }
   },
   "outputs": [],
   "source": [
    "per_fold_preds_labels_outputs_fold_training_only = []\n",
    "for i in range(0, 5):\n",
    "    # load \n",
    "    weights = torch.load(os.path.join(\n",
    "        'models/deepsbd_resnet_clipshots_pretrain_train_on_folds_weak',\n",
    "        'fold{}_{}_epoch.pth'.format(i + 1, 4)))['state_dict']\n",
    "    deepsbd_resnet_model_no_clipshots.load_state_dict(weights)\n",
    "    deepsbd_resnet_model_no_clipshots = deepsbd_resnet_model_no_clipshots.eval()\n",
    "    test_dataset = deepsbd_datasets_weak[i]\n",
    "    dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    preds, labels, outputs = test_deepsbd(deepsbd_resnet_model_no_clipshots, dataloader)\n",
    "    \n",
    "    per_fold_preds_labels_outputs_fold_training_only.append((preds, labels, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Precision: 0.7669491525423728, Recall: 0.8190045248868778, F1: 0.7921225382932167\n",
    "TP: 181.0, TN: 1319.0, FP: 55.0, FN: 40.0\n",
    "\n",
    "Precision: 0.45294117647058824, Recall: 0.8369565217391305, F1: 0.5877862595419847\n",
    "TP: 77.0, TN: 333.0, FP: 93.0, FN: 15.0\n",
    "\n",
    "Precision: 0.7121771217712177, Recall: 0.6225806451612903, F1: 0.6643717728055077\n",
    "TP: 193.0, TN: 2276.0, FP: 78.0, FN: 117.0\n",
    "\n",
    "Precision: 0.7078651685393258, Recall: 0.7455621301775148, F1: 0.7262247838616714\n",
    "TP: 126.0, TN: 882.0, FP: 52.0, FN: 43.0\n",
    "\n",
    "Precision: 0.7053140096618358, Recall: 0.7564766839378239, F1: 0.73\n",
    "TP: 146.0, TN: 1164.0, FP: 61.0, FN: 47.0\n",
    "\n",
    "Average F1: 0.70\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T20:47:35.150307Z",
     "start_time": "2019-03-05T20:47:35.110710Z"
    }
   },
   "outputs": [],
   "source": [
    "# same as above, except train on whole movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 100 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialize pre-trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
