{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "from query.datasets.tvnews.shot_detect import shot_detect, shot_stitch\n",
    "from query.datasets.tvnews.face_detect import face_detect\n",
    "from query.datasets.tvnews.face_embed import face_embed\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "from query.datasets.tvnews.identity_detect import identity_detect\n",
    "from query.datasets.tvnews.animatedness import shot_frame_to_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment.objects.filter(things__name='rick perry', things__type=1).filter(things__name='china', things__type=2).values('id').print_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Detecting shots'):\n",
    "    import query.datasets.tvnews.shot_detect\n",
    "    reload(query.datasets.tvnews.shot_detect)\n",
    "    from query.datasets.tvnews.shot_detect import shot_detect\n",
    "    log.debug('Loading videos')\n",
    "    all_videos = list(tqdm(Video.objects.all().order_by('id')))\n",
    "    shot_indices, all_shots, all_blackframes = shot_detect(all_videos)\n",
    "    shot_videos = gather(all_videos, shot_indices)\n",
    "    log.debug('Computing face frames to detect')\n",
    "    face_frame_per_shot = [[shot_frame_to_detect(shot) for shot in vid_shots]\n",
    "                           for vid_shots in tqdm(all_shots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def bulk_create_copy(self, objects):\n",
    "    meta = self.model._meta\n",
    "    keys = [f.attname for f in meta._get_fields(reverse=False) \n",
    "            if not isinstance(f, models.ManyToManyField)]\n",
    "    fname = '/app/rows.csv'\n",
    "    log.debug('Creating CSV')\n",
    "    with open(fname, 'wb') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow(keys)\n",
    "        max_id = self.all().aggregate(Max('id'))['id__max']\n",
    "        id = max_id + 1 if max_id is not None else 0\n",
    "        for obj in tqdm(objects):\n",
    "            obj['id'] = id\n",
    "            writer.writerow([obj[k] for k in keys])\n",
    "            id += 1\n",
    "\n",
    "    table = meta.db_table\n",
    "    log.debug('Writing to database')\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"COPY {} FROM '{}' DELIMITER ',' CSV HEADER\".format(table, fname))\n",
    "        cursor.execute(\"SELECT setval('{}_id_seq', {}, false)\".format(table, id))\n",
    "\n",
    "    os.remove(fname)\n",
    "    log.debug('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Saving shots'):\n",
    "    Shot.objects.bulk_create_copy(flatten(all_shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Detecting sparse face'):\n",
    "    import query.datasets.tvnews.face_detect\n",
    "    reload(query.datasets.tvnews.face_detect)\n",
    "    from query.datasets.tvnews.face_detect import face_detect\n",
    "    \n",
    "    all_faces, indices = face_detect(shot_videos, face_frame_per_shot)\n",
    "    face_videos = gather(shot_videos, indices)\n",
    "    face_shots = gather(all_shots, indices)\n",
    "    face_frames = gather(face_frame_per_shot, indices)\n",
    "    print(len(all_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sid = 72345948\n",
    "for vid_shots in all_shots:\n",
    "    for shot in vid_shots:\n",
    "        shot['id'] = sid\n",
    "        sid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Saving faces'):\n",
    "#     log.debug('Creating frames')\n",
    "#     frames_to_save = [\n",
    "#         [{\n",
    "#             'video_id': video.id,\n",
    "#             'number': f\n",
    "#         } for f in frames]\n",
    "#         for (video, frames) in tqdm(zip(face_videos, face_frames))\n",
    "#     ]\n",
    "#     log.debug('Saving frames')\n",
    "#     Frame.objects.bulk_create_copy(flatten(frames_to_save))\n",
    "\n",
    "#     people_to_save = [\n",
    "#         [[{'frame_id': frame['id']} for face in faces]\n",
    "#          for (frame, faces) in zip(frames, vid_faces)]\n",
    "#         for (frames, vid_faces) in tqdm(zip(frames_to_save, all_faces))\n",
    "#     ]\n",
    "#     Person.objects.bulk_create_copy(flatten(flatten(people_to_save)))\n",
    "    \n",
    "#     log.debug('Creating faces')\n",
    "#     labeler, _ = Labeler.objects.get_or_create(name='mtcnn')\n",
    "#     pid = 0\n",
    "#     for (vid_faces, vid_shots) in tqdm(zip(all_faces, face_shots)):\n",
    "#         for (frame_faces, shot) in zip(vid_faces, vid_shots):\n",
    "#             for face in frame_faces:\n",
    "#                 #face['frame_id'] = frame['id']\n",
    "#                 face['labeler_id'] = labeler.id\n",
    "#                 face['bbox_score'] = 1.0\n",
    "#                 face['person_id'] = pid\n",
    "#                 face['shot_id'] = shot['id']\n",
    "#                 pid += 1\n",
    "#     log.debug('Saving faces')\n",
    "    Face.objects.bulk_create_copy(flatten(flatten(all_faces)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Face._meta.get_fields()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_name(video, frames):\n",
    "    return video.path + '_faces_' + str(hash(tuple(frames)))\n",
    "\n",
    "face_tables = [output_name(video, frames) for video, frames in tqdm(zip(face_videos, face_frames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_montage(face_videos[0], face_frames[0], '/app/montage.jpg', bboxes=all_faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Gender faces'):\n",
    "    import query.datasets.tvnews.gender_detect\n",
    "    reload(query.datasets.tvnews.gender_detect)\n",
    "    from query.datasets.tvnews.gender_detect import gender_detect\n",
    "    \n",
    "    all_genders, indices = gender_detect(face_videos, face_frames, face_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_videos = gather(face_videos, indices)\n",
    "gender_faces = gather(all_faces, indices)\n",
    "gender_frames = gather(face_frames, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Pinging db'):\n",
    "    db_faces = list(Face.objects.all().values('id', 'person__frame__video__id', 'person__frame__number', 'bbox_x1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(l, kfn):\n",
    "    d = defaultdict(list)\n",
    "    for x in l:\n",
    "        d[kfn(x)].append(x)\n",
    "    return dict(d)\n",
    "\n",
    "d1 = {k: collect(f, itemgetter('person__frame__number')) for k, f in collect(db_faces, itemgetter('person__frame__video__id')).iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders_to_save = []\n",
    "genders = {\n",
    "    k: Gender.objects.get_or_create(name=k)[0]\n",
    "    for k in ['M', 'F', 'U']\n",
    "}\n",
    "labeler, _ = Labeler.objects.get_or_create(name='rudecarnie')\n",
    "EPSILON = 0.0001\n",
    "for (video, vid_faces, vid_frames, vid_genders) in tqdm(zip(gender_videos, gender_faces, gender_frames, all_genders)):\n",
    "    for (frame_faces, frame, frame_genders) in zip(vid_faces, vid_frames, vid_genders):\n",
    "        for (face, (label, score)) in zip(frame_faces, frame_genders):\n",
    "#             face_id = None\n",
    "#             for face2 in d1[video.id][frame]:\n",
    "#                 if abs(face['bbox_x1'] - face2['bbox_x1']) < EPSILON:\n",
    "#                     face_id = face2['id']\n",
    "#                     break\n",
    "#             if face_id is None:\n",
    "#                 print(d1[video.id][frame], face)\n",
    "#                 assert False\n",
    "            face_id = face['id']\n",
    "\n",
    "            if score < 0.9:\n",
    "                label = 'U'\n",
    "\n",
    "            genders_to_save.append({\n",
    "                'face_id': face_id,\n",
    "                'gender_id': genders[label].id,\n",
    "                'labeler_id': labeler.id\n",
    "            })\n",
    "\n",
    "print(len(genders_to_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_create_copy(self, objects):\n",
    "    meta = self.model._meta\n",
    "    keys = [\n",
    "        f.attname for f in meta._get_fields(reverse=False)\n",
    "        if not isinstance(f, models.ManyToManyField)\n",
    "    ]\n",
    "    fname = '/app/rows.csv'\n",
    "    log.debug('Creating CSV')\n",
    "    with open(fname, 'wb') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow(keys)\n",
    "        max_id = self.all().aggregate(Max('id'))['id__max']\n",
    "        id = max_id + 1 if max_id is not None else 0\n",
    "        for obj in tqdm(objects):\n",
    "            obj['id'] = id\n",
    "            writer.writerow([obj[k] for k in keys])\n",
    "            id += 1\n",
    "\n",
    "    table = meta.db_table\n",
    "    log.debug('Writing to database')\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"COPY {} ({}) FROM '{}' DELIMITER ',' CSV HEADER\".format(\n",
    "            table, ', '.join(keys), fname))\n",
    "        cursor.execute(\"SELECT setval('{}_id_seq', {}, false)\".format(table, id))\n",
    "\n",
    "    os.remove(fname)\n",
    "    log.debug('Done!')\n",
    "\n",
    "# genders_to_save2 = []\n",
    "# seen = set()\n",
    "# for g in tqdm(genders_to_save):\n",
    "#     if g['face_id'] not in seen:\n",
    "#         genders_to_save2.append(g)\n",
    "#     seen.add(g['face_id'])\n",
    "bulk_create_copy(FaceGender.objects, genders_to_save2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_name(video, frames):\n",
    "    return video.path + '_embeddings_' + str(hash(tuple(frames)))\n",
    "\n",
    "with make_scanner_db() as db:\n",
    "    db._load_db_metadata()\n",
    "    \n",
    "filter2_videos, filter2_frames, filter2_faces, filter2_shots, embed_tables = unzip(\n",
    "    [(video, frames, faces, shots, db.table(output_name(video, frames)))\n",
    "          for (video, frames, faces, shots) in tqdm(zip(filtered_videos, filtered_frames, filtered_faces, filtered_shots))\n",
    "          if db.has_table(output_name(video, frames)) and db.table(output_name(video, frames)).committed()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Embedding faces\"):\n",
    "    def load_embs():\n",
    "        log.debug('Loading embs')\n",
    "        EMBEDDING_SIZE = 128\n",
    "        def load((t, vid_faces)):\n",
    "            embs = list(t.column('embeddings').load())\n",
    "            arrays = [np.frombuffer(emb, dtype=np.float32) if emb is not None else [] for _, emb in embs]\n",
    "            return [np.split(a, len(a) / 128) if len(a) > 0 else [] for a in arrays]\n",
    "        return par_for(load, zip(embed_tables, filter2_faces), workers=8)\n",
    "\n",
    "    all_embs = pcache.get('all_embs', load_embs, method='pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "serializers = {}\n",
    "type_hashes = {}\n",
    "def serializer(ty):\n",
    "    def register_class(cls):\n",
    "        serializers[ty] = cls\n",
    "        type_hashes[hash(ty)] = ty\n",
    "        return cls\n",
    "    return register_class\n",
    "\n",
    "def serialize(v):\n",
    "    ty = type(v)\n",
    "    if ty in serializers:\n",
    "        serializer = serializers[ty]\n",
    "        hsh = hash(ty)\n",
    "    else:\n",
    "        serializer = DefaultSerializer\n",
    "        hsh = 0\n",
    "    return '{}{}'.format(struct.pack('=i', hsh), serializer.serialize(v))\n",
    "\n",
    "def _deserialize(s):\n",
    "    hsh, s = struct.unpack('=i', s[:4])[0], s[4:]\n",
    "    serializer = serializers[type_hashes[hsh]]\n",
    "    return serializer.deserialize(s)\n",
    "\n",
    "def deserialize(s):\n",
    "    return _deserialize(s)[0]\n",
    "    \n",
    "class DefaultSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return serialize(pickle.dumps(v))\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        ps, s = _deserialize(s)\n",
    "        return pickle.loads(ps), s\n",
    "    \n",
    "type_hashes[0] = 0    \n",
    "serializers[0] = DefaultSerializer    \n",
    "\n",
    "@serializer(int)\n",
    "class IntSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return struct.pack('=q', v)\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        return struct.unpack('=q', s[:8])[0], s[8:]\n",
    "    \n",
    "@serializer(str)    \n",
    "class StringSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        return '{}{}'.format(serialize(len(v)), v)\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        n, s = _deserialize(s)\n",
    "        return s[:n], s[n:]\n",
    "\n",
    "@serializer(np.array)    \n",
    "class NumpySerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        dtype = serialize(pi)\n",
    "        n = serialize(len(v))\n",
    "        return '{}{}{}'.format(dtype, n, v.tobytes())\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        dtype, s = _deserialize(s)\n",
    "        n, s = _deserialize(s)\n",
    "        return np.frombuffer(s[:n], dtype=dtype), s[n:]\n",
    "\n",
    "@serializer(list)    \n",
    "class ListSerializer:\n",
    "    @staticmethod\n",
    "    def serialize(v):\n",
    "        n = serialize(len(v))\n",
    "        return '{}{}'.format(\n",
    "            n, ''.join([serialize(x) for x in v])\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(s):\n",
    "        n, s = _deserialize(s)\n",
    "        l = []\n",
    "        for _ in range(n):\n",
    "            x, s = _deserialize(s)\n",
    "            l.append(x)\n",
    "        return l, s\n",
    "\n",
    "def test(x):\n",
    "    assert(deserialize(serialize(x)) == x)\n",
    "\n",
    "test(1)\n",
    "test(\"hello\")\n",
    "test([1, \"hello\"])\n",
    "\n",
    "# with Timer('myser'):\n",
    "#     x = serialize(all_embs[:10])\n",
    "# with Timer('mydeser'):\n",
    "#     deserialize(x)\n",
    "# with Timer('pickleser'):\n",
    "#     x = pickle.dumps(all_embs[:10])\n",
    "# with Timer('pickledeser'):\n",
    "#     pickle.loads(x)\n",
    "\n",
    "#print(len(pickle.dumps(all_embs[0])))\n",
    "#print(sum([sum([e.nbytes for e in l]) for l in all_embs[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Stitching shots\"):\n",
    "    import query.datasets.prelude\n",
    "    reload(query.datasets.prelude)\n",
    "    def load_stitches():\n",
    "        log.debug('Computing stitches')\n",
    "        import query.datasets.tvnews.shot_detect\n",
    "        reload(query.datasets.tvnews.shot_detect)\n",
    "        return query.datasets.tvnews.shot_detect.shot_stitch(filter2_videos, filter2_shots, filter2_frames, filter2_faces, all_embs)\n",
    "    (stitched_shots, stitched_indices) = query.datasets.prelude.pcache.get('stitched_shots', load_stitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(l, idx):\n",
    "    return [l[i] for i in idx]\n",
    "\n",
    "def gather2(l, idx):\n",
    "    return [l[i][j] for i, j in idx]\n",
    "\n",
    "(filter3_videos, filter3_frames, filter3_faces) = unzip([\n",
    "    (video, gather(frames, idxs), gather(faces, idxs))\n",
    "    for (video, frames, faces, idxs) in tqdm(zip(filter2_videos, filter2_frames, filter2_faces,  stitched_indices))\n",
    "])\n",
    "\n",
    "# (filter3_videos, filter3_frames, filter3_faces, filter3_embs) = unzip([\n",
    "#     (video, gather(frames, idxs), gather(faces, idxs), gather(embs, idxs))\n",
    "#     for (video, frames, faces, embs, idxs) in tqdm(zip(filter2_videos, filter2_frames, filter2_faces, all_embs, stitched_indices))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = Show.objects.get(name='The Rachel Maddow Show').id\n",
    "indices = [i for i, video in enumerate(filter3_videos) if video.show_id == show]\n",
    "\n",
    "with Timer('Detecting identities'):\n",
    "    def load_identities():\n",
    "        log.debug('Computing identities')\n",
    "        import query.datasets.tvnews.identity_detect\n",
    "        reload(query.datasets.tvnews.identity_detect)\n",
    "\n",
    "        return query.datasets.tvnews.identity_detect.identity_detect(\n",
    "           gather(filter3_videos, indices), \"/app/rachel-maddow.jpg\", gather(filter3_embs, indices))\n",
    "    \n",
    "    matching_indices = pcache.get('matching_indices', load_identities)\n",
    "    \n",
    "print(len(matching_indices), sum([len(l) for l in matching_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_indices_onelevel = [[j for j, k in l] for l in matching_indices]\n",
    "matching_videos, matching_shots, matching_frames, matching_faces = \\\n",
    "    (gather(filter3_videos, indices),      \n",
    "    [gather(shots, idxs) for (shots, idxs) in zip(gather(stitched_shots, indices), matching_indices_onelevel)],\n",
    "    [gather(frames, idxs) for (frames, idxs) in zip(gather(filter3_frames, indices), matching_indices_onelevel)],\n",
    "    [gather2(faces, idxs) for (faces, idxs) in zip(gather(filter3_faces, indices), matching_indices)])\n",
    "    \n",
    "#pose_blacklist = ['tvnews/videos/MSNBCW_20170708_010000_The_Rachel_Maddow_Show.mp4']    \n",
    "#pose_blacklist = ['tvnews/videos/MSNBCW_20170506_040000_The_Rachel_Maddow_Show.mp4']\n",
    "pose_blacklist = []\n",
    "    \n",
    "matching2_videos, matching2_shots, matching2_frames, matching2_faces = unzip([\n",
    "    (video, shots, frames, faces)\n",
    "    for video, shots, frames, faces in zip(matching_videos, matching_shots, matching_frames, matching_faces)\n",
    "    if len(shots) > 0 and video.path not in pose_blacklist\n",
    "])\n",
    "    \n",
    "TARGET_FPS = 10\n",
    "pose_frames = [\n",
    "    sum([list(range(s['min_frame'], s['max_frame'], int(round(video.fps / TARGET_FPS)))) for s in shots], [])\n",
    "    for (video, shots) in zip(matching2_videos, matching2_shots)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "\n",
    "all_poses = pose_detect(matching2_videos, pose_frames, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_track\n",
    "\n",
    "\n",
    "#pose_track(matching2_videos, matching2_shots, matching2_frames, matching2_faces, all_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    if len(matches) == 0:\n",
    "        print(video.path)\n",
    "        return\n",
    "    make_montage(\n",
    "        video,\n",
    "        [frames[j] for j, _ in matches],\n",
    "        '/tmp/montage{}.jpg'.format(i),\n",
    "        bboxes=[[faces[j][k]] for j, k in matches],\n",
    "        progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "\n",
    "# make_montage(filter3_videos[indices[i]], filter3_frames[indices[i]],\n",
    "#              '/app/montage.jpg', filter3_faces[indices[i]], workers=96, progress=True)\n",
    "\n",
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    try:\n",
    "        if len(matches) == 0:\n",
    "            print(video.path)\n",
    "            return\n",
    "        bbox_map = defaultdict(list, {j: [faces[j][k]] for j, k in matches})\n",
    "        make_montage(\n",
    "            video,\n",
    "            #[frames[j] for j, _ in matches],\n",
    "            frames,\n",
    "            '/tmp/montage{}.jpg'.format(i),\n",
    "            bboxes=[bbox_map[i] for i in range(len(frames))],\n",
    "            #bboxes=[[faces[j][k]] for j, k in matches],\n",
    "            progress=False)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        print(video.path)\n",
    "    \n",
    "_ = par_for(bbox_montage,\n",
    "        list(enumerate(zip(gather(filter3_videos, indices)[:100], gather(filter3_frames, indices), \n",
    "            gather(filter3_faces, indices), matching_indices))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "\n",
    "par_for(make_montage,\n",
    "        list(enumerate(zip(filter2_videos, [[s['min_frame'] for s in l] for l in stitched_shots][:100]))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shot.objects.bulk_create_copy({\n",
    "    'min_frame': shot['min_frame'], \n",
    "    'max_frame': shot['max_frame'], \n",
    "    'labeler_id': shot['labeler'],\n",
    "    'video_id': shot['video__id']\n",
    "} for shot_list in tqdm(stitched_shots) for shot in shot_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
