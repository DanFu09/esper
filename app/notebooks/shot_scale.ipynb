{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ScratchPad-From-This-Point-On\" data-toc-modified-id=\"ScratchPad-From-This-Point-On-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>ScratchPad From This Point On</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:29.841656Z",
     "start_time": "2018-12-07T23:00:29.812164Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "import esper.stdlib as stdlib\n",
    "from django.db.models import ExpressionWrapper, F\n",
    "import rekall as rk\n",
    "import rekall.parsers\n",
    "import rekall.payload_predicates\n",
    "import esper.rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from query.models import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:39:30.164499Z",
     "start_time": "2018-12-08T00:39:30.057390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the shot scale in terms of labels: face height percentage.\n",
    "# Using https://filmanalysis.coursepress.yale.edu/cinematography/ as reference.\n",
    "from enum import IntEnum\n",
    "class ShotScale(IntEnum):\n",
    "    \"\"\" L=Long CU=Close-up X=Extreme M=Medium \"\"\"\n",
    "    UNK = 0\n",
    "    XL = 1\n",
    "    L = 2\n",
    "    ML = 3\n",
    "    M = 4\n",
    "    CU = 5\n",
    "    XCU = 6\n",
    "\n",
    "# Limitations:\n",
    "#   Extreme Close-up is difficult to get since face detector does not work on those frames.\n",
    "#   Long shots and Extreme Long shots are difficult to get since faces are too small for face detectors.\n",
    "def face_height_to_shot_scale(face_height):\n",
    "    if face_height >= 0.95:\n",
    "        return ShotScale.XCU\n",
    "    if face_height >= 0.5:\n",
    "        return ShotScale.CU\n",
    "    if face_height >= 0.25:\n",
    "        return ShotScale.M\n",
    "    if face_height >= 0.12:\n",
    "        return ShotScale.ML\n",
    "    # if face_height >= 0.05:\n",
    "    #     return ShotScale.L\n",
    "    # return ShotScale.XL\n",
    "    return ShotScale.UNK\n",
    "\n",
    "def pose_keypoints_to_shot_scale(keypoints):\n",
    "    def visible(pose, positions):\n",
    "        return np.any(pose[positions, 2]>0)\n",
    "    def get_y(pose, positions, reduce):\n",
    "        rows = pose[positions, :]\n",
    "        heights = rows[rows[:,2]>0, 1] # only consider existing keypoints\n",
    "        return reduce(heights)\n",
    "    def get_height(pose, upper_pos, lower_pose):\n",
    "        return get_y(pose, lower_pose, max) - get_y(pose, upper_pos, min)\n",
    "    pose = np.array(keypoints).reshape((-1,3))\n",
    "    ankles = [Pose.RAnkle, Pose.LAnkle]\n",
    "    knees = [Pose.RKnee, Pose.LKnee]\n",
    "    hips = [Pose.RHip, Pose.LHip]\n",
    "    shoulders = [Pose.RShoulder, Pose.LShoulder, Pose.Neck]\n",
    "    head = [Pose.Nose, Pose.LEye, Pose.REye, Pose.REar, Pose.LEar]\n",
    "    show_ankle = visible(pose, ankles)\n",
    "    show_knee = visible(pose, knees)\n",
    "    show_hip = visible(pose, hips)\n",
    "    show_shoulder = visible(pose, shoulders)\n",
    "    show_head = visible(pose, head)\n",
    "    if show_head and show_shoulder and show_hip and show_knee and show_ankle:\n",
    "        if get_height(pose, head, ankles+knees+hips) >= 0.5:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder and show_hip and show_knee:\n",
    "        height = get_height(pose, head, knees+hips)\n",
    "        if height >= 0.75:\n",
    "            return ShotScale.ML\n",
    "        elif height >= 0.4:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder and show_hip:\n",
    "        height = get_height(pose, head, hips)\n",
    "        if height >= 0.75:\n",
    "            return ShotScale.M\n",
    "        elif height >= 0.5:\n",
    "            return ShotScale.ML\n",
    "        elif height >= 0.2:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder:\n",
    "        height = get_height(pose, head, shoulders)\n",
    "        if height >= 0.4:\n",
    "            return ShotScale.CU\n",
    "        elif height >= 0.15:\n",
    "            return ShotScale.M\n",
    "        return ShotScale.UNK\n",
    "    if show_head:\n",
    "        height = get_height(pose, head, head)\n",
    "        if height >= 0.25:\n",
    "            return ShotScale.XCU\n",
    "        elif height >= 0.1:\n",
    "            return ShotScale.CU\n",
    "    return ShotScale.UNK    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:30.231364Z",
     "start_time": "2018-12-07T23:00:29.963445Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for operating on QuerySets\n",
    "def annotate_face_height(qs):\n",
    "    return qs.annotate(face_height=Face.height_expr())\n",
    "\n",
    "def filter_faces_by_face_height(qs, min_height=0.0, max_height=1.0):\n",
    "    return qs.filter(face_height__gte=min_height, face_height__lt=max_height)\n",
    "\n",
    "def annotate_frame_and_video(qs):\n",
    "    return qs.annotate(frame_number=F('frame__number'), video_id=F('frame__video__id'))\n",
    "\n",
    "def to_simple_display(frames):\n",
    "    \"\"\"values need to have frame_number, video_id fields\"\"\"\n",
    "    return stdlib.simple_result([{'video': row.video_id,\n",
    "                                'min_frame': row.frame_number,\n",
    "                                 'objects':[]} for row in frames], 'Video')\n",
    "\n",
    "def bbox_payload_to_object(bbox, video):\n",
    "    return {'id': video,\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': bbox['x1'],\n",
    "            'bbox_x2': bbox['x2'],\n",
    "            'bbox_y1': bbox['y1'],\n",
    "            'bbox_y2': bbox['y2'],\n",
    "            }\n",
    "\n",
    "def pose_payload_to_object(pose, video):\n",
    "    return {\n",
    "        \"id\": video,\n",
    "        'type': 'pose',\n",
    "        'labeler': 'UNKNOWN',\n",
    "        'keypoints': pose\n",
    "    }\n",
    "\n",
    "def payload_to_objects(payload, video_id):\n",
    "    result = []\n",
    "    result += [bbox_payload_to_object(x, video_id) for x in payload.get('bbox', [])]\n",
    "    result += [pose_payload_to_object(x, video_id) for x in payload.get('pose', [])]\n",
    "    return result\n",
    "    \n",
    "\n",
    "def pose_payload_parser():\n",
    "    def get_pose(row):\n",
    "        return {\n",
    "            'hand_left': row.hand_keypoints()[0].tolist(),\n",
    "            'hand_right': row.hand_keypoints()[1].tolist(),\n",
    "            'pose': row.pose_keypoints().tolist(),\n",
    "            'face': row.face_keypoints().tolist()\n",
    "        }\n",
    "    return get_pose\n",
    "\n",
    "# Convert named payloads to objects to send to vgrid\n",
    "def intrvllists_to_result_general(intrvllists, limit=None, stride=1):\n",
    "    \"\"\" Gets a result for intrvllists, assuming that the objects are bounding boxes.\n",
    "    \"\"\"\n",
    "    materialized_results = []\n",
    "    for video in intrvllists:\n",
    "        intrvllist = intrvllists[video].get_intervals()\n",
    "        if len(intrvllist) == 0:\n",
    "            continue\n",
    "        if limit is not None and len(materialized_results) > limit:\n",
    "            break\n",
    "        for intrvl in intrvllist[::stride]:\n",
    "            materialized_results.append({\n",
    "                'video': video,\n",
    "                'min_frame': (intrvl.get_start() + intrvl.get_end()) / 2,\n",
    "                'objects': payload_to_objects(intrvl.get_payload(), video)\n",
    "            })\n",
    "          \n",
    "\n",
    "    if limit is None:\n",
    "        limit = len(materialized_results)\n",
    "    materialized_results = materialized_results[:limit]\n",
    "\n",
    "    groups = [{'type': 'flat', 'label': '', 'elements': [r]}\n",
    "            for r in materialized_results]\n",
    "\n",
    "    return {'result': groups, 'count': len(list(intrvllists.keys())), 'type': 'Video'}\n",
    "\n",
    "# Put ouput of `parser` under `name`\n",
    "def with_named_payload(name, parser):\n",
    "    def getter(obj):\n",
    "        return {name: parser(obj)}\n",
    "    return getter\n",
    "\n",
    "def with_bbox():\n",
    "    return with_named_payload('bbox',\n",
    "             rk.parsers.in_array(\n",
    "               rk.parsers.bbox_payload_parser(VideoIntervalCollection.django_accessor)))\n",
    "\n",
    "def with_pose():\n",
    "    return with_named_payload('pose',\n",
    "            rk.parsers.in_array(\n",
    "               pose_payload_parser()))\n",
    "\n",
    "def with_attr(attr):\n",
    "    return with_named_payload(attr, lambda obj:getattr(obj, attr))\n",
    "\n",
    "def shot_scale_payload_merge(p1, p2):\n",
    "    \"\"\" Merges all bboxes and poses, but take the largest face_height.\n",
    "        This assumes that the intervals to be merged are single-frame intervals.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    agg_terms = ['bbox', 'pose']\n",
    "    max_terms = ['shot_scale', 'face_height']\n",
    "    for term in agg_terms:\n",
    "        if term in p1 or term in p2:\n",
    "            result[term] =  p1.get(term, [])+p2.get(term, [])\n",
    "    for term in max_terms:\n",
    "        if term in p1 or term in p2:\n",
    "            result[term]= max(p1.get(term, 0), p2.get(term, 0))\n",
    "    return result\n",
    "\n",
    "def has_entire_body(p):\n",
    "    if 'pose' not in p:\n",
    "        return False\n",
    "    poses = p['pose']\n",
    "    for all_pose in poses:\n",
    "        pose = np.array(all_pose['pose']).reshape((-1,3)) # Get the body pose\n",
    "        if np.all(pose[:,2]>0):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_shot_scale_fn(s):\n",
    "    def has_scale(p):\n",
    "        return p['shot_scale'] == s\n",
    "    return has_scale\n",
    "\n",
    "# Derive from face_height or pose\n",
    "def add_shot_scale_payload(p):\n",
    "    s = ShotScale.UNK\n",
    "    if 'face_height' in p:\n",
    "        s = max(s, face_height_to_shot_scale(p['face_height']))\n",
    "    if 'pose' in p:\n",
    "        for all_pose in p['pose']:\n",
    "            s = max(s, pose_keypoints_to_shot_scale(all_pose['pose']))\n",
    "    p['shot_scale'] = s\n",
    "    return p\n",
    "\n",
    "def map_payload(payload_fn):\n",
    "    def fn(interval):\n",
    "        interval.payload = payload_fn(interval.payload)\n",
    "        return interval\n",
    "    return fn\n",
    "        \n",
    "def get_video_interval_collection(qs, with_payload=None):\n",
    "    return VideoIntervalCollection.from_django_qs(qs, schema={\n",
    "        \"start\": \"frame_number\",\n",
    "        \"end\": \"frame_number\"\n",
    "    }, with_payload=with_payload)\n",
    "\n",
    "def get_all_frames_with_shot_scale(video_id, scale):\n",
    "    collection = get_video_interval_collection(\n",
    "            annotate_frame_and_video(annotate_face_height(Face.objects)).filter(video_id=video_id),\n",
    "            rk.parsers.merge_dict_parsers([with_attr('face_height'), with_bbox()]))\n",
    "    collection = collection.set_union(get_video_interval_collection(\n",
    "             annotate_frame_and_video(Pose.objects).filter(video_id=video_id),\n",
    "             with_pose()))\n",
    "    collection = collection.map(map_payload(add_shot_scale_payload))\n",
    "    collection = collection.coalesce(shot_scale_payload_merge)\n",
    "    collection = collection.filter(rk.payload_predicates.payload_satisfies(get_shot_scale_fn(scale)))\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:39:58.437053Z",
     "start_time": "2018-12-08T00:39:39.322016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c59a0497fb048c6b569509a193bc234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'bucket': 'esper', 'queries': [['All faces', 'def all_faces():\\n    from query.models i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_general(\n",
    "        get_all_frames_with_shot_scale(214, ShotScale.UNK).get_allintervals(),\n",
    "        limit=1000, stride=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScratchPad From This Point On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:23:28.195484Z",
     "start_time": "2018-12-07T23:23:26.933493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr mrs smith 123\n",
      "star wars episode i the phantom menace 184\n",
      "star wars episode ii attack of the clones 185\n",
      "star wars episode iii revenge of the sith 186\n",
      "star wars episode iv a new hope 187\n",
      "star wars episode v the empire strikes back 188\n",
      "star wars episode vi return of the jedi 189\n",
      "the godfather 214\n",
      "the godfather part ii 215\n",
      "the godfather part iii 216\n",
      "brooklyn 313\n",
      "harry potter and the chamber of secrets 374\n",
      "harry potter and the deathly hallows part 1 375\n",
      "harry potter and the deathly hallows part 2 376\n",
      "harry potter and the goblet of fire 377\n",
      "harry potter and the halfblood prince 378\n",
      "harry potter and the order of the phoenix 379\n",
      "harry potter and the prisoner of azkaban 380\n",
      "harry potter and the sorcerers stone 381\n",
      "mr mrs smith 445\n",
      "pillow talk 467\n",
      "star wars the force awakens 519\n"
     ]
    }
   ],
   "source": [
    "#list(Video.objects.filter(name=\"the godfather\"))\n",
    "#POSE_ID=5010\n",
    "#print(Pose.objects.filter(pk=POSE_ID)[0].pose_keypoints())\n",
    "#esper_widget(stdlib.qs_to_result(Pose.objects.filter(pk=POSE_ID)))\n",
    "for f in Pose.objects.annotate(video_id=F(\"frame__video__id\")).distinct('video_id'):\n",
    "    print(f.frame.video.name, f.frame.video.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:43:17.699550Z",
     "start_time": "2018-12-08T00:43:17.666378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32388258  0.54875612  0.62992316]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.27171788  0.45053458  0.63950366]\n",
      " [ 0.36837217  0.4532536   0.56719869]\n",
      " [ 0.16590875  0.52145916  0.45909595]\n",
      " [ 0.42359021  0.49964789  0.09720651]]\n",
      "ShotScale.UNK\n"
     ]
    }
   ],
   "source": [
    "for p in Pose.objects.filter(frame__video__id=214, frame__number=119268):\n",
    "    print(p.pose_keypoints())\n",
    "    print(pose_keypoints_to_shot_scale(p.pose_keypoints()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
