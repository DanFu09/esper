{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:48:35.254905Z",
     "start_time": "2019-02-05T18:48:34.393717Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.temporal_predicates import overlaps\n",
    "from esper.rekall import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:18:55.665243Z",
     "start_time": "2019-02-06T21:18:55.616480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load up small ground truth set for training\n",
    "shots_gt_training_qs = Shot.objects.filter(\n",
    "    Q(video_id=123, labeler__name__contains='manual', max_frame__lte=16560) | # easy\n",
    "    Q(video_id=172, labeler__name__contains='manual') | # hard\n",
    "    Q(video_id=179, labeler__name__contains='manual') | # easy\n",
    "    Q(video_id=104, labeler__name__contains='manual') |\n",
    "    Q(video_id=148, labeler__name__contains='manual')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:18:56.787914Z",
     "start_time": "2019-02-06T21:18:56.745895Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_test_qs = Shot.objects.filter(labeler__name__contains='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:18:57.508119Z",
     "start_time": "2019-02-06T21:18:57.419182Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_training = VideoIntervalCollection.from_django_qs(shots_gt_training_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:18:58.419447Z",
     "start_time": "2019-02-06T21:18:58.143461Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_test = VideoIntervalCollection.from_django_qs(shots_gt_test_qs).minus(shots_gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:13:12.221143Z",
     "start_time": "2019-02-07T00:13:11.081880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the ground truth.\n",
    "esper_widget(intrvllists_to_result(shots_gt_training), jupyter_keybindings=True, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up Shots from Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:05.844181Z",
     "start_time": "2019-02-06T21:19:05.793673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure out temporal extents of the clips that were labeled\n",
    "clips_training = shots_gt_training.dilate(1).coalesce().dilate(-1)\n",
    "clips_test = shots_gt_test.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.105936Z",
     "start_time": "2019-02-06T21:19:07.146927Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shots_qs = Shot.objects.filter(cinematic=True).all()\n",
    "cinematic_shots = VideoIntervalCollection.from_django_qs(\n",
    "    cinematic_shots_qs,\n",
    "    progress = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.213569Z",
     "start_time": "2019-02-06T21:19:24.109168Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shots_training = cinematic_shots.filter_against(\n",
    "    clips_training,\n",
    "    predicate=overlaps()\n",
    ")\n",
    "cinematic_shots_test = cinematic_shots.filter_against(\n",
    "    clips_test,\n",
    "    predicate=overlaps()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.237850Z",
     "start_time": "2019-02-06T21:19:24.215396Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shot_boundaries_training = cinematic_shots_training.map(lambda i: (i.start, i.start, i.payload))\n",
    "cinematic_shot_boundaries_test = cinematic_shots_test.map(lambda i: (i.start, i.start, i.payload))\n",
    "gt_shot_boundaries_training = shots_gt_training.map(lambda i: (i.start, i.start, i.payload))\n",
    "gt_shot_boundaries_test = shots_gt_test.map(lambda i: (i.start, i.start, i.payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.262850Z",
     "start_time": "2019-02-06T21:19:24.240241Z"
    }
   },
   "outputs": [],
   "source": [
    "def size(interval_collection):\n",
    "    count = 0\n",
    "    for video_id in interval_collection.get_allintervals():\n",
    "        count += interval_collection.get_intervallist(video_id).size()\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.291115Z",
     "start_time": "2019-02-06T21:19:24.264540Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_per_video_precision_recall(gt_shot_boundaries, eval_shot_boundaries):\n",
    "    for video_id in gt_shot_boundaries.get_allintervals():\n",
    "        print(\"Video {}: \".format(video_id))\n",
    "        cine_sb = VideoIntervalCollection({\n",
    "            video_id: eval_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        gt_sb = VideoIntervalCollection({\n",
    "            video_id: gt_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        accurate_sb = cine_sb.filter_against(gt_sb, predicate=overlaps())\n",
    "        inaccurate_sb = cine_sb.minus(accurate_sb)\n",
    "\n",
    "        found_human_sb = gt_sb.filter_against(cine_sb, predicate=overlaps())\n",
    "        missed_human_sb = gt_sb.minus(found_human_sb)\n",
    "        \n",
    "        print(\"Precision: {}, {} out of {}\".format(\n",
    "            size(accurate_sb) / size(cine_sb), \n",
    "            size(accurate_sb), \n",
    "            size(cine_sb)))\n",
    "        print(\"Recall: {}, {} out of {}\".format(\n",
    "            size(accurate_sb) / size(gt_sb), \n",
    "            size(accurate_sb), \n",
    "            size(gt_sb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:19:24.319105Z",
     "start_time": "2019-02-06T21:19:24.292799Z"
    }
   },
   "outputs": [],
   "source": [
    "print_per_video_precision_recall(gt_shot_boundaries_training, cinematic_shot_boundaries_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:31:37.879758Z",
     "start_time": "2019-02-05T18:31:37.681127Z"
    }
   },
   "outputs": [],
   "source": [
    "print_per_video_precision_recall(gt_shot_boundaries_test, cinematic_shot_boundaries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:13:00.658866Z",
     "start_time": "2019-02-07T00:12:59.512820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the discrepancies. Ground truth is in red, heuristic results are in blue.\n",
    "result = intrvllists_to_result(shots_gt_training, color='red')\n",
    "add_intrvllists_to_result(result, cinematic_shots_training, color='blue')\n",
    "esper_widget(result, jupyter_keybindings=True, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T19:03:32.183559Z",
     "start_time": "2019-02-05T19:03:32.133985Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import scannertools as st\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:49:02.734751Z",
     "start_time": "2019-02-05T18:49:02.714715Z"
    }
   },
   "outputs": [],
   "source": [
    "st.init_storage(os.environ['BUCKET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T01:32:48.423977Z",
     "start_time": "2019-02-06T01:32:48.315329Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShotDetectionDataset(Dataset):\n",
    "    def __init__(self, shots, window_size=1, height=224):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            shots: VideoIntervalCollection of all the intervals to get frames from. If the payload is -1,\n",
    "            then the interval is not an actual shot and just needs to be included in the dataset.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        items = set()\n",
    "        frame_nums = {}\n",
    "        \n",
    "        for video_id in shots.get_allintervals():\n",
    "            frame_nums[video_id] = set()\n",
    "            for intrvl in shots.get_intervallist(video_id).get_intervals():\n",
    "                for f in range(intrvl.start, intrvl.end + 1):\n",
    "                    items.add((\n",
    "                        video_id,\n",
    "                        f,\n",
    "                        1 if f == intrvl.start and intrvl.payload != -1 else 0\n",
    "                    ))\n",
    "                    for i in range(intrvl.start - window_size, intrvl.end + window_size + 1):\n",
    "                        frame_nums[video_id].add(i)\n",
    "        self.items = sorted(list(items))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((100, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # Load frames into memory\n",
    "        self.frames = {\n",
    "            video_id: {\n",
    "                'frame_nums': sorted(list(frame_nums[video_id])),\n",
    "                'frames': [\n",
    "                    self.transform(f)\n",
    "                    for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "                        sorted(list(frame_nums[video_id]))\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "            for video_id in tqdm(frame_nums)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video_id, frame_num, label = self.items[idx]\n",
    "        \n",
    "        start_index = self.frames[video_id]['frame_nums'].index(frame_num - self.window_size)\n",
    "        img_tensors = self.frames[video_id]['frames'][start_index:start_index + 2*self.window_size + 1]\n",
    "        \n",
    "#         img_tensors = [\n",
    "#             self.transform(f)\n",
    "#             for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "#                 list(range(frame_num - self.window_size, frame_num + self.window_size + 1))\n",
    "#             )\n",
    "#         ]\n",
    "        \n",
    "        return img_tensors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:53:43.020900Z",
     "start_time": "2019-02-06T21:53:42.932572Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct a training set with good class balance\n",
    "shot_boundaries = shots_gt_training.map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    ")\n",
    "shots_without_boundaries = shots_gt_training.map(\n",
    "    lambda intrvl: (intrvl.start + 1, intrvl.end, intrvl.payload)\n",
    ").get_allintervals()\n",
    "non_boundary_frames = [\n",
    "    (video_id, f)\n",
    "    for video_id in shots_without_boundaries\n",
    "    for intrvl in shots_without_boundaries[video_id].get_intervals()\n",
    "    for f in range(intrvl.start, intrvl.end + 1)\n",
    "]\n",
    "random.seed(0)\n",
    "random.shuffle(non_boundary_frames) # seed of 0 for reproducibility\n",
    "chosen_frames = collect(non_boundary_frames[:size(shot_boundaries)], lambda tup: tup[0])\n",
    "\n",
    "training_frames = shot_boundaries.set_union(\n",
    "    VideoIntervalCollection({\n",
    "        video_id: [\n",
    "            (frame, frame, -1)\n",
    "            for vid, frame in chosen_frames[video_id]\n",
    "        ]\n",
    "        for video_id in chosen_frames\n",
    "    })\n",
    ").set_union(\n",
    "    shots_gt_training.map(\n",
    "        lambda intrvl: (intrvl.end, intrvl.end, -1)\n",
    "    )\n",
    ").set_union(\n",
    "    shots_gt_training.map(\n",
    "        lambda intrvl: (intrvl.start+1, intrvl.start+1, -1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:54:25.488154Z",
     "start_time": "2019-02-06T21:53:45.385807Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_training = ShotDetectionDataset(training_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:54:33.822974Z",
     "start_time": "2019-02-06T21:54:33.769951Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_training = DataLoader(dataset_training, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:45:09.421375Z",
     "start_time": "2019-02-06T21:43:35.173069Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_training_test = ShotDetectionDataset(shots_gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:45:09.449337Z",
     "start_time": "2019-02-06T21:45:09.423975Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_training_test = DataLoader(dataset_training_test, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:43:06.215051Z",
     "start_time": "2019-02-06T18:43:06.088330Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoNet(nn.Module):\n",
    "    def __init__(self, window_size=1):\n",
    "        super(VideoNet, self).__init__()\n",
    "#         self.resnet1 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "#         self.resnet2 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "#         self.resnet3 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "        self.resnet1 = models.resnet18(pretrained=True)\n",
    "        self.resnet2 = models.resnet18(pretrained=True)\n",
    "        self.resnet3 = models.resnet18(pretrained=True)\n",
    "    \n",
    "        # Replace pooling layer with Adaptive Pooling\n",
    "        self.resnet1.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.resnet2.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.resnet3.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "#         self.embeddingpool = nn.MaxPool1d(5, stride=3)\n",
    "        \n",
    "#         self.rnfc1 = nn.Linear(1000, 128)\n",
    "#         self.rnfc2 = nn.Linear(1000, 128)\n",
    "#         self.rnfc3 = nn.Linear(1000, 128)\n",
    "        \n",
    "        self.embeddingconv = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.kaiming_normal_(self.embeddingconv.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, image1, image2, image3):\n",
    "        image1embedding = self.resnet1(image1).unsqueeze(1)\n",
    "        image2embedding = self.resnet2(image2).unsqueeze(1)\n",
    "        image3embedding = self.resnet3(image3).unsqueeze(1)\n",
    "        \n",
    "#         print(image1embedding.size())\n",
    "        \n",
    "#         embedding_image = torch.cat(\n",
    "#             (self.embeddingpool(image1embedding),\n",
    "#              self.embeddingpool(image2embedding),\n",
    "#              self.embeddingpool(image3embedding)),\n",
    "#             dim=1\n",
    "#         )\n",
    "        \n",
    "        embedding_image = torch.cat(\n",
    "            (image1embedding,\n",
    "             image2embedding,\n",
    "             image3embedding),\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "#         print(embedding_image.size())\n",
    "        \n",
    "        embedding_image = embedding_image.unsqueeze(1)\n",
    "        \n",
    "#         print(embedding_image.size())\n",
    "        out = self.embeddingconv(embedding_image)\n",
    "#         print(out.size())\n",
    "        out = self.relu(out)\n",
    "#         print(out.size())\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "#         out = nn.LogSoftmax(1)(out)\n",
    "#         out = self.sigmoid(out)\n",
    "#         out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def parameters(self):\n",
    "#         return [self.embeddingconv.parameters(), self.fc.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:04.464558Z",
     "start_time": "2019-02-06T23:50:03.370288Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet = VideoNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:04.488212Z",
     "start_time": "2019-02-06T23:50:04.467321Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:05.862647Z",
     "start_time": "2019-02-06T23:50:05.819990Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:06.253840Z",
     "start_time": "2019-02-06T23:50:06.188945Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet = vnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T17:57:24.068965Z",
     "start_time": "2019-02-06T17:57:23.878669Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_inputs = 0.0\n",
    "            \n",
    "            true_positive = 0.\n",
    "            false_positive = 0.\n",
    "            true_negative = 0.\n",
    "            false_negative = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, (inputs, labels) in tqdm(enumerate(dataloader_training)):\n",
    "#                 if idx > 100:\n",
    "#                     break\n",
    "#                 print(\"Start loop {}\".format(datetime.datetime.now()))\n",
    "#                 crit = nn.BCELoss(\n",
    "#                     weight = torch.tensor([\n",
    "#                         1.0 if l.item() == 1 else .25\n",
    "#                         for l in labels\n",
    "#                     ]).to(device)\n",
    "#                 )\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "                labels = labels.to(device)\n",
    "#                 print(\"Moved inputs {}\".format(datetime.datetime.now()))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs[0], inputs[1], inputs[2])\n",
    "                    batch_size = labels.size(0)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs.view(1, 4), labels.view(1, 4))\n",
    "#                     loss=torch.tensor([[0]]).to(device)\n",
    "#                     print(outputs.view(1, batch_size), labels.view(1, batch_size))\n",
    "#                     loss=criterion(outputs, labels)\n",
    "                    loss=criterion(outputs.view(1, batch_size), labels.float().view(1, batch_size))\n",
    "#                     print(outputs.view(1, 4), labels.float().view(1, 4), loss)\n",
    "#                     if False:\n",
    "                    if idx == 0:\n",
    "                        print(outputs, labels, loss)\n",
    "#                     print(labels)\n",
    "#                     print(loss)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                \n",
    "#                     for p, l in zip(preds, labels):\n",
    "#                         if p.item() == l.item():\n",
    "#                             if l.item() == 1:\n",
    "#                                 true_positive += 1.\n",
    "#                             else:\n",
    "#                                 true_negative += 1.\n",
    "#                         else:\n",
    "#                             if p.item() == 1:\n",
    "#                                 false_positive += 1.\n",
    "#                             else:\n",
    "#                                 false_negative += 1.\n",
    "#                         total_inputs += 1\n",
    "\n",
    "                    for o, l in zip(outputs, labels):\n",
    "                        if o.item() > 0.:\n",
    "                            if l.item() == 1:\n",
    "                                true_positive += 1.\n",
    "                            else:\n",
    "                                false_positive += 1.\n",
    "                        else:\n",
    "                            if l.item() == 1:\n",
    "                                false_negative += 1.\n",
    "                            else:\n",
    "                                true_negative += 1.\n",
    "                        total_inputs += 1\n",
    "                            \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs[0].size(0)\n",
    "                    running_corrects = true_positive + true_negative\n",
    "#                     print(running_corrects, true_positive, true_negative, total_inputs)\n",
    "\n",
    "#                 print(\"End loop {}\".format(datetime.datetime.now()))\n",
    "\n",
    "            epoch_loss = running_loss / total_inputs #/ len(dataset)\n",
    "            epoch_acc = running_corrects / total_inputs #/ len(dataset)\n",
    "            if true_positive + false_positive != 0:\n",
    "                precision = true_positive / (true_positive + false_positive)\n",
    "            else:\n",
    "                precision = 0.\n",
    "            if true_positive + false_negative != 0:\n",
    "                recall = true_positive / (true_positive + false_negative)\n",
    "            else:\n",
    "                recall = 0.\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, precision, recall))\n",
    "            print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                true_positive, true_negative, false_positive, false_negative\n",
    "            ))\n",
    "\n",
    "            # deep copy the model\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:10.494427Z",
     "start_time": "2019-02-06T23:50:10.449164Z"
    }
   },
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([.1, 1.]).to(device))\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.NLLLoss(weight=torch.tensor([.01, .99]).to(device))\n",
    "# criterion = nn.NLLLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:11.229810Z",
     "start_time": "2019-02-06T23:50:11.184268Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(vnet.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:50:11.845291Z",
     "start_time": "2019-02-06T23:50:11.804287Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T23:55:50.838767Z",
     "start_time": "2019-02-06T23:50:12.865123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_model(vnet, criterion, optimizer, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:01:49.578109Z",
     "start_time": "2019-02-07T00:01:49.445012Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, dataloader=dataloader_test):\n",
    "    since = time.time()\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_inputs = 0.0\n",
    "\n",
    "    true_positive = 0.\n",
    "    false_positive = 0.\n",
    "    true_negative = 0.\n",
    "    false_negative = 0.\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for idx, (inputs, labels) in tqdm(enumerate(dataloader)):\n",
    "        inputs = [i.to(device) for i in inputs]\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs[0], inputs[1], inputs[2])\n",
    "            batch_size = labels.size(0)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss=criterion(outputs, labels)\n",
    "            loss=criterion(outputs.view(1, batch_size), labels.float().view(1, batch_size))\n",
    "#             if False:\n",
    "            if idx == 0:\n",
    "                print(outputs, labels, loss)\n",
    "#             print(labels)\n",
    "#             print(loss)\n",
    "                \n",
    "                \n",
    "#             for p, l in zip(preds, labels):\n",
    "#                 if p.item() == l.item():\n",
    "#                     if l.item() == 1:\n",
    "#                         true_positive += 1.\n",
    "#                     else:\n",
    "#                         true_negative += 1.\n",
    "#                 else:\n",
    "#                     if p.item() == 1:\n",
    "#                         false_positive += 1.\n",
    "#                     else:\n",
    "#                         false_negative += 1.\n",
    "#                 total_inputs += 1\n",
    "\n",
    "            for o, l in zip(outputs, labels):\n",
    "                if o.item() > 0.:\n",
    "                    if l.item() == 1:\n",
    "                        true_positive += 1.\n",
    "                    else:\n",
    "                        false_positive += 1.\n",
    "                else:\n",
    "                    if l.item() == 1:\n",
    "                        false_negative += 1.\n",
    "                    else:\n",
    "                        true_negative += 1.\n",
    "                total_inputs += 1\n",
    "                results.append((o.item(), l.item()))\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs[0].size(0)\n",
    "        running_corrects = true_positive + true_negative\n",
    "#     print(running_corrects, true_positive, true_negative, total_inputs)\n",
    "\n",
    "    epoch_loss = running_loss / total_inputs #/ len(dataset)\n",
    "    epoch_acc = running_corrects / total_inputs #/ len(dataset)\n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0.\n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0.\n",
    "\n",
    "    print('Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, precision, recall))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positive, true_negative, false_positive, false_negative\n",
    "    ))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:39:32.423594Z",
     "start_time": "2019-02-06T21:23:49.621583Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_test = ShotDetectionDataset(shots_gt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:39:36.691657Z",
     "start_time": "2019-02-06T21:39:36.495092Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:38:05.779427Z",
     "start_time": "2019-02-07T00:36:20.713535Z"
    }
   },
   "outputs": [],
   "source": [
    "test_results = test_model(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:15:39.588672Z",
     "start_time": "2019-02-07T17:15:24.559617Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results = test_model(model, criterion, dataloader_training_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:13:59.590954Z",
     "start_time": "2019-02-07T00:13:59.543632Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives = []\n",
    "false_positives = []\n",
    "for (output, label), item in zip(training_test_results, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives.append((output, label, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:14:27.286019Z",
     "start_time": "2019-02-07T00:14:27.241067Z"
    }
   },
   "outputs": [],
   "source": [
    "tp_collected = collect(true_positives, lambda tup: tup[2][0])\n",
    "true_positive_intrvls = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in tp_collected[video_id]\n",
    "    ]\n",
    "    for video_id in tp_collected\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:06:43.497182Z",
     "start_time": "2019-02-07T00:06:43.453790Z"
    }
   },
   "outputs": [],
   "source": [
    "fp_collected = collect(false_positives, lambda tup: tup[2][0])\n",
    "false_positive_intrvls = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:14:37.438784Z",
     "start_time": "2019-02-07T00:14:35.264388Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(true_positive_intrvls, lambda a, b: []),\n",
    "    jupyter_keybindings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:17:08.903343Z",
     "start_time": "2019-02-07T00:17:07.796286Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T01:30:01.330833Z",
     "start_time": "2019-02-06T01:30:01.078841Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-5-19_529pm_videonet_1to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T17:49:06.096024Z",
     "start_time": "2019-02-06T17:49:05.840036Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_948am_videonet_10to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:16:54.511803Z",
     "start_time": "2019-02-06T18:16:54.190444Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_1016am_videonet_2to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:16:10.898185Z",
     "start_time": "2019-02-07T17:16:10.645534Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_5pm_videonet_3to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model/loss: raw output of last FC layer to BCEWithLogitsLoss\n",
    "\n",
    "Training with perfectly balanced classes - selected 58 positive examples from training dataset and randomly selected 58 negative examples:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 26.7%/24.4%. Confusion matrix `TP: 139.0 TN: 52399.0 FP: 381.0 FN: 430.0`. Output of model had absolute value < 0.5.\n",
    "* Saved in `2-5-19_529pm_videonet_1to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Training with 10:1 class imbalance - 58 positive examples, 580 randomly selected negative examples:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 57.9%/1.9%. Confusion matrix `TP: 11.0 TN: 52772.0 FP: 8.0 FN: 558.0`. Output of model had absolute value around 5-10.\n",
    "* Saved in `2-6-19_948am_videonet_10to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Training with 2:1 class imbalance - 58 positive examples, 58 randomly selected negative examples, 58 examples from the end of shots:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 18.2%/3.9%. Confusion matrix `TP: 22.0 TN: 52681.0 FP: 99.0 FN: 547.0`. Output of model had absolute value < 2.\n",
    "* Saved in `2-6-19_1016am_videonet_2to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Issue: if you train on a subset of frames from the training clips, you won't do great on the full range of frames from the training clips. I.e. if you train on all the shot transitions, along with some random selected non-transition frames, you'll be able to identify all the shot transitions in your training clips, but you'll also get a bunch of false positives.\n",
    "\n",
    "Training with a 3:1 class imbalance and 97 positive examples - plus 97 randomly selected negative examples. 97 examples from the end of shots, and 97 examples from the frame right after each shot transition.\n",
    "* 100% accuracy on the training set.\n",
    "* On the full set of training clips, 100% recall with 66% precision.\n",
    "* On the set of training clips, hallucinating that many frames in a row are shot boundaries. Confusion matrix `TP: 97.0 TN: 7155.0 FP: 49.0 FN: 0.0`.\n",
    "* Saved in `2-6-19_5pm_videonet_3to1classbalance_bcewithlogitsloss.pth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:47:44.853381Z",
     "start_time": "2019-02-04T17:47:44.756804Z"
    }
   },
   "outputs": [],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    inputs = [i.to(device) for i in inputs]\n",
    "    labels = labels.to(device)\n",
    "    outputs = vnet(inputs[0], inputs[1], inputs[2])\n",
    "    print(outputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:33:24.309227Z",
     "start_time": "2019-02-02T07:33:24.259449Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(\n",
    "    torch.tensor([\n",
    "        [0.3, 0.7],\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.3]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        1, 0, 0, 0\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:46:43.148824Z",
     "start_time": "2019-02-02T07:46:43.115481Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([.01, 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:54:03.467426Z",
     "start_time": "2019-02-04T17:54:03.418652Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=torch.tensor([1., .5]).to(device))(\n",
    "    torch.tensor(\n",
    "        [[-0.9855, 1.1573]]\n",
    "    ).to(device),\n",
    "    torch.tensor([1]).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:47:05.924229Z",
     "start_time": "2019-02-02T07:47:05.875365Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(\n",
    "    torch.tensor([\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        1, 0, 0, 0\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.679659Z",
     "start_time": "2019-01-30T18:46:21.401945Z"
    }
   },
   "outputs": [],
   "source": [
    "#tenlayer_resnet = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.725369Z",
     "start_time": "2019-01-30T18:46:21.682349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the avgpool layer with an AdaptiveAvgPool so we don't have to worry about input size\n",
    "#tenlayer_resnet.avgpool = nn.AdaptiveAvgPool2d((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.770551Z",
     "start_time": "2019-01-30T18:46:21.727728Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(tenlayer_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.814927Z",
     "start_time": "2019-01-30T18:46:21.773056Z"
    }
   },
   "outputs": [],
   "source": [
    "#params = list(tenlayer_resnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.861630Z",
     "start_time": "2019-01-30T18:46:21.817094Z"
    }
   },
   "outputs": [],
   "source": [
    "#len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.921166Z",
     "start_time": "2019-01-30T18:46:21.864281Z"
    }
   },
   "outputs": [],
   "source": [
    "#params[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:25.853366Z",
     "start_time": "2019-01-30T18:46:21.923954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load up an image and run it through the network\n",
    "vid_id = list(shots_gt.get_allintervals().keys())[0]\n",
    "frame = shots_gt.get_intervallist(vid_id).get_intervals()[0].start\n",
    "img = cv2.cvtColor(load_frame(Video.objects.get(id=vid_id), frame, []), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:25.930315Z",
     "start_time": "2019-01-30T18:46:25.855973Z"
    }
   },
   "outputs": [],
   "source": [
    "#img_tensor = transforms.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:27.508647Z",
     "start_time": "2019-01-30T18:46:25.932776Z"
    }
   },
   "outputs": [],
   "source": [
    "#tenlayer_resnet(img_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:21.242891Z",
     "start_time": "2019-02-04T17:46:16.791137Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = [\n",
    "   cv2.cvtColor(load_frame(Video.objects.get(id=123), f, []), cv2.COLOR_BGR2RGB)\n",
    "   for f in range(14455-1, 14455+2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:31.789691Z",
     "start_time": "2019-02-02T06:52:31.109122Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:33.365579Z",
     "start_time": "2019-02-02T06:52:32.661208Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:35.229727Z",
     "start_time": "2019-02-02T06:52:34.508177Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:21.313660Z",
     "start_time": "2019-02-04T17:46:21.270556Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:22.144299Z",
     "start_time": "2019-02-04T17:46:22.066566Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tensors = [\n",
    "    transform(npimg).unsqueeze(0).to(device)\n",
    "    for npimg in imgs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:21:09.512104Z",
     "start_time": "2019-02-02T07:21:09.033686Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:25.355822Z",
     "start_time": "2019-02-04T17:46:25.287032Z"
    }
   },
   "outputs": [],
   "source": [
    "o = vnet(img_tensors[0], img_tensors[1], img_tensors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:26.343946Z",
     "start_time": "2019-02-04T17:46:26.294723Z"
    }
   },
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:17:37.130594Z",
     "start_time": "2019-02-02T07:17:37.062589Z"
    }
   },
   "outputs": [],
   "source": [
    "model(img_tensors[0], img_tensors[1], img_tensors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:42.732433Z",
     "start_time": "2019-02-02T06:52:42.687175Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.max(o, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:07:44.130846Z",
     "start_time": "2019-01-30T19:07:44.083431Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShotDetectionDataset(Dataset):\n",
    "    def __init__(self, shots, window_size=1, height=224):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            shots: VideoIntervalCollection of all the intervals to get frames from.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        frames = set()\n",
    "        \n",
    "        for video_id in shots.get_allintervals():\n",
    "            for intrvl in shots.get_intervallist(video_id).get_intervals():\n",
    "                for f in range(intrvl.start, intrvl.end + 1):\n",
    "                    frames.add((video_id, f, 1 if f == intrvl.start else 0))\n",
    "        self.frames = sorted(list(frames))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video_id, frame_num, label = self.frames[idx]\n",
    "        npimgs = [\n",
    "            cv2.cvtColor(load_frame(Video.objects.get(id=video_id), f, []), cv2.COLOR_BGR2RGB)\n",
    "            for f in range(frame_num-self.window_size, frame_num+self.window_size + 1)\n",
    "        ]\n",
    "        img_tensors = [\n",
    "            self.transform(npimg)\n",
    "            for npimg in imgs\n",
    "        ]\n",
    "        \n",
    "        return img_tensors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:07:47.796617Z",
     "start_time": "2019-01-30T19:07:47.759909Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ShotDetectionDataset(shots_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:33.152379Z",
     "start_time": "2019-01-30T18:46:33.107682Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:01:14.638644Z",
     "start_time": "2019-01-30T18:00:59.269639Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:08:36.982721Z",
     "start_time": "2019-01-30T19:08:36.931067Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:10:01.921632Z",
     "start_time": "2019-01-30T19:09:28.114952Z"
    }
   },
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    sample, label = sample_batched\n",
    "    print(i_batch, len(sample))\n",
    "    print(sample[0].size())\n",
    "    print(label)\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:54:11.945930Z",
     "start_time": "2019-01-30T18:54:10.426271Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet(sample_batched[0], sample_batched[1], sample_batched[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:54:50.597303Z",
     "start_time": "2019-01-30T18:54:50.553861Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:56:40.575775Z",
     "start_time": "2019-01-30T18:56:39.106132Z"
    }
   },
   "outputs": [],
   "source": [
    "outs = vnet(sample_batched[0], sample_batched[1], sample_batched[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:56:47.355993Z",
     "start_time": "2019-01-30T18:56:47.312049Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.max(outs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:17:04.058988Z",
     "start_time": "2019-01-30T19:17:04.019402Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(vnet.modules()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
