{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Major-Shootings\" data-toc-modified-id=\"Major-Shootings-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Major Shootings</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T23:11:10.278801Z",
     "start_time": "2018-08-07T23:11:10.244517Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from esper.stdlib import *\n",
    "from esper.identity import *\n",
    "from esper.topics import *\n",
    "from esper.plot_util import *\n",
    "\n",
    "import random\n",
    "from django.db.models import ExpressionWrapper, F, FloatField\n",
    "try:\n",
    "    from IPython.display import clear_output\n",
    "except ImportError as e:\n",
    "    print('Failed to import clear_output')\n",
    "    clear_output = lambda: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:53:50.030699Z",
     "start_time": "2018-08-08T04:53:49.711608Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cluster_images(clusters, n, c):\n",
    "    cluster_images = {}\n",
    "    for cluster_id, face_ids in clusters.items():\n",
    "        im = faces_to_tiled_img(\n",
    "            Face.objects.filter(id__in=face_ids).order_by('?')[:n], \n",
    "            cols=c\n",
    "        )\n",
    "        cluster_images[cluster_id] = im\n",
    "    return cluster_images\n",
    "\n",
    "def recluster_clusters(clusters, merge_cluster_thresh):\n",
    "    cluster_samples = []\n",
    "    cluster_clusters = []\n",
    "    cluster_nsamples = {}\n",
    "    for k, v in clusters.items():\n",
    "        cluster_nsamples[k] = min(len(v), 10)\n",
    "        cluster_samples.extend(random.sample(v, cluster_nsamples[k]))\n",
    "        cluster_clusters.extend([k] * cluster_nsamples[k])\n",
    "    est_centroids = {}\n",
    "    for cluster_id, features in zip(cluster_clusters, face_features(cluster_samples)):\n",
    "        if cluster_id not in est_centroids:\n",
    "            est_centroids[cluster_id] = features / cluster_nsamples[cluster_id]\n",
    "        else:\n",
    "            est_centroids[cluster_id] += features / cluster_nsamples[cluster_id]\n",
    "\n",
    "    def _find_meta_cluster(meta_clusters, k):\n",
    "        for i, c in enumerate(meta_clusters):\n",
    "            if k in c:\n",
    "                return i\n",
    "        raise Exception('Not found')\n",
    "\n",
    "    def _merge_meta_clusters(meta_clusters, i, j):\n",
    "        i_idx = _find_meta_cluster(meta_clusters, i)\n",
    "        j_idx = _find_meta_cluster(meta_clusters, j)\n",
    "        if i_idx != j_idx:\n",
    "            meta_clusters[i_idx].update(meta_clusters[j_idx])\n",
    "            del meta_clusters[j_idx]\n",
    "        return meta_clusters\n",
    "\n",
    "    meta_clusters = [{i} for i in range(k)]\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            if np.linalg.norm(est_centroids[i] - est_centroids[j]) <= merge_cluster_thresh:\n",
    "                meta_clusters = _merge_meta_clusters(meta_clusters, i, j)\n",
    "\n",
    "    new_clusters = defaultdict(list)\n",
    "    for i, l in enumerate(meta_clusters):\n",
    "        for cluster_id in l:\n",
    "            new_clusters[i].extend(clusters[cluster_id])\n",
    "    return new_clusters\n",
    "\n",
    "\n",
    "def manual_recluster(clusters, examples_per_cluster):\n",
    "    cluster_images = get_cluster_images(clusters, n=examples_per_cluster,\n",
    "                                        c=examples_per_cluster)\n",
    "    \n",
    "    def _show_clusters(cluster_ids):\n",
    "        for cluster_id in sorted(cluster_ids):\n",
    "            print('Cluster {} ({} faces)'.format(cluster_id, len(clusters[cluster_id])))\n",
    "            imshow(cluster_images[cluster_id])\n",
    "            plt.show()\n",
    "\n",
    "    def _get_remaining_clusters(meta_clusters):\n",
    "        meta_cluster_set = set()\n",
    "        for l in meta_clusters: \n",
    "            meta_cluster_set.update(l)\n",
    "        return set(clusters.keys()) - meta_cluster_set \n",
    "\n",
    "    meta_clusters = []\n",
    "    while True:\n",
    "        clear_output()\n",
    "        remaining_clusters = _get_remaining_clusters(meta_clusters)\n",
    "        if len(remaining_clusters) == 0:\n",
    "            break\n",
    "        elif len(remaining_clusters) == 1:\n",
    "            meta_clusters.append(list(remaining_clusters))\n",
    "            break\n",
    "        else:\n",
    "            _show_clusters(remaining_clusters)\n",
    "\n",
    "        try:\n",
    "            line = input(\n",
    "                'Enter a cluster (\"d\" if done): [choices: {}]: '.format(\n",
    "                    ', '.join([str(i) for i in sorted(remaining_clusters)])\n",
    "                )\n",
    "            )\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "                continue\n",
    "            elif line == 'd':\n",
    "                for i in remaining_clusters:\n",
    "                    meta_clusters.append([i])\n",
    "            else:\n",
    "                choices = [int(s.strip()) for s in line.split(',') if s.strip() != '']\n",
    "                for choice in choices:\n",
    "                    if choice not in remaining_clusters:\n",
    "                        print('{} is not a valid choice')\n",
    "                        break\n",
    "                else:\n",
    "                    meta_clusters.append(choices)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    clear_output()\n",
    "\n",
    "    recluster = defaultdict(list)\n",
    "    for i, l in enumerate(meta_clusters):\n",
    "        for j in l:\n",
    "            recluster[i].extend(clusters[j])\n",
    "    return recluster\n",
    "\n",
    "\n",
    "def identity_still_montage(name, examples_per_cluster=10, \n",
    "                           merge_cluster_thresh=0.3, \n",
    "                           init_clusters=20):\n",
    "\n",
    "    def _plot_heatmap_helper(heatmap, cluster_images, title, \n",
    "                             heatmap_label_fn=lambda x: '{:0.2f}'.format(x)):\n",
    "        face_labels_proportion = examples_per_cluster / (examples_per_cluster + len(channels))\n",
    "        fig, ax = plt.subplots(\n",
    "            figsize=(1.5 * (examples_per_cluster + len(channels)), 1.5 * len(cluster_images))\n",
    "        )\n",
    "        ax.set_position([face_labels_proportion, 0, 1 - face_labels_proportion, 1])\n",
    "        cax = ax.imshow(heatmap, origin='lower')\n",
    "        ax.set_xticks(range(len(channels)))\n",
    "        ax.set_xticklabels(channels)\n",
    "        ax.set_yticks([])\n",
    "        max_val = np.max(heatmap)\n",
    "        for i in range(heatmap.shape[0]):\n",
    "            for j in range(heatmap.shape[1]):\n",
    "                text = ax.text(\n",
    "                    j, i, heatmap_label_fn(heatmap[i, j]), \n",
    "                    ha='center', va='center', \n",
    "                    color='white' if heatmap[i, j] / (max_val + 1e-12) < 0.6 else 'black'\n",
    "                )\n",
    "                \n",
    "        def _swap_channels(im):\n",
    "            im2 = im.copy()\n",
    "            im2[:, :, 0] = im[:, :, 2]\n",
    "            im2[:, :, 2] = im[:, :, 0]\n",
    "            return im2\n",
    "        \n",
    "        for cluster_id, im in sorted(cluster_images.items(), key=lambda x: x[0]):\n",
    "            ax1 = fig.add_axes(\n",
    "                [\n",
    "                     0,\n",
    "                     cluster_id / len(cluster_images), \n",
    "                     face_labels_proportion,\n",
    "                     1 / len(cluster_images)\n",
    "                ]\n",
    "            )\n",
    "            ax1.axison = False\n",
    "            ax1.imshow(_swap_channels(im))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    channels = [c.name for c in Channel.objects.all()]\n",
    "    face_id_to_info = {\n",
    "        x['face__id'] : { \n",
    "            'channel' : x['face__shot__video__channel__name'],\n",
    "            'screentime' : x['screentime']\n",
    "        } for x in FaceIdentity.objects.filter(\n",
    "            identity__name=name.lower(), probability__gt=0.9\n",
    "        ).annotate(\n",
    "            screentime=ExpressionWrapper(\n",
    "                (F('face__shot__max_frame') - F('face__shot__min_frame')) / F('face__shot__video__fps'), \n",
    "                output_field=FloatField()\n",
    "            )\n",
    "        ).values('face__id', 'face__shot__video__channel__name', 'screentime')\n",
    "    }    \n",
    "        \n",
    "    clusters = defaultdict(list)\n",
    "    for face_id, cluster_id in face_kmeans(list(face_id_to_info.keys()), k=init_clusters):\n",
    "        clusters[cluster_id].append(face_id)\n",
    "    clusters = recluster_clusters(clusters, merge_cluster_thresh)\n",
    "    clusters = manual_recluster(clusters, examples_per_cluster)\n",
    "    \n",
    "    def _sort_clusters_by_screentime(clusters):\n",
    "        return {\n",
    "            i : v for i, v in enumerate(sorted(\n",
    "                clusters.values(), \n",
    "                key=lambda l: sum(face_id_to_info[x]['screentime'] for x in l)\n",
    "            ))\n",
    "        }\n",
    "    clusters = _sort_clusters_by_screentime(clusters)\n",
    "    \n",
    "    cluster_images = get_cluster_images(clusters, n=examples_per_cluster,\n",
    "                                        c=examples_per_cluster)    \n",
    "    raw_heatmap = np.zeros((len(clusters), len(channels)))\n",
    "    for cluster_id, face_ids in sorted(clusters.items(), key=lambda x: x[0]):\n",
    "        for face_id in face_ids:\n",
    "            raw_heatmap[cluster_id][\n",
    "                channels.index(face_id_to_info[face_id]['channel'])\n",
    "            ] += face_id_to_info[face_id]['screentime']\n",
    "            \n",
    "    _plot_heatmap_helper(\n",
    "        raw_heatmap, cluster_images,\n",
    "        'Images of {} and Screen Time'.format(name),\n",
    "        heatmap_label_fn=lambda x: '{:d}m'.format(int(x / 60))\n",
    "    )\n",
    "    _plot_heatmap_helper(\n",
    "        raw_heatmap / raw_heatmap.sum(axis=1)[:, np.newaxis], cluster_images,\n",
    "        'Images of {} and Screen Time (Row Normalized)'.format(name)\n",
    "    )\n",
    "    _plot_heatmap_helper(\n",
    "        raw_heatmap / raw_heatmap.sum(axis=0)[np.newaxis, :], cluster_images,\n",
    "        'Images of {} and Screen Time (Column Normalized)'.format(name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major Shootings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T23:29:58.763877Z",
     "start_time": "2018-08-07T23:29:58.720083Z"
    }
   },
   "outputs": [],
   "source": [
    "shootings = [\n",
    "    ('Muhammad Youssef Abdulazeez', 'Chattanooga', 'Jul 16, 2015'),\n",
    "    ('Chris Harper-Mercer', 'Umpqua Community College', 'Oct 1, 2015'),\n",
    "    ('Robert Lewis Dear Jr', 'Colorado Springs - Planned Parenthood', 'Nov 27, 2015'),\n",
    "    ('Syed Rizwan Farook', 'San Bernardino', 'Dec 2, 2015'), \n",
    "    ('Tashfeen Malik', 'San Bernardino', 'Dec 2, 2015'),\n",
    "    ('Dylann Roof', 'Charleston Shurch', 'Jun 17, 2015'),\n",
    "    ('Omar Mateen', 'Orlando Nightclub', 'Jun 12, 2016'),\n",
    "    ('Micah Xavier Johnson', 'Dallas Police', 'Jul 7-8, 2016'),\n",
    "    ('Gavin Eugene Long', 'Baton Rouge Police', 'Jul 17, 2016'),\n",
    "    ('Esteban Santiago-Ruiz', 'Ft. Lauderdale Airport', 'Jan 6, 2017'),\n",
    "    ('Willie Corey Godbolt', 'Lincoln County', 'May 28, 2017'),\n",
    "    ('Stephen Paddock', 'Las Vegas', 'Oct 1, 2017'),\n",
    "    ('Devin Patrick Kelley', 'San Antonio Church', 'Nov 5, 2017')\n",
    "]\n",
    "orm_set = { x.name for x in Thing.objects.filter(name__in=[s[0].lower() for s in shootings]) }\n",
    "for s in shootings:\n",
    "    assert s[0].lower() in orm_set, '{} is not in the database'.format(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:43:47.530810Z",
     "start_time": "2018-08-08T04:39:26.380238Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_still_montage('Tashfeen Malik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:48:35.577610Z",
     "start_time": "2018-08-08T04:44:42.303167Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_still_montage('Omar Mateen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:28:11.367859Z",
     "start_time": "2018-08-08T04:26:54.705295Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_still_montage('Syed Rizwan Farook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T04:55:56.499143Z",
     "start_time": "2018-08-08T04:53:53.626688Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_still_montage('Stephen Paddock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T05:01:36.498138Z",
     "start_time": "2018-08-08T05:00:50.538132Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_still_montage('Devin Patrick Kelley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
