{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Evaluating-Shot-Boundaries\" data-toc-modified-id=\"Evaluating-Shot-Boundaries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Evaluating Shot Boundaries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algorithm-1:-Greedy-Search\" data-toc-modified-id=\"Algorithm-1:-Greedy-Search-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Algorithm 1: Greedy Search</a></span></li><li><span><a href=\"#Algorithm-2:-Greedy-Search-with-Replacement\" data-toc-modified-id=\"Algorithm-2:-Greedy-Search-with-Replacement-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Algorithm 2: Greedy Search with Replacement</a></span></li><li><span><a href=\"#Statistics-on-Shot-Length\" data-toc-modified-id=\"Statistics-on-Shot-Length-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Statistics on Shot Length</a></span></li><li><span><a href=\"#Implementations\" data-toc-modified-id=\"Implementations-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Implementations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algorithm-1-Implementation\" data-toc-modified-id=\"Algorithm-1-Implementation-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Algorithm 1 Implementation</a></span></li><li><span><a href=\"#Algorithm-2-Implemenation\" data-toc-modified-id=\"Algorithm-2-Implemenation-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Algorithm 2 Implemenation</a></span></li></ul></li><li><span><a href=\"#Evaluating-Algorithms\" data-toc-modified-id=\"Evaluating-Algorithms-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Evaluating Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algorithm-1\" data-toc-modified-id=\"Algorithm-1-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Algorithm 1</a></span></li><li><span><a href=\"#Algorithm-2\" data-toc-modified-id=\"Algorithm-2-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Algorithm 2</a></span></li></ul></li></ul></li><li><span><a href=\"#Post-Processing-Shot-Boundaries\" data-toc-modified-id=\"Post-Processing-Shot-Boundaries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Post-Processing Shot Boundaries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coalesce-Sequences-of-Short-Microshots\" data-toc-modified-id=\"Coalesce-Sequences-of-Short-Microshots-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Coalesce Sequences of Short Microshots</a></span></li><li><span><a href=\"#Merge-all-remaining-short-shots-with-preceding-shot\" data-toc-modified-id=\"Merge-all-remaining-short-shots-with-preceding-shot-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Merge all remaining short shots with preceding shot</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:51.877271Z",
     "start_time": "2018-12-03T23:25:51.843975Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from esper.rekall import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.temporal_predicates import *\n",
    "from query.models import Video, Shot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:52.369933Z",
     "start_time": "2018-12-03T23:25:51.879417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load shot boundaries from database\n",
    "video_ids = [123, 186, 188, 377]\n",
    "eval_interval_collection = VideoIntervalCollection.from_django_qs(\n",
    "    Shot.objects.filter(video_id__in=video_ids, labeler_id=3)\n",
    ")\n",
    "cutting_interval_collection = VideoIntervalCollection.from_django_qs(\n",
    "    Shot.objects.filter(video_id__in=video_ids, labeler_id=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Shot Boundaries\n",
    "This is a notebook for evaluating precision/recall of shot boundaries against ground truth. For ground truth, we use James Cutting's annotations. Unfortunately, his annotations have a few problems that make working with them directly a little difficult:\n",
    "* In Cutting's annotations, \"Shot 1\" starts after studio logos, so it doesn't start at the beginning of the movie\n",
    "* Sometimes, it's not clear where \"Shot 1\" starts; in the Star Wars movies, for instance, it's sometimes difficult to tell if the shots begin before or after the initial plot description\n",
    "* By the end of the movie, the shot annotations are consistently 1-2 seconds off, even taking earlier offsets into account\n",
    "\n",
    "Because of these reasons, it's difficult to precisely compute precision/recall numbers for shot boundaries against Cutting's annotations. Given a set of shot boundaries we want to evaluate, we need to use some hueristics to determine which of Cutting's boundaries our shot boundaries correspond to. We have a few algorithms to compute these heuristics.\n",
    "\n",
    "To start with, we evaluate our microshots vs. Cutting's shot annotations for four movies:\n",
    "* Mr. & Mrs. Smith (2005)\n",
    "* Star Wars: Episode III - Revenge of the Sith (2005)\n",
    "* Star Wars: Episode V - The Empire Strikes Back (1980)\n",
    "* Harry Potter and the Goblet of Fire (2005)\n",
    "\n",
    "## Algorithm 1: Greedy Search\n",
    "Map each Cutting shot boundary to the nearest shot boundary from the evaluation set that is close enough by some threshold (such as two seconds). Each boundary in the evaluation set can only be mapped to by a single Cutting shot boundary. If no such boundary exists, mark the Cutting shot boundary as a \"missed\" boundary. Recall is `# of non-missed Cutting boundaries / total # of Cutting boundaries`, and precision is `# of evaluation shot boundaries that have a Cutting mapping / total # of evaluation shot boundaries`.\n",
    "\n",
    "This algorithm can run into problems when it assigns Cutting shot boundaries to the wrong shot boundaries in the evaluation set.\n",
    "\n",
    "## Algorithm 2: Greedy Search with Replacement\n",
    "This algorithm is like the greedy one, except we allow multiple Cutting boundaries to be mapped to the same evaluation shot boundary. Note that this is **not** an accurate representation of precision, but it does give us an upper bound on recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T19:15:56.704625Z",
     "start_time": "2018-11-28T19:15:56.664131Z"
    }
   },
   "source": [
    "## Statistics on Shot Length\n",
    "Before we try to match our shot boundaries to Cutting's boundaries, let's start by computing some statistics on how badly our shot durations differ from James Cutting's shot durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:52.743905Z",
     "start_time": "2018-12-03T23:25:52.677968Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph_shot_durations(n_bins, eval_interval_collection=eval_interval_collection):\n",
    "    for video_id in video_ids:\n",
    "        title = Video.objects.get(pk=video_id).name\n",
    "        eval_intervallist = eval_interval_collection.get_intervallist(video_id)\n",
    "        cutting_intervallist = cutting_interval_collection.get_intervallist(video_id)\n",
    "        eval_durations = sorted([interval.length() for interval in eval_intervallist.get_intervals()])\n",
    "        cutting_durations = sorted([interval.length() for interval in cutting_intervallist.get_intervals()])\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.hist([eval_durations, cutting_durations], n_bins, histtype='bar',\n",
    "                 label=['Computed Durations', 'Ground Truth Durations'])\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "        plt.show()\n",
    "\n",
    "def movingaverage(values, window_size, eval_interval_collection=eval_interval_collection):\n",
    "    window = np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(values, window, 'same')\n",
    "        \n",
    "def graph_moving_averages(window_size, eval_interval_collection=eval_interval_collection):\n",
    "    for video_id in video_ids:\n",
    "        title = Video.objects.get(pk=video_id).name\n",
    "        eval_intervallist = eval_interval_collection.get_intervallist(video_id)\n",
    "        cutting_intervallist = cutting_interval_collection.get_intervallist(video_id)\n",
    "        \n",
    "        eval_x = [interval.get_start() for interval in eval_intervallist.get_intervals()]\n",
    "        cutting_x = [interval.get_start() for interval in cutting_intervallist.get_intervals()]\n",
    "        eval_durations = [interval.length() for interval in eval_intervallist.get_intervals()]\n",
    "        cutting_durations = [interval.length() for interval in cutting_intervallist.get_intervals()]\n",
    "        \n",
    "        eval_avg = movingaverage(eval_durations, window_size)\n",
    "        cutting_avg = movingaverage(cutting_durations, window_size)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.plot(eval_x, eval_avg, label='Computed Durations')\n",
    "        ax.plot(cutting_x, cutting_avg, label='Ground Truth Durations')\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:54.499102Z",
     "start_time": "2018-12-03T23:25:52.746511Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_shot_durations(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:55.240524Z",
     "start_time": "2018-12-03T23:25:54.500904Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.095357Z",
     "start_time": "2018-12-03T23:25:55.243607Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.144859Z",
     "start_time": "2018-12-03T23:25:56.097717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate precision/recall from algorithm results\n",
    "def precision_recall(eval_intervallist, cutting_intervallist, algorithm, threshold=48):\n",
    "    valid, used_eval, matched_cutting = algorithm(eval_intervallist, cutting_intervallist, threshold)\n",
    "    precision = len(used_eval) / len(valid)\n",
    "    recall = len(matched_cutting) / len(cutting_intervallist.get_intervals())\n",
    "    return precision, recall\n",
    "\n",
    "def print_precision_recall(precision_recall):\n",
    "    print('Precision:', precision_recall[0])\n",
    "    print('Recall:', precision_recall[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.188114Z",
     "start_time": "2018-12-03T23:25:56.146753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Greedy Search precision/recall\n",
    "def greedy_match(eval_intervallist, cutting_intervallist, threshold=48):\n",
    "    '''\n",
    "    eval_intervallist and cutting_intervallist are IntervalLists.\n",
    "    threshold is the threshold to search nearby.\n",
    "    \n",
    "    Returns tuple of:\n",
    "    * list of eval boundaries (start times only) within Cutting's\n",
    "      boundaries +/- threshold\n",
    "    * list of eval boundaries that have a matching Cutting boundary\n",
    "    * list of Cutting boundaries that have a matching eval boundary\n",
    "    '''\n",
    "    min_start = cutting_intervallist.get_intervals()[0].get_start()\n",
    "    max_end = cutting_intervallist.get_intervals()[-1].get_end() + threshold\n",
    "    \n",
    "    # construct ordered list of valid eval boundaries\n",
    "    valid_eval_boundaries = [\n",
    "        interval.get_start()\n",
    "        for interval in eval_intervallist.get_intervals()\n",
    "        if interval.get_start() >= min_start and interval.get_start() <= max_end\n",
    "    ]\n",
    "    \n",
    "    # construct ordered list of cutting boundaries\n",
    "    cutting_boundaries = [\n",
    "        interval.get_start()\n",
    "        for interval in cutting_intervallist.get_intervals()\n",
    "    ]\n",
    "    \n",
    "    used_eval_boundaries = set()\n",
    "    matched_cutting_boundaries = set()\n",
    "    for boundary in cutting_boundaries:\n",
    "        best_eval = None\n",
    "        for eval_boundary in valid_eval_boundaries:\n",
    "            if eval_boundary + threshold < boundary:\n",
    "                continue\n",
    "            if eval_boundary - threshold > boundary:\n",
    "                break\n",
    "            if eval_boundary in used_eval_boundaries:\n",
    "                continue\n",
    "            if (best_eval is None or\n",
    "                abs(boundary - eval_boundary) < abs(boundary - best_eval)):\n",
    "                best_eval = eval_boundary\n",
    "        if best_eval is not None:\n",
    "            used_eval_boundaries.add(best_eval)\n",
    "            matched_cutting_boundaries.add(boundary)\n",
    "    \n",
    "    return valid_eval_boundaries, sorted(list(used_eval_boundaries)), sorted(list(matched_cutting_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 Implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.234255Z",
     "start_time": "2018-12-03T23:25:56.190331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Greedy Search with replacement\n",
    "def greedy_match_with_replacement(eval_intervallist, cutting_intervallist, threshold=48):\n",
    "    '''\n",
    "    eval_intervallist and cutting_intervallist are IntervalLists.\n",
    "    threshold is the threshold to search nearby.\n",
    "    \n",
    "    Returns tuple of:\n",
    "    * list of eval boundaries (start times only) within Cutting's\n",
    "      boundaries +/- threshold\n",
    "    * list of eval boundaries that have a matching Cutting boundary\n",
    "    * list of Cutting boundaries that have a matching eval boundary\n",
    "    '''\n",
    "    min_start = cutting_intervallist.get_intervals()[0].get_start()\n",
    "    max_end = cutting_intervallist.get_intervals()[-1].get_end() + threshold\n",
    "    \n",
    "    # construct ordered list of valid eval boundaries\n",
    "    valid_eval_boundaries = [\n",
    "        interval.get_start()\n",
    "        for interval in eval_intervallist.get_intervals()\n",
    "        if interval.get_start() >= min_start and interval.get_start() <= max_end\n",
    "    ]\n",
    "    \n",
    "    # construct ordered list of cutting boundaries\n",
    "    cutting_boundaries = [\n",
    "        interval.get_start()\n",
    "        for interval in cutting_intervallist.get_intervals()\n",
    "    ]\n",
    "    \n",
    "    used_eval_boundaries = set()\n",
    "    matched_cutting_boundaries = set()\n",
    "    for boundary in cutting_boundaries:\n",
    "        best_eval = None\n",
    "        for eval_boundary in valid_eval_boundaries:\n",
    "            if eval_boundary + threshold < boundary:\n",
    "                continue\n",
    "            if eval_boundary - threshold > boundary:\n",
    "                break\n",
    "            if (best_eval is None or\n",
    "                abs(boundary - eval_boundary) < abs(boundary - best_eval)):\n",
    "                best_eval = eval_boundary\n",
    "        if best_eval is not None:\n",
    "            used_eval_boundaries.add(best_eval)\n",
    "            matched_cutting_boundaries.add(boundary)\n",
    "    \n",
    "    return valid_eval_boundaries, sorted(list(used_eval_boundaries)), sorted(list(matched_cutting_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.286050Z",
     "start_time": "2018-12-03T23:25:56.235974Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_precision_recall(algorithm, threshold):\n",
    "    for video_id in video_ids:\n",
    "        print(Video.objects.get(pk=video_id).name)\n",
    "        print_precision_recall(precision_recall(\n",
    "            eval_interval_collection.get_intervallist(video_id),\n",
    "            cutting_interval_collection.get_intervallist(video_id),\n",
    "            algorithm,\n",
    "            threshold=threshold\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.339246Z",
     "start_time": "2018-12-03T23:25:56.287838Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph_precision_recall(algorithm, threshold):\n",
    "    data = []\n",
    "    for video_id in video_ids:\n",
    "        name = Video.objects.get(pk=video_id).name\n",
    "        precision, recall = precision_recall(\n",
    "            eval_interval_collection.get_intervallist(video_id),\n",
    "            cutting_interval_collection.get_intervallist(video_id),\n",
    "            algorithm,\n",
    "            threshold=threshold\n",
    "        )\n",
    "        data.append((precision, recall, name))\n",
    "    \n",
    "    precisions = [precision for precision, _, _ in data]\n",
    "    recalls = [recall for _, recall, _ in data]\n",
    "    names = [name for _, _, name in data]\n",
    "    N = len(names)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    width = 0.35\n",
    "    ind = np.arange(N)\n",
    "    p1 = ax.bar(ind, precisions, width)\n",
    "    p2 = ax.bar(ind + width, recalls, width)\n",
    "    \n",
    "    ax.set_title('Precision and Recall by movie')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.set_ylim((0, 1))\n",
    "    \n",
    "    ax.legend((p1[0], p2[0]), ('Precision', 'Recall'))\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar displaying its height\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%f' % height,\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    autolabel(p1)\n",
    "    autolabel(p2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.375747Z",
     "start_time": "2018-12-03T23:25:56.341307Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph_inaccuracies(algorithm, threshold, n_bins):\n",
    "    for video_id in video_ids:\n",
    "        title = Video.objects.get(pk=video_id).name\n",
    "        eval_intervallist = eval_interval_collection.get_intervallist(video_id)\n",
    "        cutting_intervallist = cutting_interval_collection.get_intervallist(video_id)\n",
    "        valid, used_eval, matched_cutting = algorithm(eval_intervallist, cutting_intervallist, threshold=threshold)\n",
    "        inaccurate_eval = [boundary for boundary in valid if boundary not in used_eval]\n",
    "        missed_shots = [interval.get_start()\n",
    "                        for interval in cutting_intervallist.get_intervals()\n",
    "                        if interval.get_start() not in matched_cutting]\n",
    "        ax = plt.gca()\n",
    "        ax.hist([inaccurate_eval, missed_shots], n_bins, histtype='bar',\n",
    "                 label=['Inaccurate shot boundaries', 'Missed shot boundaries'])\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T18:21:29.851303Z",
     "start_time": "2018-11-28T18:21:29.809756Z"
    }
   },
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:56.863289Z",
     "start_time": "2018-12-03T23:25:56.377763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see raw precision/recall numbers\n",
    "evaluate_precision_recall(greedy_match, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:25:57.559740Z",
     "start_time": "2018-12-03T23:25:56.865336Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_precision_recall(greedy_match, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:02.241273Z",
     "start_time": "2018-12-03T23:25:57.562037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's look at where our inaccuracies are\n",
    "graph_inaccuracies(greedy_match, 72, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:02.769197Z",
     "start_time": "2018-12-03T23:26:02.243482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see raw precision/recall numbers\n",
    "evaluate_precision_recall(greedy_match_with_replacement, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:03.463978Z",
     "start_time": "2018-12-03T23:26:02.771389Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_precision_recall(greedy_match_with_replacement, 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:08.200025Z",
     "start_time": "2018-12-03T23:26:03.466002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's look at where our inaccuracies are\n",
    "graph_inaccuracies(greedy_match_with_replacement, 72, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing Shot Boundaries\n",
    "Let's see if we can do better by combining sequences of very short shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:09.104486Z",
     "start_time": "2018-12-03T23:26:08.202033Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many very short shots do we have?\n",
    "def graph_short_shot_durations(min_length=1, max_length=20,\n",
    "                               eval_interval_collection=eval_interval_collection):\n",
    "    for video_id in video_ids:\n",
    "        title = Video.objects.get(pk=video_id).name\n",
    "        eval_intervallist = eval_interval_collection.get_intervallist(video_id).filter_length(\n",
    "            min_length=min_length, max_length=max_length\n",
    "        )\n",
    "        cutting_intervallist = cutting_interval_collection.get_intervallist(video_id).filter_length(\n",
    "            min_length=min_length, max_length=max_length\n",
    "        )\n",
    "        eval_durations = sorted([interval.length() for interval in eval_intervallist.get_intervals()])\n",
    "        cutting_durations = sorted([interval.length() for interval in cutting_intervallist.get_intervals()])\n",
    "        \n",
    "        n_bins = max_length - min_length + 1\n",
    "        ax = plt.gca()\n",
    "        ax.hist([eval_durations, cutting_durations], n_bins, histtype='bar',\n",
    "                 label=['Computed Durations', 'Ground Truth Durations'])\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "        plt.show()\n",
    "\n",
    "graph_short_shot_durations(1, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most shots shorter than 15 frames are bad. Let's first merge all continuous sequences of 15 frames or shorter and then see what we get from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:10.141293Z",
     "start_time": "2018-12-03T23:26:09.108961Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_interval_collection_shortcoalesced = eval_interval_collection.set_union(\n",
    "    eval_interval_collection.filter_length(\n",
    "        max_length=15).dilate(1).coalesce().dilate(-1)\n",
    ").coalesce()\n",
    "\n",
    "graph_short_shot_durations(1, 25, eval_interval_collection=eval_interval_collection_shortcoalesced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gets some of the changes, but not all. Let's merge any remaining sequences that 15 frames or shorter to the preceding shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:11.215443Z",
     "start_time": "2018-12-03T23:26:10.143545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_interval_collection_no_short = eval_interval_collection_shortcoalesced.filter_length(\n",
    "    max_length=15\n",
    ").merge(\n",
    "    eval_interval_collection_shortcoalesced,\n",
    "    predicate=after(max_dist=15)\n",
    ").set_union(eval_interval_collection_shortcoalesced).coalesce()\n",
    "\n",
    "graph_short_shot_durations(1, 25, eval_interval_collection=eval_interval_collection_no_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:12:21.080681Z",
     "start_time": "2018-12-03T23:12:21.047221Z"
    }
   },
   "source": [
    "### Coalesce Sequences of Short Microshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:12.912456Z",
     "start_time": "2018-12-03T23:26:11.217540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Graph some statistics\n",
    "graph_shot_durations(100, eval_interval_collection=eval_interval_collection_shortcoalesced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:13.662872Z",
     "start_time": "2018-12-03T23:26:12.914436Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(100, eval_interval_collection=eval_interval_collection_shortcoalesced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:14.677765Z",
     "start_time": "2018-12-03T23:26:13.664894Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(1, eval_interval_collection=eval_interval_collection_shortcoalesced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all remaining short shots with preceding shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:16.289751Z",
     "start_time": "2018-12-03T23:26:14.680368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Graph some statistics\n",
    "graph_shot_durations(100, eval_interval_collection=eval_interval_collection_no_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:17.019315Z",
     "start_time": "2018-12-03T23:26:16.291965Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(100, eval_interval_collection=eval_interval_collection_no_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:26:17.849352Z",
     "start_time": "2018-12-03T23:26:17.021190Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_moving_averages(1, eval_interval_collection=eval_interval_collection_no_short)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
