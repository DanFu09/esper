{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ScratchPad-From-This-Point-On\" data-toc-modified-id=\"ScratchPad-From-This-Point-On-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>ScratchPad From This Point On</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:29.841656Z",
     "start_time": "2018-12-07T23:00:29.812164Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "import esper.stdlib as stdlib\n",
    "from django.db.models import ExpressionWrapper, F\n",
    "import rekall as rk\n",
    "import rekall.parsers\n",
    "import rekall.payload_predicates\n",
    "import esper.rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from query.models import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:29.960326Z",
     "start_time": "2018-12-07T23:00:29.845386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the shot scale in terms of labels: face height percentage.\n",
    "# Using https://filmanalysis.coursepress.yale.edu/cinematography/ as reference.\n",
    "from enum import IntEnum\n",
    "class ShotScale(IntEnum):\n",
    "    \"\"\" L=Long CU=Close-up X=Extreme M=Medium \"\"\"\n",
    "    UNK = 0\n",
    "    XL = 1\n",
    "    L = 2\n",
    "    ML = 3\n",
    "    M = 4\n",
    "    CU = 5\n",
    "    XCU = 6\n",
    "\n",
    "# Limitations:\n",
    "#   Extreme Close-up is difficult to get since face detector does not work on those frames.\n",
    "#   Long shots and Extreme Long shots are difficult to get since faces are too small for face detectors.\n",
    "def face_height_to_shot_scale(face_height):\n",
    "    if face_height >= 0.95:\n",
    "        return ShotScale.XCU\n",
    "    if face_height >= 0.5:\n",
    "        return ShotScale.CU\n",
    "    if face_height >= 0.25:\n",
    "        return ShotScale.M\n",
    "    if face_height >= 0.12:\n",
    "        return ShotScale.ML\n",
    "    # if face_height >= 0.05:\n",
    "    #     return ShotScale.L\n",
    "    # return ShotScale.XL\n",
    "    return ShotScale.UNK\n",
    "\n",
    "def pose_keypoints_to_shot_scale(keypoints):\n",
    "    def visible(pose, positions):\n",
    "        return np.any(pose[positions, 2]>0)\n",
    "    def get_y(pose, positions, reduce):\n",
    "        rows = pose[positions, :]\n",
    "        heights = rows[rows[:,2]>0, 1] # only consider existing keypoints\n",
    "        return reduce(heights)\n",
    "    def get_height(pose, upper_pos, lower_pose):\n",
    "        return get_y(pose, lower_pose, max) - get_y(pose, upper_pos, min)\n",
    "    pose = np.array(keypoints).reshape((-1,3))\n",
    "    ankles = [Pose.RAnkle, Pose.LAnkle]\n",
    "    knees = [Pose.RKnee, Pose.LKnee]\n",
    "    hips = [Pose.RHip, Pose.LHip]\n",
    "    shoulders = [Pose.RShoulder, Pose.LShoulder]\n",
    "    head = [Pose.Nose, Pose.LEye, Pose.REye, Pose.REar, Pose.LEar]\n",
    "    show_ankle = visible(pose, ankles)\n",
    "    show_knee = visible(pose, knees)\n",
    "    show_hip = visible(pose, hips)\n",
    "    show_shoulder = visible(pose, shoulders)\n",
    "    show_head = visible(pose, head)\n",
    "    if show_head and show_shoulder and show_hip and show_knee and show_ankle:\n",
    "        if get_height(pose, head, ankles+knees+hips) >= 0.5:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder and show_hip and show_knee:\n",
    "        height = get_height(pose, head, knees+hips)\n",
    "        if height >= 0.75:\n",
    "            return ShotScale.ML\n",
    "        elif height >= 0.4:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder and show_hip:\n",
    "        height = get_height(pose, head, hips)\n",
    "        if height >= 0.75:\n",
    "            return ShotScale.M\n",
    "        elif height >= 0.5:\n",
    "            return ShotScale.ML\n",
    "        elif height >= 0.2:\n",
    "            return ShotScale.L\n",
    "        return ShotScale.XL\n",
    "    if show_head and show_shoulder:\n",
    "        height = get_height(pose, head, shoulders)\n",
    "        if height >= 0.5:\n",
    "            return ShotScale.CU\n",
    "        return ShotScale.UNK\n",
    "    if show_head:\n",
    "        height = get_height(pose, head, head+[Pose.Neck])\n",
    "        if height >= 0.5:\n",
    "            return ShotScale.CU\n",
    "        if (visible(pose, [Pose.REye]) and visible(pose, [Pose.LEye]) and visible(pose, [Pose.Nose])):\n",
    "            eyes_to_nose = pose[Pose.Nose, 1] - (pose[Pose.REye, 1] + pose[Pose.LEye, 1]) / 2\n",
    "            if eyes_to_nose >= 0.3:\n",
    "                return ShotScale.XCU\n",
    "            elif eyes_to_nose >= 0.2:\n",
    "                return ShotScale.CU\n",
    "    return ShotScale.UNK    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:30.231364Z",
     "start_time": "2018-12-07T23:00:29.963445Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for operating on QuerySets\n",
    "def annotate_face_height(qs):\n",
    "    return qs.annotate(face_height=Face.height_expr())\n",
    "\n",
    "def filter_faces_by_face_height(qs, min_height=0.0, max_height=1.0):\n",
    "    return qs.filter(face_height__gte=min_height, face_height__lt=max_height)\n",
    "\n",
    "def annotate_frame_and_video(qs):\n",
    "    return qs.annotate(frame_number=F('frame__number'), video_id=F('frame__video__id'))\n",
    "\n",
    "def to_simple_display(frames):\n",
    "    \"\"\"values need to have frame_number, video_id fields\"\"\"\n",
    "    return stdlib.simple_result([{'video': row.video_id,\n",
    "                                'min_frame': row.frame_number,\n",
    "                                 'objects':[]} for row in frames], 'Video')\n",
    "\n",
    "def bbox_payload_to_object(bbox, video):\n",
    "    return {'id': video,\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': bbox['x1'],\n",
    "            'bbox_x2': bbox['x2'],\n",
    "            'bbox_y1': bbox['y1'],\n",
    "            'bbox_y2': bbox['y2'],\n",
    "            }\n",
    "\n",
    "def pose_payload_to_object(pose, video):\n",
    "    return {\n",
    "        \"id\": video,\n",
    "        'type': 'pose',\n",
    "        'labeler': 'UNKNOWN',\n",
    "        'keypoints': pose\n",
    "    }\n",
    "\n",
    "def payload_to_objects(payload, video_id):\n",
    "    result = []\n",
    "    result += [bbox_payload_to_object(x, video_id) for x in payload.get('bbox', [])]\n",
    "    result += [pose_payload_to_object(x, video_id) for x in payload.get('pose', [])]\n",
    "    return result\n",
    "    \n",
    "\n",
    "def pose_payload_parser():\n",
    "    def get_pose(row):\n",
    "        return {\n",
    "            'hand_left': row.hand_keypoints()[0].tolist(),\n",
    "            'hand_right': row.hand_keypoints()[1].tolist(),\n",
    "            'pose': row.pose_keypoints().tolist(),\n",
    "            'face': row.face_keypoints().tolist()\n",
    "        }\n",
    "    return get_pose\n",
    "\n",
    "# Convert named payloads to objects to send to vgrid\n",
    "def intrvllists_to_result_general(intrvllists, limit=None, stride=1):\n",
    "    \"\"\" Gets a result for intrvllists, assuming that the objects are bounding boxes.\n",
    "    \"\"\"\n",
    "    materialized_results = []\n",
    "    for video in intrvllists:\n",
    "        intrvllist = intrvllists[video].get_intervals()\n",
    "        if len(intrvllist) == 0:\n",
    "            continue\n",
    "        if limit is not None and len(materialized_results) > limit:\n",
    "            break\n",
    "        for intrvl in intrvllist[::stride]:\n",
    "            materialized_results.append({\n",
    "                'video': video,\n",
    "                'min_frame': (intrvl.get_start() + intrvl.get_end()) / 2,\n",
    "                'objects': payload_to_objects(intrvl.get_payload(), video)\n",
    "            })\n",
    "          \n",
    "\n",
    "    if limit is None:\n",
    "        limit = len(materialized_results)\n",
    "    materialized_results = materialized_results[:limit]\n",
    "\n",
    "    groups = [{'type': 'flat', 'label': '', 'elements': [r]}\n",
    "            for r in materialized_results]\n",
    "\n",
    "    return {'result': groups, 'count': len(list(intrvllists.keys())), 'type': 'Video'}\n",
    "\n",
    "# Put ouput of `parser` under `name`\n",
    "def with_named_payload(name, parser):\n",
    "    def getter(obj):\n",
    "        return {name: parser(obj)}\n",
    "    return getter\n",
    "\n",
    "def with_bbox():\n",
    "    return with_named_payload('bbox',\n",
    "             rk.parsers.in_array(\n",
    "               rk.parsers.bbox_payload_parser(VideoIntervalCollection.django_accessor)))\n",
    "\n",
    "def with_pose():\n",
    "    return with_named_payload('pose',\n",
    "            rk.parsers.in_array(\n",
    "               pose_payload_parser()))\n",
    "\n",
    "def with_attr(attr):\n",
    "    return with_named_payload(attr, lambda obj:getattr(obj, attr))\n",
    "\n",
    "def shot_scale_payload_merge(p1, p2):\n",
    "    \"\"\" Merges all bboxes and poses, but take the largest face_height.\n",
    "        This assumes that the intervals to be merged are single-frame intervals.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    agg_terms = ['bbox', 'pose']\n",
    "    max_terms = ['shot_scale', 'face_height']\n",
    "    for term in agg_terms:\n",
    "        if term in p1 or term in p2:\n",
    "            result[term] =  p1.get(term, [])+p2.get(term, [])\n",
    "    for term in max_terms:\n",
    "        if term in p1 or term in p2:\n",
    "            result[term]= max(p1.get(term, 0), p2.get(term, 0))\n",
    "    return result\n",
    "\n",
    "def has_entire_body(p):\n",
    "    if 'pose' not in p:\n",
    "        return False\n",
    "    poses = p['pose']\n",
    "    for all_pose in poses:\n",
    "        pose = np.array(all_pose['pose']).reshape((-1,3)) # Get the body pose\n",
    "        if np.all(pose[:,2]>0):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_shot_scale_fn(s):\n",
    "    def has_scale(p):\n",
    "        return p['shot_scale'] == s\n",
    "    return has_scale\n",
    "\n",
    "# Derive from face_height or pose\n",
    "def add_shot_scale_payload(p):\n",
    "    s = ShotScale.UNK\n",
    "    if 'face_height' in p:\n",
    "        s = max(s, face_height_to_shot_scale(p['face_height']))\n",
    "    if 'pose' in p:\n",
    "        for all_pose in p['pose']:\n",
    "            s = max(s, pose_keypoints_to_shot_scale(all_pose['pose']))\n",
    "    p['shot_scale'] = s\n",
    "    return p\n",
    "\n",
    "def map_payload(payload_fn):\n",
    "    def fn(interval):\n",
    "        interval.payload = payload_fn(interval.payload)\n",
    "        return interval\n",
    "    return fn\n",
    "        \n",
    "def get_video_interval_collection(qs, with_payload=None):\n",
    "    return VideoIntervalCollection.from_django_qs(qs, schema={\n",
    "        \"start\": \"frame_number\",\n",
    "        \"end\": \"frame_number\"\n",
    "    }, with_payload=with_payload)\n",
    "\n",
    "def get_all_frames_with_shot_scale(video_id, scale):\n",
    "    collection = get_video_interval_collection(\n",
    "            annotate_frame_and_video(annotate_face_height(Face.objects)).filter(video_id=video_id),\n",
    "            rk.parsers.merge_dict_parsers([with_attr('face_height'), with_bbox()]))\n",
    "    collection = collection.set_union(get_video_interval_collection(\n",
    "             annotate_frame_and_video(Pose.objects).filter(video_id=video_id),\n",
    "             with_pose()))\n",
    "    collection = collection.map(map_payload(add_shot_scale_payload))\n",
    "    collection = collection.coalesce(shot_scale_payload_merge)\n",
    "    collection = collection.filter(rk.payload_predicates.payload_satisfies(get_shot_scale_fn(scale)))\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:02:21.473257Z",
     "start_time": "2018-12-07T23:02:01.250493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9551628b2a34cab8d77813a0d539503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(jsglobals={'bucket': 'esper', 'queries': [['All faces', 'def all_faces():\\n    from query.models iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_general(\n",
    "        get_all_frames_with_shot_scale(377, ShotScale.XL).get_allintervals(),\n",
    "        limit=100, stride=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScratchPad From This Point On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:00:48.329109Z",
     "start_time": "2018-12-07T23:00:48.298393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [Video(id: 377, path: movies/harry_potter_and_the_goblet_of_fire_2005.mp4, num_frames: 225985, fps: 23.9760257778482, width: 1920, height: 800, has_captions: False, name: harry potter and the goblet of fire, year: 2005)]>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(Video.objects.filter(name=\"the godfather\"))\n",
    "#POSE_ID=5010\n",
    "#print(Pose.objects.filter(pk=POSE_ID)[0].pose_keypoints())\n",
    "#esper_widget(stdlib.qs_to_result(Pose.objects.filter(pk=POSE_ID)))\n",
    "Video.objects.filter(name__contains=\"goblet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
