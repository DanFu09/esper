{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Shot-Boundary-Eval\" data-toc-modified-id=\"Shot-Boundary-Eval-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Shot Boundary Eval</a></span><ul class=\"toc-item\"><li><span><a href=\"#Human-(Dan-and-David)-Annotated-Clips\" data-toc-modified-id=\"Human-(Dan-and-David)-Annotated-Clips-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Human (Dan and David) Annotated Clips</a></span></li><li><span><a href=\"#Microshots\" data-toc-modified-id=\"Microshots-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Microshots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shot-Boundaries\" data-toc-modified-id=\"Shot-Boundaries-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Shot Boundaries</a></span></li><li><span><a href=\"#Incorporating-Motion-Flow\" data-toc-modified-id=\"Incorporating-Motion-Flow-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Incorporating Motion Flow</a></span></li><li><span><a href=\"#Compute-which-shots-are-accurate/inaccurate\" data-toc-modified-id=\"Compute-which-shots-are-accurate/inaccurate-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Compute which shots are accurate/inaccurate</a></span></li><li><span><a href=\"#Precision/Recall-across-the-three-clips\" data-toc-modified-id=\"Precision/Recall-across-the-three-clips-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Precision/Recall across the three clips</a></span></li><li><span><a href=\"#Visualizing-Mistakes-and-Missed-Shot-Boundaries\" data-toc-modified-id=\"Visualizing-Mistakes-and-Missed-Shot-Boundaries-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Visualizing Mistakes and Missed Shot Boundaries</a></span></li><li><span><a href=\"#Frames-at-Mistakes-and-Missed-Boundaries\" data-toc-modified-id=\"Frames-at-Mistakes-and-Missed-Boundaries-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>Frames at Mistakes and Missed Boundaries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clip-1\" data-toc-modified-id=\"Clip-1-1.2.6.1\"><span class=\"toc-item-num\">1.2.6.1&nbsp;&nbsp;</span>Clip 1</a></span></li><li><span><a href=\"#Clip-2\" data-toc-modified-id=\"Clip-2-1.2.6.2\"><span class=\"toc-item-num\">1.2.6.2&nbsp;&nbsp;</span>Clip 2</a></span></li><li><span><a href=\"#Clip-3\" data-toc-modified-id=\"Clip-3-1.2.6.3\"><span class=\"toc-item-num\">1.2.6.3&nbsp;&nbsp;</span>Clip 3</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:46.455522Z",
     "start_time": "2018-12-07T21:52:45.479113Z"
    }
   },
   "outputs": [],
   "source": [
    "import scannerpy\n",
    "import scannertools as st\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from esper.prelude import *\n",
    "from rekall.interval_list import IntervalList\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.logical_predicates import *\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.payload_predicates import *\n",
    "from rekall.list_predicates import *\n",
    "from rekall.bbox_predicates import *\n",
    "from rekall.spatial_predicates import *\n",
    "from rekall.merge_ops import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shot Boundary Eval\n",
    "In this notebook we evaluate shot boundaries against human annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:46.500841Z",
     "start_time": "2018-12-07T21:52:46.459148Z"
    }
   },
   "outputs": [],
   "source": [
    "video_id = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human (Dan and David) Annotated Clips\n",
    "We manually annotated shot boundaries in three five-minute clips in the movie Mr. and Mrs. Smith (2005). The first clip is minutes 10-15, the second clip is minutes 60-65, and the third clip is minutes 90-95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:46.572627Z",
     "start_time": "2018-12-07T21:52:46.503140Z"
    }
   },
   "outputs": [],
   "source": [
    "human_shots = IntervalList(\n",
    "    [(shot.min_frame, shot.max_frame, shot.id)\n",
    "     for shot in Shot.objects.filter(video_id=video_id, labeler_id=12).all()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:46.619412Z",
     "start_time": "2018-12-07T21:52:46.576430Z"
    }
   },
   "outputs": [],
   "source": [
    "clips = human_shots.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:46.672702Z",
     "start_time": "2018-12-07T21:52:46.622255Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, clip in enumerate(clips.get_intervals()):\n",
    "    print('Clip {} starts at frame {} and ends at frame {}'.format(\n",
    "        i+1, clip.get_start(), clip.get_end()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microshots\n",
    "We use RGB color histograms to generate candidate microshots by computing the difference between color histograms and detecting outliers in the difference. Then we take out any shot boundaries that are fewer than ten frames after another shot boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:52:47.966272Z",
     "start_time": "2018-12-07T21:52:46.747682Z"
    }
   },
   "outputs": [],
   "source": [
    "db = scannerpy.Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.054929Z",
     "start_time": "2018-12-07T21:52:47.970589Z"
    }
   },
   "outputs": [],
   "source": [
    "videos = Video.objects.filter(id=123).all()\n",
    "hists = st.histograms.compute_histograms(\n",
    "    db,\n",
    "    videos=[video.for_scannertools() for video in videos]\n",
    ")\n",
    "\n",
    "# Do simple outlier detection to find boundaries between shots\n",
    "WINDOW_SIZE=500\n",
    "hists_list = [hist for hist in hists[0].load()]\n",
    "diffs = np.array([\n",
    "    np.mean([distance.chebyshev(hists_list[i - 1][j], hists_list[i][j]) for j in range(3)])\n",
    "    for i in range(1, len(hists_list))\n",
    "])\n",
    "diffs = np.insert(diffs, 0, 0)\n",
    "n = len(diffs)\n",
    "boundaries = []\n",
    "for i in range(1, n):\n",
    "    window = diffs[max(i - WINDOW_SIZE, 0):min(i + WINDOW_SIZE, n)]\n",
    "    if diffs[i] - np.mean(window) > 2.5 * np.std(window):\n",
    "        boundaries.append(i)\n",
    "        \n",
    "video = videos[0]\n",
    "frames = list(range(0, video.num_frames, int(round(video.fps) / 2)))\n",
    "frames_set = set(frames)\n",
    "frames_set = frames_set.union(set(boundaries))\n",
    "frames_set = frames_set.union(set([boundary - 1 for boundary in boundaries if boundary > 0]))\n",
    "frames = sorted(list(frames_set))\n",
    "\n",
    "faces = st.face_detection.detect_faces(\n",
    "    db,\n",
    "    videos=[video.for_scannertools()],\n",
    "    frames=[frames]\n",
    ")\n",
    "\n",
    "faces_per_frames = IntervalList([\n",
    "    (frame, frame, facelist)\n",
    "    for frame, facelist in zip(frames, faces[0].load())\n",
    "])\n",
    "\n",
    "transitions = IntervalList([(boundary - 1, boundary, 0) for boundary in boundaries])\n",
    "\n",
    "faces_at_boundaries = faces_per_frames.filter_against(\n",
    "    transitions,\n",
    "    predicate=overlaps()\n",
    ").filter(payload_satisfies(length_at_least(1)))\n",
    "\n",
    "# Get all transitions where there are faces before and after the transition\n",
    "boundaries_with_faces = transitions.filter_against(\n",
    "    faces_at_boundaries, predicate=starts_inv()\n",
    ").filter_against(\n",
    "    transitions.filter_against(faces_at_boundaries, predicate=finishes_inv()),\n",
    "    predicate=equal()\n",
    ")\n",
    "\n",
    "boundaries_starting_faces = boundaries_with_faces.merge(\n",
    "    faces_at_boundaries, predicate = starts_inv(),\n",
    "    payload_merge_op = payload_second\n",
    ")\n",
    "\n",
    "boundaries_ending_faces = boundaries_with_faces.merge(\n",
    "    faces_at_boundaries, predicate = finishes_inv(),\n",
    "    payload_merge_op = payload_second\n",
    ")\n",
    "\n",
    "boundaries_transition_faces = boundaries_starting_faces.merge(\n",
    "    boundaries_ending_faces, predicate=equal(),\n",
    "    payload_merge_op = lambda starts_payload, finishes_payload: { 'starts': starts_payload, 'finishes': finishes_payload }\n",
    ")\n",
    "\n",
    "def similar_face_lists(faces):\n",
    "    graph = {\n",
    "        'nodes': [\n",
    "            {\n",
    "                'name': 'face{}'.format(idx),\n",
    "                'predicates': [ position(face.x1, face.y1, face.x2, face.y2, epsilon=.05),\n",
    "                              lambda face: face['score'] > 0.9 ]\n",
    "            }\n",
    "            for idx, face in enumerate(faces['starts'])\n",
    "            if face.score > 0.9\n",
    "        ],\n",
    "        'edges': []\n",
    "    }\n",
    "    return scene_graph(graph, exact=True)([\n",
    "        { 'x1': face.x1, 'y1': face.y1, 'x2': face.x2, 'y2': face.y2, 'score': face.score }\n",
    "        for face in faces['finishes']\n",
    "    ])\n",
    "    \n",
    "bad_boundaries = boundaries_transition_faces.filter(\n",
    "    payload_satisfies(similar_face_lists)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.112380Z",
     "start_time": "2018-12-07T21:53:15.057810Z"
    }
   },
   "outputs": [],
   "source": [
    "def boundaries_to_shots_fold(acc, frame):\n",
    "    if acc == []:\n",
    "        return [frame.copy()]\n",
    "    top = acc[-1]\n",
    "    top.end = frame.start - 1\n",
    "    if top.length() > 0:\n",
    "        acc.append(frame.copy())\n",
    "    else:\n",
    "        top.end = frame.start\n",
    "    return acc\n",
    "\n",
    "def boundaries_to_shots(boundaries):\n",
    "    boundaries = [0] + boundaries\n",
    "    boundary_list = IntervalList([(boundary, boundary, 0) for boundary in boundaries])\n",
    "    shots = boundary_list.fold_list(boundaries_to_shots_fold, [])\n",
    "    \n",
    "    return shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.191341Z",
     "start_time": "2018-12-07T21:53:15.116151Z"
    }
   },
   "outputs": [],
   "source": [
    "microshots = boundaries_to_shots(boundaries)\n",
    "short_microshots = microshots.filter_length(max_length=10)\n",
    "shots = microshots.set_union(\n",
    "    short_microshots.map(lambda i: (i.start, i.end + 1, i.payload)).coalesce()\n",
    ").coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.291893Z",
     "start_time": "2018-12-07T21:53:15.195528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the bad boundaries we identified earlier\n",
    "bad_shots = shots.filter_against(\n",
    "    bad_boundaries.map(lambda i: (i.start+1, i.end, i.payload)),\n",
    "    predicate=starts_inv()\n",
    ")\n",
    "shot_boundaries = shots.map(lambda i: (i.start, i.start, i.payload))\n",
    "shot_boundaries_without_bad_shots = shot_boundaries.minus(bad_shots)\n",
    "shots = shot_boundaries_without_bad_shots.fold_list(boundaries_to_shots_fold, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shot Boundaries\n",
    "For most of our precision/recall analysis, we're interested in shot boundaries, so we convert the `shots` and `human_shots` arrays to boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.342124Z",
     "start_time": "2018-12-07T21:53:15.294483Z"
    }
   },
   "outputs": [],
   "source": [
    "shot_boundaries = shots.map(lambda i: (i.start, i.start, i.payload))\n",
    "human_shot_boundaries = human_shots.map(lambda i: (i.start, i.start, i.payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Motion Flow\n",
    "If you want to incorporate motion flow into the shot detector, uncomment and run the three cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.414851Z",
     "start_time": "2018-12-07T21:53:15.344363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to get our best go using motion flow histograms too\n",
    "# import scannertools as st\n",
    "# import scannerpy\n",
    "# video = Video.objects.get(id=video_id)\n",
    "# frames = [list(range(0, video.num_frames))]\n",
    "\n",
    "# db = scannerpy.Database()\n",
    "\n",
    "# flow_histograms = st.histograms.compute_flow_histograms(\n",
    "#     db,\n",
    "#     videos=[video.for_scannertools()],\n",
    "#     frames=frames)\n",
    "\n",
    "# avg_magnitudes = [\n",
    "#     np.sum([i * bin_num for bin_num, i in enumerate(hist[0])]) /\n",
    "#     np.sum(hist[0])\n",
    "#     for hist in flow_histograms[0].load()\n",
    "# ]\n",
    "\n",
    "# avg_magnitudes_list = IntervalList([(frame, frame, mag) for frame, mag in enumerate(avg_magnitudes)])\n",
    "\n",
    "# def window(intervallist, n):\n",
    "#     from rekall.logical_predicates import or_pred\n",
    "#     from rekall.temporal_predicates import before, after\n",
    "#     from rekall.merge_ops import payload_plus\n",
    "    \n",
    "#     def my_merge_op(interval1, interval2):\n",
    "#         return [(interval1.start, interval1.end, [{\n",
    "#             'interval1': interval1.payload,\n",
    "#             'interval2': interval2.payload\n",
    "#         }])]\n",
    "    \n",
    "#     return intervallist.join(\n",
    "#         intervallist, merge_op=my_merge_op,\n",
    "#         predicate=or_pred(before(max_dist=n), after(max_dist=n), arity=2),\n",
    "#         working_window=n\n",
    "#     ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "# avg_magnitudes_windows = window(avg_magnitudes_list, 5)\n",
    "\n",
    "# window_means_stds = avg_magnitudes_windows.map(\n",
    "#     lambda interval: (interval.start, interval.end, {\n",
    "#         'mean_mag': np.mean([p['interval2'] for p in interval.payload]),\n",
    "#         'std_mag': np.std([p['interval2'] for p in interval.payload]),\n",
    "#         'my_mag': interval.payload[0]['interval1']\n",
    "#     }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.467934Z",
     "start_time": "2018-12-07T21:53:15.417117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate microshot boundary candidates\n",
    "# flow_microshot_boundaries = window_means_stds.filter(\n",
    "#     payload_satisfies(lambda payload: \n",
    "#                       (payload['my_mag'] - payload['mean_mag'] > 2 * payload['std_mag']))).map(\n",
    "#     lambda intrvl: (intrvl.start + 1, intrvl.end + 1, intrvl.payload)\n",
    "# )\n",
    "# heavy_flow_microshot_boundaries = window_means_stds.filter(\n",
    "#     payload_satisfies(lambda payload: payload['my_mag'] - payload['mean_mag'] > 3 * payload['std_mag'])).map(\n",
    "#     lambda intrvl: (intrvl.start + 1, intrvl.end + 1, intrvl.payload)\n",
    "# )\n",
    "\n",
    "# def boundaries_to_shots_fold(acc, frame):\n",
    "#     if acc == []:\n",
    "#         return [frame.copy()]\n",
    "#     top = acc[-1]\n",
    "#     top.end = frame.start - 1\n",
    "#     if top.length() > 0:\n",
    "#         acc.append(frame.copy())\n",
    "#     else:\n",
    "#         top.end = frame.start\n",
    "#     return acc\n",
    "\n",
    "# # Generate new shots\n",
    "\n",
    "# # rgb_and_flow_microshot_boundaries = shot_boundaries.set_union(heavy_flow_microshot_boundaries)\n",
    "# # rgb_and_flow_microshot_boundaries = shot_boundaries.overlaps(flow_microshot_boundaries)\n",
    "# rgb_and_flow_microshot_boundaries = shot_boundaries.overlaps(\n",
    "#     flow_microshot_boundaries).set_union(heavy_flow_microshot_boundaries)\n",
    "# rgb_and_flow_microshots = rgb_and_flow_microshot_boundaries.fold_list(boundaries_to_shots_fold, [])\n",
    "# short_rgb_and_flow = rgb_and_flow_microshots.filter_length(max_length=10)\n",
    "# rgb_and_flow_shots = rgb_and_flow_microshots.set_union(\n",
    "#     short_microshots.map(lambda i: (i.start, i.end + 1, i.payload)).coalesce()\n",
    "# ).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.516660Z",
     "start_time": "2018-12-07T21:53:15.470145Z"
    }
   },
   "outputs": [],
   "source": [
    "#shot_boundaries = rgb_and_flow_shots.map(lambda i: (i.start, i.start, i.payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute which shots are accurate/inaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:15.822721Z",
     "start_time": "2018-12-07T21:53:15.518902Z"
    }
   },
   "outputs": [],
   "source": [
    "accurate_shot_boundaries = shot_boundaries.filter_against(human_shot_boundaries, predicate=overlaps())\n",
    "inaccurate_shot_boundaries = shot_boundaries.minus(accurate_shot_boundaries)\n",
    "\n",
    "found_human_shot_boundaries = human_shot_boundaries.filter_against(shot_boundaries, predicate=overlaps())\n",
    "missed_human_shot_boundaries = human_shot_boundaries.minus(found_human_shot_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall across the three clips\n",
    "Let's graph precision/recall numbers for our three clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:16.139923Z",
     "start_time": "2018-12-07T21:53:15.825359Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, clip in enumerate(clips.get_intervals()):\n",
    "    def filter_fn(intrvl):\n",
    "        return overlaps()(intrvl, clip)\n",
    "    \n",
    "    precision = accurate_shot_boundaries.filter(filter_fn).size() / shot_boundaries.filter(filter_fn).size()\n",
    "    recall = found_human_shot_boundaries.filter(filter_fn).size() / human_shot_boundaries.filter(filter_fn).size()\n",
    "    data.append((precision, recall, 'Clip {}'.format(i + 1)))\n",
    "    \n",
    "    print(\"Total human shot boundaries in Clip {}: {}\".format(\n",
    "        i+1, human_shot_boundaries.filter(filter_fn).size()))\n",
    "    \n",
    "precisions = [precision for precision, _, _ in data]\n",
    "recalls = [recall for _, recall, _ in data]\n",
    "names = [name for _, _, name in data]\n",
    "N = len(names)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "width = 0.35\n",
    "ind = np.arange(N)\n",
    "p1 = ax.bar(ind, precisions, width)\n",
    "p2 = ax.bar(ind + width, recalls, width)\n",
    "\n",
    "ax.set_title('Precision and Recall by clip')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_ylim((0, 1))\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('Precision', 'Recall'))\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%f' % height,\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(p1)\n",
    "autolabel(p2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Mistakes and Missed Shot Boundaries\n",
    "Let's visualize where the mistakes happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:17.067388Z",
     "start_time": "2018-12-07T21:53:16.142732Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, clip in enumerate(clips.get_intervals()):\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Clip {}\".format(i + 1))\n",
    "    ax.scatter([intrvl.get_start() for intrvl in shot_boundaries.get_intervals()],\n",
    "               [2.2 for i in range(0, shot_boundaries.size())],\n",
    "               label='Histogram shot boundaries')\n",
    "    ax.scatter([intrvl.get_start() for intrvl in inaccurate_shot_boundaries.get_intervals()],\n",
    "               [2.1 for i in range(0, inaccurate_shot_boundaries.size())],\n",
    "               label='Inaccurate histogram shot boundaries')\n",
    "    ax.scatter([intrvl.get_start() for intrvl in missed_human_shot_boundaries.get_intervals()],\n",
    "               [2 for i in range(0, missed_human_shot_boundaries.size())],\n",
    "               label='Missed human shot boundaries')\n",
    "    ax.scatter([intrvl.get_start() for intrvl in human_shot_boundaries.get_intervals()],\n",
    "               [1.9 for i in range(0, human_shot_boundaries.size())],\n",
    "               label='All human shot boundaries')\n",
    "    ax.set_ylim(0, 4.0)\n",
    "    ax.set_xlim(int(math.floor(clip.get_start() / 100.0)) * 100, \n",
    "               int(math.ceil(clip.get_end() / 100.0)) * 100)\n",
    "    ax.set_xlabel('frame number')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames at Mistakes and Missed Boundaries\n",
    "Let's look at the frames where the histogram shot boundary detector made mistakes or where it missed a shot boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:17.122824Z",
     "start_time": "2018-12-07T21:53:17.069769Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_frames(video_id, boundaries, clip):\n",
    "    frame_nums = [\n",
    "        intrvl.get_start()\n",
    "        for intrvl in boundaries.filter(lambda intrvl: overlaps()(intrvl, clip)).get_intervals()\n",
    "    ]\n",
    "    \n",
    "    from esper.stdlib import simple_result\n",
    "    materialized_result = []\n",
    "    for frame_num in frame_nums:\n",
    "        materialized_result.append({\n",
    "            'video': video_id,\n",
    "            'min_frame': frame_num,\n",
    "            'objects': []\n",
    "        })\n",
    "    return simple_result(materialized_result, 'frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:17.171047Z",
     "start_time": "2018-12-07T21:53:17.125010Z"
    }
   },
   "outputs": [],
   "source": [
    "clip1 = clips.get_intervals()[0]\n",
    "clip2 = clips.get_intervals()[1]\n",
    "clip3 = clips.get_intervals()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.590068Z",
     "start_time": "2018-12-07T21:53:17.173263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inaccuracies in clip 1\n",
    "print(\"Inaccurate shot boundaries in Clip 1\")\n",
    "esper_widget(visualize_frames(video_id, inaccurate_shot_boundaries, clip1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.654512Z",
     "start_time": "2018-12-07T21:53:19.592227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missed shot boundaries in clip 1\n",
    "print(\"Missed shot boundaries in Clip 1\")\n",
    "esper_widget(visualize_frames(video_id, missed_human_shot_boundaries, clip1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.726003Z",
     "start_time": "2018-12-07T21:53:19.656631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inaccuracies in clip 2\n",
    "print(\"Inaccurate shot boundaries in Clip 2\")\n",
    "esper_widget(visualize_frames(video_id, inaccurate_shot_boundaries, clip2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.798083Z",
     "start_time": "2018-12-07T21:53:19.730529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missed shot boundaries in clip 2\n",
    "print(\"Missed shot boundaries in Clip 2\")\n",
    "esper_widget(visualize_frames(video_id, missed_human_shot_boundaries, clip2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.871379Z",
     "start_time": "2018-12-07T21:53:19.800603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inaccuracies in clip 3\n",
    "print(\"Inaccurate shot boundaries in Clip 3\")\n",
    "esper_widget(visualize_frames(video_id, inaccurate_shot_boundaries, clip3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:53:19.943900Z",
     "start_time": "2018-12-07T21:53:19.873514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missed shot boundaries in clip 3\n",
    "print(\"Missed shot boundaries in Clip 3\")\n",
    "esper_widget(visualize_frames(video_id, missed_human_shot_boundaries, clip3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
