{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query.datasets.prelude import *\n",
    "from query.datasets.ingest import ingest_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Person.objects.filter(frame__video__path='tvnews/videos/MSNBC_20090703_010000_The_Rachel_Maddow_Show.mp4').delete()\n",
    "#Face.objects.all().count()\n",
    "#Video.objects.all().distinct('height').values('height')\n",
    "\n",
    "with open('/app/paths') as f:\n",
    "    paths = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "tag, _ = Tag.objects.get_or_create(name='pose-test')    \n",
    "for path in paths:\n",
    "    video = Video.objects.get(path=path)\n",
    "    VideoTag(video=video, tag=tag).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video.objects.filter(videotag__tag__name='pose-test').values('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceFeatures.objects.filter(face__person__frame__video__videotag__tag__name='pose-test').count()\n",
    "#print Face.objects.all().order_by('facefeatures__distto').values('id').query\n",
    "#PersonTrack.objects.filter(video__path='tvnews/videos/MSNBC_20100827_060000_The_Rachel_Maddow_Show.mp4') \\\n",
    "#    .annotate(duration=Track.duration()).values()\n",
    "\n",
    "#id = 2043\n",
    "#FaceFeatures.compute_distances(id)\n",
    "tracks = list(PersonTrack.objects.filter(video__videotag__tag__name='pose-test') \\\n",
    "#tracks = list(PersonTrack.objects.filter(video__path='tvnews/videos/MSNBCW_20120303_020000_The_Rachel_Maddow_Show.mp4') \\\n",
    "    .annotate(c=Subquery(\n",
    "        Face.objects.filter(person__tracks=OuterRef('pk')) \\\n",
    "        .filter(labeler__name='tinyfaces', facefeatures__distto__isnull=False, facefeatures__distto__lte=1.0) \\\n",
    "        .values('person__tracks')\n",
    "        .annotate(c=Count('*'))\n",
    "        .values('c'), models.IntegerField()\n",
    "        )) \\\n",
    "    .filter(c__gt=0))\n",
    "len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvnews/videos/FOXNEWSW_20130402_040000_Hannity.mp4\n",
      "tvnews/videos/MSNBCW_20120303_020000_The_Rachel_Maddow_Show.mp4\n",
      "tvnews/videos/MSNBC_20111109_220000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBC_20100827_060000_The_Rachel_Maddow_Show.mp4\n",
      "tvnews/videos/MSNBCW_20130404_060000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBCW_20140125_000000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBCW_20150520_230000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBCW_20120924_210000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/FOXNEWS_20100728_010000_Hannity.mp4\n",
      "tvnews/videos/MSNBC_20100630_210000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBC_20110506_230000_Hardball_With_Chris_Matthews.mp4\n",
      "tvnews/videos/MSNBCW_20120823_040000_The_Rachel_Maddow_Show.mp4\n",
      "tvnews/videos/MSNBCW_20130402_080000_The_Rachel_Maddow_Show.mp4\n",
      "tvnews/videos/MSNBCW_20120412_060000_Hardball_With_Chris_Matthews.mp4\n"
     ]
    }
   ],
   "source": [
    "frames = defaultdict(set)    \n",
    "for track in tracks:\n",
    "    frames[track.video.path] |= set(range(track.min_frame, track.max_frame, 3))\n",
    "\n",
    "# for path in frames.keys():    \n",
    "#     if path == 'tvnews/videos/MSNBCW_20120303_020000_The_Rachel_Maddow_Show.mp4': continue\n",
    "#     print(path)\n",
    "#     #print('Deleting')\n",
    "#     #Person.objects.filter(frame__video=Video.objects.get(path=path))\n",
    "#     #Pose.objects.filter(person__frame__video=Video.objects.get(path=path)).delete()\n",
    "#     print('Ingesting')\n",
    "#     ingest_pose(\n",
    "#         Video.objects.get(path=path),\n",
    "#         db.table(path + '_poses_gather'),\n",
    "#         sorted(frames[path]))\n",
    "#     print('Ingested!')\n",
    "\n",
    "with open('/app/chris-matthews-frames', 'w') as f:\n",
    "    for path, frames in frames.iteritems():\n",
    "        print(path)\n",
    "        f.write('{} {}\\n'.format(path, ' '.join([str(s) for s in sorted(frames)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_pose(candidates, target):\n",
    "    noses = [pose.pose_keypoints()[Pose.Nose] for pose in candidates]\n",
    "    noses, indices = zip(*[(nose[:2], i) for i, nose in enumerate(noses) if nose[2] > 0])\n",
    "    dists = np.linalg.norm(np.array(noses) - target, axis=1)\n",
    "    closest = candidates[indices[np.argmin(dists)]]\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match detected poses with the sparse faces \n",
    "for track in tracks:\n",
    "    faces = list(Face.objects.filter(person__tracks=track).select_related('person__frame'))\n",
    "    for face in faces:\n",
    "        poses = list(Pose.objects.filter(person__frame=face.person.frame))\n",
    "        if len(poses) == 0:\n",
    "            continue\n",
    "        closest = closest_pose(poses, bbox_midpoint(face))\n",
    "        closest.person = face.person\n",
    "        closest.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in tracks with poses\n",
    "for track in tracks:\n",
    "    faces = list(Face.objects.filter(person__tracks=track).select_related('person__frame') \\\n",
    "                 .order_by('person__frame__number'))\n",
    "    for i in range(len(faces) - 1):\n",
    "        try:\n",
    "            last_pose = Pose.objects.get(person=faces[i].person)\n",
    "            for j in range(faces[i].person.frame.number, faces[i+1].person.frame.number, 3):\n",
    "                cur_poses = Pose.objects.filter(person__frame__video=track.video, person__frame__number=j)\n",
    "                if len(cur_poses) == 0:\n",
    "                    continue\n",
    "                closest = closest_pose(cur_poses, last_pose.pose_keypoints()[Pose.Nose][:2])\n",
    "                closest.person.tracks.add(track)\n",
    "                closest.save()\n",
    "                last_pose = closest\n",
    "        except Pose.DoesNotExist:\n",
    "            pass      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3988, 1020, 341)\n",
      "(3994, 600, 201)\n"
     ]
    }
   ],
   "source": [
    "for track in tracks:\n",
    "    print(track.id, track.max_frame-track.min_frame, Person.objects.filter(tracks=track).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to associate faces with poses\n",
    "[p1, p2] = Pose.objects.all()[:2]\n",
    "\n",
    "def pose_dist(p1, p2):\n",
    "    kp1 = p1.pose_keypoints()\n",
    "    kp2 = p2.pose_keypoints()\n",
    "    \n",
    "    weights = defaultdict(float, {\n",
    "        Pose.LWrist: 0.4,\n",
    "        Pose.RWrist: 0.4,\n",
    "        Pose.Nose: 0.1,        \n",
    "        Pose.LElbow: 0.05,\n",
    "        Pose.RElbow: 0.05\n",
    "    })\n",
    "    weight_vector = [weights[i] for i in range(Pose.POSE_KEYPOINTS)]\n",
    "    \n",
    "    dist = np.linalg.norm(kp2[:,:2] - kp1[:,:2], axis=1)\n",
    "    weighted_dist = np.array([d * w for d, s, w in zip(dist, kp2[:, 2], weight_vector) if s > 0])\n",
    "    return np.linalg.norm(weighted_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(544, 0.085587267049609075, 8),\n",
      " (526, 0.055704442668377659, 10),\n",
      " (558, 0.035203824877924374, 14),\n",
      " (432, 0.028847280277080549, 22),\n",
      " (491, 0.028283478618785909, 57),\n",
      " (510, 0.027027021788168945, 20),\n",
      " (522, 0.026710241897755622, 37),\n",
      " (502, 0.022655125863687901, 53),\n",
      " (525, 0.022558063862747633, 16),\n",
      " (490, 0.022357948323882836, 72),\n",
      " (435, 0.022315314581304497, 24),\n",
      " (487, 0.021614651581525295, 31),\n",
      " (478, 0.020917978833957813, 41),\n",
      " (596, 0.020014221168435462, 28),\n",
      " (438, 0.016960143127957041, 64),\n",
      " (640, 0.016895490152096994, 6),\n",
      " (625, 0.016696972105883095, 22),\n",
      " (592, 0.014646016962719175, 8),\n",
      " (500, 0.014513806718985042, 18),\n",
      " (436, 0.013565350686883196, 26),\n",
      " (515, 0.012427645897858055, 26),\n",
      " (470, 0.01176938304234541, 10),\n",
      " (600, 0.010864488866605888, 10),\n",
      " (481, 0.010818233255223368, 10),\n",
      " (643, 0.010761149358219677, 20),\n",
      " (483, 0.010726049869230826, 14),\n",
      " (585, 0.010419506163391799, 12),\n",
      " (602, 0.010132901905334611, 6),\n",
      " (532, 0.0095096386942751434, 4),\n",
      " (475, 0.0090205058706705182, 8),\n",
      " (599, 0.0084171420680630455, 8),\n",
      " (454, 0.0082746978516830202, 24),\n",
      " (636, 0.0077138343202574631, 6),\n",
      " (507, 0.0074205916956733434, 28),\n",
      " (445, 0.0066165060562111619, 12),\n",
      " (613, 0.0065691500261339597, 8),\n",
      " (611, 0.0057533949110523007, 12),\n",
      " (505, 0.0055376605970983532, 33),\n",
      " (511, 0.0055280428621626576, 43),\n",
      " (513, 0.0044149519203243622, 18),\n",
      " (506, 0.0010541579658517697, 6),\n",
      " (563, 1.2415514535090413e-06, 4)]\n"
     ]
    }
   ],
   "source": [
    "all_dists = []\n",
    "for track in tracks:\n",
    "    poses = list(Pose.objects.filter(person__tracks=track).order_by('person__frame__number'))\n",
    "    dists = [pose_dist(poses[i], poses[i+1]) for i in range(len(poses) - 1)]\n",
    "    all_dists.append((track.id, np.mean(dists), track.duration()))\n",
    "\n",
    "pprint(sorted(all_dists, key=itemgetter(1), reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
