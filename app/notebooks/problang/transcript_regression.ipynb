{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:24:09.628663Z",
     "start_time": "2018-12-05T02:24:01.299243Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "import pyro.infer as infer\n",
    "from torch.utils.data import DataLoader\n",
    "from transcript_utils import *\n",
    "from timeit import default_timer as now\n",
    "from custom_mlp import MLP, Exp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:26:02.788078Z",
     "start_time": "2018-12-05T02:25:37.982360Z"
    }
   },
   "outputs": [],
   "source": [
    "mi_dict = {ngram: score for [ngram, score] in mutual_info('immigration')}\n",
    "mi_priors = torch.tensor([mi_dict[ngram] if ngram in mi_dict else 0 for ngram in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:26:02.928163Z",
     "start_time": "2018-12-05T02:26:02.792557Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in ['immigration', 'border', 'healthcare']:\n",
    "    print('{} {:.4f}'.format(k, mi_priors[vocabulary.index(k)].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:28.625805Z",
     "start_time": "2018-12-03T05:06:28.597004Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute_vectors(video_list(), vocabulary, SEGMENT_SIZE, SEGMENT_STRIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:38:20.757461Z",
     "start_time": "2018-12-05T02:38:20.665784Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "    \n",
    "    def model(self, x, y):\n",
    "        # Create unit normal priors over the parameters\n",
    "        loc, scale = torch.zeros(self.p), torch.ones(self.p) * 10\n",
    "        bias_loc, bias_scale = torch.zeros(1), torch.ones(1) * 10\n",
    "        w_prior = dist.Normal(loc, scale).independent(1)\n",
    "        b_prior = dist.Normal(bias_loc, bias_scale).independent(1)\n",
    "        priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "        # lift module parameters to random variables sampled from the priors\n",
    "        lifted_module = pyro.random_module(\"module\", self, priors)\n",
    "        # sample a regressor (which also samples w and b)\n",
    "        lifted_reg_model = lifted_module()\n",
    "        with pyro.iarange(\"map\", x.shape[0]):\n",
    "            # run the regressor forward conditioned on data\n",
    "            prediction_mean = lifted_reg_model(x).squeeze(-1)\n",
    "            # condition on the observed data\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(prediction_mean), obs=y)                                                \n",
    "\n",
    "    def guide(self, x, y):\n",
    "        # define our variational parameters\n",
    "        w_loc = torch.tensor(mi_priors)\n",
    "        # note that we initialize our scales to be pretty narrow\n",
    "        w_log_sig = torch.tensor(-3.0 * torch.ones(1, self.p) + 0.05 * torch.randn(1, self.p))\n",
    "        b_loc = torch.tensor(0.5) + 0.05 * torch.randn(1)\n",
    "        b_log_sig = torch.tensor(-3.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
    "        # register learnable params in the param store\n",
    "        mw_param = pyro.param(\"guide_mean_weight\", w_loc)\n",
    "        sw_param = self.softplus(pyro.param(\"guide_log_scale_weight\", w_log_sig))\n",
    "        mb_param = pyro.param(\"guide_mean_bias\", b_loc)\n",
    "        sb_param = self.softplus(pyro.param(\"guide_log_scale_bias\", b_log_sig))\n",
    "        # guide distributions for w and b\n",
    "        w_dist = dist.Normal(mw_param, sw_param).independent(1)\n",
    "        b_dist = dist.Normal(mb_param, sb_param).independent(1)\n",
    "        dists = {'linear.weight': w_dist, 'linear.bias': b_dist}\n",
    "        # overload the parameters in the module with random samples\n",
    "        # from the guide distributions\n",
    "        lifted_module = pyro.random_module(\"module\", self, dists)\n",
    "        # sample a regressor (which also samples w and b)\n",
    "        return lifted_module()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:26:18.855454Z",
     "start_time": "2018-12-05T02:26:03.027013Z"
    }
   },
   "outputs": [],
   "source": [
    "unsup_dataset = SegmentVectorDataset(video_list(), vocab_size=vocab_size, inmemory=True)\n",
    "sup_dataset = LabeledSegmentDataset(unsup_dataset, pcache.get('labeled_segments'), categories=2)\n",
    "active_sup_dataset = LabeledSegmentDataset(unsup_dataset, pcache.get('active_labels'), categories=2)\n",
    "loader_params = {'shuffle': True}\n",
    "unsup_loader = DataLoader(unsup_dataset, batch_size=100, **loader_params)\n",
    "sup_loader = DataLoader(sup_dataset, batch_size=100, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:29:30.650366Z",
     "start_time": "2018-12-05T02:29:30.582873Z"
    }
   },
   "outputs": [],
   "source": [
    "x, _ = unsup_dataset[0]\n",
    "m = model_gen()\n",
    "infer.EmpiricalMarginal(infer.Importance(model_gen(), num_samples=100).run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:28:11.431954Z",
     "start_time": "2018-12-05T02:28:11.390236Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model_gen, x, y, iters=100):\n",
    "    samples = []\n",
    "    for _ in range(iters):\n",
    "        model = model_gen()\n",
    "        y_pred = model(x).squeeze(-1).round()\n",
    "        fp = torch.sum((y_pred != y) & (y_pred == 1)).item()\n",
    "        fn =  torch.sum((y_pred != y) & (y_pred == 0)).item()\n",
    "        acc = torch.sum(y_pred == y).item()\n",
    "        n = float(y_pred.shape[0])\n",
    "        samples.append(torch.tensor([acc/n, fp/n, fn/n]))\n",
    "    return torch.mean(torch.stack(samples), dim=0).tolist(), torch.std(torch.stack(samples), dim=0).tolist(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:09:21.881629Z",
     "start_time": "2018-12-05T08:09:21.812702Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels(dataset):\n",
    "    x_data, y_data, _ = unzip(list(dataset))\n",
    "    y_data = torch.tensor([y[1] for y in y_data])\n",
    "    x_data = torch.stack(x_data)\n",
    "    \n",
    "    split = int(len(x_data) / 2)\n",
    "\n",
    "    (train_x, val_x) = (x_data[:split], x_data[split:])\n",
    "    (train_y, val_y) = (y_data[:split], y_data[split:])\n",
    "    \n",
    "    return train_x, val_x, train_y, val_y\n",
    "\n",
    "train_x, val_x, train_y, val_y = get_labels(sup_dataset)\n",
    "\n",
    "active_train_x, active_val_x, active_train_y, active_val_y = get_labels(active_sup_dataset)\n",
    "train_x = torch.cat((train_x, active_train_x))\n",
    "train_y = torch.cat((train_y, active_train_y))\n",
    "val_x = torch.cat((val_x, active_val_x))\n",
    "val_y = torch.cat((val_y, active_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:09:22.344476Z",
     "start_time": "2018-12-05T08:09:22.245053Z"
    }
   },
   "outputs": [],
   "source": [
    "mi_priors_raw = torch.tensor([mi_dict[ngram] if ngram in mi_dict else 0 for ngram in vocabulary])\n",
    "def baseline_model(x):\n",
    "    return torch.mm(x, mi_priors_raw.unsqueeze(0).t()).squeeze()\n",
    "acc = get_accuracy(lambda: baseline_model,\n",
    "             torch.cat((train_x, val_x)), torch.cat((train_y, val_y)), iters=2)[0][0]\n",
    "\n",
    "print('Baseline accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:39:23.841628Z",
     "start_time": "2018-12-05T02:39:16.035674Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'regression_active'\n",
    "regression_model = RegressionModel(vocab_size)\n",
    "\n",
    "def torch_trainer():\n",
    "    loss_fn = nn.MSELoss(size_average=False)\n",
    "    optim = torch.optim.Adam(regression_model.parameters(), lr=0.05)\n",
    "    \n",
    "    def train(x, y):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        return loss.item()\n",
    "        \n",
    "    return train, lambda: regression_model\n",
    "\n",
    "def pyro_trainer():\n",
    "    pyro.clear_param_store()\n",
    "    opt = optim.Adam({\"lr\": 0.01})\n",
    "    svi = infer.SVI(regression_model.model, regression_model.guide, opt, loss=infer.Trace_ELBO())\n",
    "    \n",
    "    def train(x, y):\n",
    "        return svi.step(x, y)\n",
    "    \n",
    "    return train, lambda: regression_model.guide(None, None)\n",
    "        \n",
    "num_iterations = 100\n",
    "train, model_gen = pyro_trainer()\n",
    "\n",
    "for epoch in range(num_iterations):\n",
    "    loss = train(train_x, train_y)\n",
    "    if epoch % 5 == 0:\n",
    "        [tacc, tfp, tfn], _ = get_accuracy(model_gen, train_x, train_y)\n",
    "        [vacc, vfp, vfn], [vaccstd, vfpstd, vfnstd] = get_accuracy(model_gen, val_x, val_y)\n",
    "        print(\"[iteration %04d] loss: %.0f, train: acc %.3f, val: acc %.3f (+/- %.3f) fp %.3f (+/- %.3f) fn %.3f (+/ %.3f)\" % \n",
    "              (epoch, loss, tacc, vacc, vaccstd, vfp, vfpstd, vfn, vfnstd))\n",
    "        pyro.get_param_store().save(\n",
    "            '/app/data/models/transcript_{}_weights_epoch{:05d}.pt'.format(model_name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:38:50.759553Z",
     "start_time": "2018-12-05T02:38:50.722747Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(path):\n",
    "    pyro.get_param_store().load(path)\n",
    "    old_model = RegressionModel(vocab_size)\n",
    "    return get_accuracy((lambda: old_model.guide(None, None)), val_x, val_y, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:39:45.108490Z",
     "start_time": "2018-12-05T02:39:43.415738Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_model('/app/data/models/transcript_regression_weights_epoch00080.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T02:39:43.412544Z",
     "start_time": "2018-12-05T02:39:41.715925Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_model('/app/data/models/transcript_regression_active_weights_epoch00060.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:21:47.567488Z",
     "start_time": "2018-12-05T07:20:42.992947Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_uncertainty(model_gen, x, iters=5):    \n",
    "    ys_pred = []\n",
    "    for _ in range(iters):\n",
    "        model = model_gen()\n",
    "        ys_pred.append(model(x).squeeze(-1).round())\n",
    "    return torch.stack(ys_pred).std(dim=0)\n",
    "\n",
    "all_std = []\n",
    "all_idx = []\n",
    "for x, i in tqdm(unsup_loader):\n",
    "    all_std.append(model_uncertainty(model_gen, x))\n",
    "    all_idx.append(i)\n",
    "    \n",
    "all_std = torch.cat(all_std)\n",
    "all_idx = torch.cat(all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:21:48.824280Z",
     "start_time": "2018-12-05T07:21:48.773218Z"
    }
   },
   "outputs": [],
   "source": [
    "top_std, top_idx = all_std.topk(1000)\n",
    "top_idx = top_idx.tolist()\n",
    "random.shuffle(top_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:21:49.720310Z",
     "start_time": "2018-12-05T07:21:49.311274Z"
    }
   },
   "outputs": [],
   "source": [
    "text_dataset = SegmentTextDataset(video_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:23:01.747581Z",
     "start_time": "2018-12-05T07:23:01.679071Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = label_widget(text_dataset, [sup_dataset[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T07:36:31.991551Z",
     "start_time": "2018-12-04T07:36:31.958438Z"
    }
   },
   "outputs": [],
   "source": [
    "pcache.set('active_labels', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:17:30.902335Z",
     "start_time": "2018-12-03T22:17:30.872732Z"
    }
   },
   "outputs": [],
   "source": [
    "data = regression_model.guide(None, None)(x_data).squeeze(-1)\n",
    "print(data)\n",
    "print(data.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:07:54.922355Z",
     "start_time": "2018-12-03T22:07:54.883478Z"
    }
   },
   "outputs": [],
   "source": [
    "list(regression_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:29.046312Z",
     "start_time": "2018-12-03T05:06:18.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in regression_model.named_parameters():\n",
    "    if name == 'linear.weight':\n",
    "        weights = param.data.numpy().squeeze()\n",
    "        idx = np.argsort(weights)[::-1]\n",
    "        print(weights[idx])\n",
    "        print(np.array(vocabulary)[idx][:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
