{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercut Template\n",
    "A notebook to copy to make supercuts from. Subject to change based on experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:28:52.401906Z",
     "start_time": "2019-01-10T01:28:52.358985Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.supercuts import *\n",
    "from query.models import Shot\n",
    "from rekall.temporal_predicates import overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:28:53.306263Z",
     "start_time": "2019-01-10T01:28:52.977708Z"
    }
   },
   "outputs": [],
   "source": [
    "def query():\n",
    "    # Takes 7min to run!\n",
    "    from query.models import Face, Shot\n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.rekall import intrvllists_to_result_with_objects, bbox_to_result_object\n",
    "    from esper.stdlib import face_landmarks_to_dict\n",
    "    from esper.captions import get_all_segments\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.5\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.6\n",
    "    \n",
    "    def map_payload(func):\n",
    "        def map_fn(intvl):\n",
    "            intvl.payload = func(intvl.payload)\n",
    "            return intvl\n",
    "        return map_fn\n",
    "    \n",
    "    def get_landmarks(faces):\n",
    "        ids = [face['id'] for face in faces]\n",
    "        try:\n",
    "            landmarks = flw.get(Face.objects.filter(id__in=ids))\n",
    "        except:\n",
    "            print(\"Error getting landmarks:\", ids)\n",
    "            return []\n",
    "        for face, landmark in zip(faces, landmarks):\n",
    "            face['landmarks'] = landmark\n",
    "        return faces\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT)\n",
    "\n",
    "    faces = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs,\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'id': 'id'})\n",
    "        ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    graph = {\n",
    "        'nodes': [\n",
    "            { 'name': 'face_left', 'predicates': [] },\n",
    "            { 'name': 'face_right', 'predicates': [] },\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'face_left', 'end':'face_right', 'predicates': [\n",
    "                lambda f1, f2: f1['x2'] < f2['x2'] and f1['x1']<f2['x1'], # Left face on the left\n",
    "                lambda f1, f2: f1['x2'] - f2['x1'] > MIN_FACE_OVERLAP_X, # Faces overlap\n",
    "                lambda f1, f2: min(f1['y2'], f2['y2'])-max(f1['y1'], f1['y1']) > MIN_FACE_OVERLAP_Y,\n",
    "                lambda f1, f2: f1['y2'] > f2['y1'] and f1['y1'] < f2['y2'],  # No face is entirely above another\n",
    "                same_height(MAX_FACE_HEIGHT_DIFF),\n",
    "                lambda f1, f2: (f1['x2']-f2['x1'])/max(f1['x2']-f1['x1'], f2['x2']-f2['x1']) < MAX_FACE_OVERLAP_X_FRACTION\n",
    "\n",
    "            ]},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "\n",
    "    # Face is profile if both eyes are on the same side of the nose bridge horizontally.\n",
    "    def is_left_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = min(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] >= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] >= nose_x)\n",
    "        return left and right\n",
    "    def is_right_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = max(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] <= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] <= nose_x)\n",
    "        return left and right\n",
    "        \n",
    "    graph2 = {\n",
    "        'nodes': [\n",
    "            {'name': 'left', 'predicates': [is_right_profile]},\n",
    "            {'name': 'right', 'predicates': [is_left_profile]},\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'left', 'end':'right', 'predicates':[\n",
    "                lambda l, r: mouths_are_close(l['landmarks'], r['landmarks'])\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mf_up_close = faces.filter(payload_satisfies(\n",
    "        scene_graph(graph, exact=True))).map(map_payload(get_landmarks)).filter(\n",
    "        payload_satisfies(scene_graph(graph2, exact=True)))\n",
    "\n",
    "    vids = mf_up_close.get_allintervals().keys()\n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face')\n",
    "    ).all()\n",
    "    total = shots_qs.count()\n",
    "    print(\"Total shots:\", total)\n",
    "    # use emtpy list as payload\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        with_payload=lambda row:[],\n",
    "        progress=True,\n",
    "        total=total\n",
    "    )\n",
    "    kissing_shots = mf_up_close.join(\n",
    "      shots,\n",
    "      lambda kiss, shot: [(kiss.get_start(), shot.get_end(), kiss.get_payload())],\n",
    "      predicate=overlaps(),\n",
    "      working_window=1\n",
    "    ).coalesce()\n",
    "\n",
    "    # Getting faces in the shot\n",
    "    print(\"Getting faces...\")\n",
    "    def wrap_in_list(intvl):\n",
    "        intvl.payload = [intvl.payload]\n",
    "        return intvl\n",
    "\n",
    "    faces_qs2 = Face.objects.filter(frame__video_id__in=vids,probability__gte=MIN_FACE_CONFIDENCE)\n",
    "    total = faces_qs2.count()\n",
    "    faces2 = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs2.annotate(\n",
    "            min_frame=F('frame__number'),\n",
    "            max_frame=F('frame__number'),\n",
    "            video_id=F('frame__video_id')\n",
    "        ),\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'frame': 'min_frame'})\n",
    "        ])),\n",
    "        progress=True,\n",
    "        total = total\n",
    "    ).coalesce(payload_merge_op=payload_plus).map(wrap_in_list)\n",
    "    \n",
    "    def clip_to_last_frame_with_two_faces(intvl):\n",
    "        faces = intvl.get_payload()[1]\n",
    "        two_faces = [(f[0], f[1]) for f in faces if len(f)==2]\n",
    "        two_high_faces = [(a, b) for a, b in two_faces if min(a['y2']-a['y1'],b['y2']-b['y1'])>=MIN_FACE_HEIGHT]\n",
    "        frame = [a['frame'] for a,b in two_high_faces]\n",
    "        \n",
    "        if len(frame) > 0:\n",
    "            intvl.end = frame[-1]\n",
    "        return intvl\n",
    "    \n",
    "    clipped_kissing_shots = kissing_shots.merge(\n",
    "        faces2,\n",
    "        payload_merge_op = lambda p1, p2: (p1, p2),\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(payload_merge_op=lambda p1, p2: (p1[0], p1[1]+p2[1])).map(\n",
    "        clip_to_last_frame_with_two_faces)\n",
    "\n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    caption_results = VideoIntervalCollection({\n",
    "        video_id: [(\n",
    "            word[0] * fps_map[video_id], # start frame\n",
    "            word[1] * fps_map[video_id], # end frame\n",
    "            word[2]) # payload is the word\n",
    "            for word in words]\n",
    "        for video_id, words in results\n",
    "    })\n",
    "    kissing_without_words = clipped_kissing_shots.minus(\n",
    "            caption_results)\n",
    "    kissing_final = kissing_without_words.map(\n",
    "            lambda intvl: (int(intvl.start),\n",
    "                int(intvl.end), intvl.payload)\n",
    "            ).coalesce().filter_length(min_length=12)\n",
    "    \n",
    "    return kissing_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:28:55.489930Z",
     "start_time": "2019-01-10T01:28:55.436175Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_supercut_intervals(\n",
    "    interval_collection,\n",
    "    dilation=0,\n",
    "    snap_to_cinematic_shots=False,\n",
    "    limit=None,\n",
    "    stride=1,\n",
    "    max_length=None\n",
    "):\n",
    "    '''\n",
    "    Generates supercut intervals for the supercut pipeline.\n",
    "    Dilates interval_collection by dilation.\n",
    "    If dilation > 0, snaps the dilations to cinematic shot boundaries.\n",
    "    '''\n",
    "    if dilation > 0:\n",
    "        if snap_to_cinematic_shots:\n",
    "            shots = VideoIntervalCollection.from_django_qs(\n",
    "                Shot.objects.filter(\n",
    "                    video_id__in=list(interval_collection.get_allintervals().keys()),\n",
    "                    labeler__name=\"shot-hsvhist-face\"\n",
    "                )\n",
    "            ).filter_against(interval_collection, predicate=overlaps())\n",
    "        interval_collection = interval_collection.dilate(dilation).coalesce()\n",
    "        if snap_to_cinematic_shots:\n",
    "            interval_collection = interval_collection.overlaps(shots)\n",
    "    \n",
    "    supercut_intervals = []\n",
    "    for video_id in sorted(list(interval_collection.get_allintervals().keys())):\n",
    "        intervallist = interval_collection.get_intervallist(video_id)\n",
    "        for intrvl in intervallist.get_intervals():\n",
    "            if max_length is None:\n",
    "                supercut_intervals.append((video_id, intrvl.get_start(), intrvl.get_end()))\n",
    "            else:\n",
    "                supercut_intervals.append((video_id, intrvl.get_start(), min(intrvl.get_end(), intrvl.get_start() + max_length)))\n",
    "            \n",
    "    if limit is not None:\n",
    "        return supercut_intervals[:limit * stride:stride]\n",
    "    \n",
    "    return supercut_intervals[::stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:28:56.221717Z",
     "start_time": "2019-01-10T01:28:56.180915Z"
    }
   },
   "outputs": [],
   "source": [
    "# output path\n",
    "OUTPUT_PATH = '/app/result/supercut/kissing.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:33:17.759696Z",
     "start_time": "2019-01-10T01:28:57.396752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the document list and lexicon\n",
      "Matched 571 documents to videos\n",
      "0 documents have no videos\n",
      "71 videos have no documents\n",
      "  0%|                                                                                                                                                                                                             | 0/224834 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shots: 224834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 224834/224834 [00:06<00:00, 34841.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting faces...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2195836/2195836 [01:15<00:00, 29160.01it/s]\n"
     ]
    }
   ],
   "source": [
    "query_results = query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:33:20.247585Z",
     "start_time": "2019-01-10T01:33:17.763022Z"
    }
   },
   "outputs": [],
   "source": [
    "supercut_intervals = generate_supercut_intervals(\n",
    "    query_results, limit=None, stride=1, dilation=12, snap_to_cinematic_shots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:37:40.430180Z",
     "start_time": "2019-01-10T01:33:20.250185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e433063900054777a445c11594add4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=209), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stitch_video_temporal(\n",
    "    supercut_intervals,\n",
    "    out_path=OUTPUT_PATH, width=640, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
