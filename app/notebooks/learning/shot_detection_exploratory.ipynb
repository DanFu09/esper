{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Load-up-Ground-Truth\" data-toc-modified-id=\"Load-up-Ground-Truth-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load up Ground Truth</a></span></li><li><span><a href=\"#Evaluate-Baselines\" data-toc-modified-id=\"Evaluate-Baselines-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Evaluate Baselines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-up-Shots-from-Heuristics\" data-toc-modified-id=\"Load-up-Shots-from-Heuristics-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load up Shots from Heuristics</a></span></li><li><span><a href=\"#Machine-Learning\" data-toc-modified-id=\"Machine-Learning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Machine Learning</a></span></li><li><span><a href=\"#Different-Window-Sizes\" data-toc-modified-id=\"Different-Window-Sizes-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Different Window Sizes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Window-Size-1\" data-toc-modified-id=\"Window-Size-1-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Window Size 1</a></span></li><li><span><a href=\"#Window-Size-2\" data-toc-modified-id=\"Window-Size-2-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Window Size 2</a></span></li><li><span><a href=\"#Window-Size-3\" data-toc-modified-id=\"Window-Size-3-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Window Size 3</a></span></li><li><span><a href=\"#Window-Size-4\" data-toc-modified-id=\"Window-Size-4-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Window Size 4</a></span></li><li><span><a href=\"#Window-Size-5\" data-toc-modified-id=\"Window-Size-5-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Window Size 5</a></span></li><li><span><a href=\"#Window-Size-6\" data-toc-modified-id=\"Window-Size-6-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Window Size 6</a></span></li><li><span><a href=\"#Window-Size-7\" data-toc-modified-id=\"Window-Size-7-2.3.7\"><span class=\"toc-item-num\">2.3.7&nbsp;&nbsp;</span>Window Size 7</a></span></li></ul></li><li><span><a href=\"#DeepSBD\" data-toc-modified-id=\"DeepSBD-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>DeepSBD</a></span></li></ul></li><li><span><a href=\"#ClipShots\" data-toc-modified-id=\"ClipShots-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>ClipShots</a></span></li><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Notes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model/loss:-raw-output-of-last-FC-layer-to-BCEWithLogitsLoss\" data-toc-modified-id=\"Model/loss:-raw-output-of-last-FC-layer-to-BCEWithLogitsLoss-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Model/loss: raw output of last FC layer to BCEWithLogitsLoss</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scratchpad\" data-toc-modified-id=\"Scratchpad-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Scratchpad</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:59:55.146984Z",
     "start_time": "2019-02-12T23:59:54.350269Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.temporal_predicates import *\n",
    "from esper.rekall import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:59:56.361286Z",
     "start_time": "2019-02-12T23:59:56.313529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load up small ground truth set for training\n",
    "shots_gt_training_qs = Shot.objects.filter(\n",
    "    Q(video_id=123, labeler__name__contains='manual', max_frame__lte=16560) | # easy\n",
    "    Q(video_id=172, labeler__name__contains='manual') | # hard\n",
    "    Q(video_id=179, labeler__name__contains='manual') | # easy\n",
    "    Q(video_id=104, labeler__name__contains='manual') |\n",
    "    Q(video_id=148, labeler__name__contains='manual')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:59:57.130860Z",
     "start_time": "2019-02-12T23:59:57.092550Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_test_qs = Shot.objects.filter(labeler__name__contains='manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:59:58.389160Z",
     "start_time": "2019-02-12T23:59:57.767844Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_training = VideoIntervalCollection.from_django_qs(shots_gt_training_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:59:58.783050Z",
     "start_time": "2019-02-12T23:59:58.484740Z"
    }
   },
   "outputs": [],
   "source": [
    "shots_gt_test = VideoIntervalCollection.from_django_qs(shots_gt_test_qs).minus(shots_gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:50:43.061957Z",
     "start_time": "2019-02-08T01:50:39.269391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the ground truth.\n",
    "esper_widget(intrvllists_to_result(shots_gt_training), jupyter_keybindings=True, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up Shots from Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:30:58.430484Z",
     "start_time": "2019-02-18T00:30:58.379044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure out temporal extents of the clips that were labeled\n",
    "clips_training = shots_gt_training.dilate(1).coalesce().dilate(-1)\n",
    "clips_test = shots_gt_test.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:31:15.860561Z",
     "start_time": "2019-02-18T00:30:59.305996Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shots_qs = Shot.objects.filter(cinematic=True).all()\n",
    "cinematic_shots = VideoIntervalCollection.from_django_qs(\n",
    "    cinematic_shots_qs,\n",
    "    progress = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:31:15.956558Z",
     "start_time": "2019-02-18T00:31:15.863517Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shots_training = cinematic_shots.filter_against(\n",
    "    clips_training,\n",
    "    predicate=overlaps()\n",
    ")\n",
    "cinematic_shots_test = cinematic_shots.filter_against(\n",
    "    clips_test,\n",
    "    predicate=overlaps()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:31:15.984130Z",
     "start_time": "2019-02-18T00:31:15.958271Z"
    }
   },
   "outputs": [],
   "source": [
    "cinematic_shot_boundaries_training = cinematic_shots_training.map(lambda i: (i.start, i.start, i.payload))\n",
    "cinematic_shot_boundaries_test = cinematic_shots_test.map(lambda i: (i.start, i.start, i.payload))\n",
    "gt_shot_boundaries_training = shots_gt_training.map(lambda i: (i.start, i.start, i.payload))\n",
    "gt_shot_boundaries_test = shots_gt_test.map(lambda i: (i.start, i.start, i.payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:31:37.132728Z",
     "start_time": "2019-02-18T00:31:37.087602Z"
    }
   },
   "outputs": [],
   "source": [
    "def size(interval_collection):\n",
    "    count = 0\n",
    "    for video_id in interval_collection.get_allintervals():\n",
    "        count += interval_collection.get_intervallist(video_id).size()\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:51:05.908460Z",
     "start_time": "2019-02-08T01:51:05.885039Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_per_video_precision_recall(gt_shot_boundaries, eval_shot_boundaries):\n",
    "    for video_id in gt_shot_boundaries.get_allintervals():\n",
    "        print(\"Video {}: \".format(video_id))\n",
    "        cine_sb = VideoIntervalCollection({\n",
    "            video_id: eval_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        gt_sb = VideoIntervalCollection({\n",
    "            video_id: gt_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        accurate_sb = cine_sb.filter_against(gt_sb, predicate=overlaps())\n",
    "        inaccurate_sb = cine_sb.minus(accurate_sb)\n",
    "\n",
    "        found_human_sb = gt_sb.filter_against(cine_sb, predicate=overlaps())\n",
    "        missed_human_sb = gt_sb.minus(found_human_sb)\n",
    "        \n",
    "        print(\"Precision: {}, {} out of {}\".format(\n",
    "            size(accurate_sb) / size(cine_sb), \n",
    "            size(accurate_sb), \n",
    "            size(cine_sb)))\n",
    "        print(\"Recall: {}, {} out of {}\".format(\n",
    "            size(accurate_sb) / size(gt_sb), \n",
    "            size(accurate_sb), \n",
    "            size(gt_sb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:31:50.528527Z",
     "start_time": "2019-02-18T00:31:50.472811Z"
    }
   },
   "outputs": [],
   "source": [
    "def prf1_boundary_intrvllist(gt_shot_boundaries, eval_shot_boundaries):\n",
    "    tp = 0.\n",
    "    fp = 0.\n",
    "    fn = 0.\n",
    "    for video_id in gt_shot_boundaries.get_allintervals():\n",
    "        cine_sb = VideoIntervalCollection({\n",
    "            video_id: eval_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        gt_sb = VideoIntervalCollection({\n",
    "            video_id: gt_shot_boundaries.get_intervallist(video_id)\n",
    "        })\n",
    "        accurate_sb = cine_sb.filter_against(gt_sb, predicate=overlaps())\n",
    "        inaccurate_sb = cine_sb.minus(accurate_sb)\n",
    "\n",
    "        found_human_sb = gt_sb.filter_against(cine_sb, predicate=overlaps())\n",
    "        missed_human_sb = gt_sb.minus(found_human_sb)\n",
    "        \n",
    "        tp += size(accurate_sb)\n",
    "        fp += size(inaccurate_sb)\n",
    "        fn += size(missed_human_sb)\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:51:05.935530Z",
     "start_time": "2019-02-08T01:51:05.910528Z"
    }
   },
   "outputs": [],
   "source": [
    "print_per_video_precision_recall(gt_shot_boundaries_training, cinematic_shot_boundaries_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:51:06.061043Z",
     "start_time": "2019-02-08T01:51:05.937206Z"
    }
   },
   "outputs": [],
   "source": [
    "print_per_video_precision_recall(gt_shot_boundaries_test, cinematic_shot_boundaries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:33:30.315197Z",
     "start_time": "2019-02-18T00:33:30.124261Z"
    }
   },
   "outputs": [],
   "source": [
    "prf1_boundary_intrvllist(\n",
    "    gt_shot_boundaries_test.set_union(gt_shot_boundaries_training),\n",
    "    cinematic_shot_boundaries_test.set_union(cinematic_shot_boundaries_training)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:13:00.658866Z",
     "start_time": "2019-02-07T00:12:59.512820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the discrepancies. Ground truth is in red, heuristic results are in blue.\n",
    "result = intrvllists_to_result(shots_gt_training, color='red')\n",
    "add_intrvllists_to_result(result, cinematic_shots_training, color='blue')\n",
    "esper_widget(result, jupyter_keybindings=True, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T00:00:05.175479Z",
     "start_time": "2019-02-13T00:00:04.787599Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import scannertools as st\n",
    "import random\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T00:00:06.201535Z",
     "start_time": "2019-02-13T00:00:06.160475Z"
    }
   },
   "outputs": [],
   "source": [
    "st.init_storage(os.environ['BUCKET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T00:00:06.935899Z",
     "start_time": "2019-02-13T00:00:06.882909Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T00:00:07.827951Z",
     "start_time": "2019-02-13T00:00:07.728591Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShotDetectionDataset(Dataset):\n",
    "    def __init__(self, shots, window_size=1, height=224):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            shots: VideoIntervalCollection of all the intervals to get frames from. If the payload is -1,\n",
    "            then the interval is not an actual shot and just needs to be included in the dataset.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        items = set()\n",
    "        frame_nums = {}\n",
    "        \n",
    "        for video_id in shots.get_allintervals():\n",
    "            frame_nums[video_id] = set()\n",
    "            for intrvl in shots.get_intervallist(video_id).get_intervals():\n",
    "                for f in range(intrvl.start, intrvl.end + 1):\n",
    "                    items.add((\n",
    "                        video_id,\n",
    "                        f,\n",
    "                        1 if f == intrvl.start and intrvl.payload != -1 else 0\n",
    "                    ))\n",
    "                    for i in range(intrvl.start - window_size, intrvl.end + window_size + 1):\n",
    "                        frame_nums[video_id].add(i)\n",
    "        self.items = sorted(list(items))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((100, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # Load frames into memory\n",
    "        self.frames = {\n",
    "            video_id: {\n",
    "                'frame_nums': sorted(list(frame_nums[video_id])),\n",
    "                'frames': [\n",
    "                    self.transform(f)\n",
    "                    for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "                        sorted(list(frame_nums[video_id]))\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "            for video_id in tqdm(frame_nums)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video_id, frame_num, label = self.items[idx]\n",
    "        \n",
    "        start_index = self.frames[video_id]['frame_nums'].index(frame_num - self.window_size)\n",
    "        img_tensors = self.frames[video_id]['frames'][start_index:start_index + 2*self.window_size + 1]\n",
    "        \n",
    "#         img_tensors = [\n",
    "#             self.transform(f)\n",
    "#             for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "#                 list(range(frame_num - self.window_size, frame_num + self.window_size + 1))\n",
    "#             )\n",
    "#         ]\n",
    "        \n",
    "        return img_tensors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:15:21.586912Z",
     "start_time": "2019-02-08T18:15:21.515608Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct a training set with good class balance\n",
    "shot_boundaries = shots_gt_training.map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    ")\n",
    "shots_without_boundaries = shots_gt_training.map(\n",
    "    lambda intrvl: (intrvl.start + 1, intrvl.end, intrvl.payload)\n",
    ").get_allintervals()\n",
    "non_boundary_frames = [\n",
    "    (video_id, f)\n",
    "    for video_id in shots_without_boundaries\n",
    "    for intrvl in shots_without_boundaries[video_id].get_intervals()\n",
    "    for f in range(intrvl.start, intrvl.end + 1)\n",
    "]\n",
    "random.seed(0)\n",
    "random.shuffle(non_boundary_frames) # seed of 0 for reproducibility\n",
    "chosen_frames = collect(non_boundary_frames[:size(shot_boundaries)], lambda tup: tup[0])\n",
    "\n",
    "training_frames = shot_boundaries.set_union(\n",
    "    VideoIntervalCollection({\n",
    "        video_id: [\n",
    "            (frame, frame, -1)\n",
    "            for vid, frame in chosen_frames[video_id]\n",
    "        ]\n",
    "        for video_id in chosen_frames\n",
    "    })\n",
    ").set_union(\n",
    "    shots_gt_training.map(\n",
    "        lambda intrvl: (intrvl.end, intrvl.end, -1)\n",
    "    )\n",
    ").set_union(\n",
    "    shots_gt_training.map(\n",
    "        lambda intrvl: (intrvl.start+1, intrvl.start+1, -1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:16:12.308981Z",
     "start_time": "2019-02-08T18:15:25.953708Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_training = ShotDetectionDataset(training_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:16:12.340429Z",
     "start_time": "2019-02-08T18:16:12.312651Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_training = DataLoader(dataset_training, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:17:50.394937Z",
     "start_time": "2019-02-08T18:16:12.342553Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_training_test = ShotDetectionDataset(shots_gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:17:50.422479Z",
     "start_time": "2019-02-08T18:17:50.397731Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_training_test = DataLoader(dataset_training_test, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T21:49:51.698288Z",
     "start_time": "2019-02-11T21:49:51.562853Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoNet(nn.Module):\n",
    "    def __init__(self, window_size=1):\n",
    "        super(VideoNet, self).__init__()\n",
    "#         self.resnet1 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "#         self.resnet2 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "#         self.resnet3 = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)\n",
    "        self.resnets = [\n",
    "            models.resnet18(pretrained=True)\n",
    "            for i in range(0, 2 * window_size + 1)\n",
    "        ]\n",
    "        self.resnet_fcs = [\n",
    "            nn.Linear(rn.fc.in_features, 128)\n",
    "            for rn in self.resnets\n",
    "        ]\n",
    "        \n",
    "        for idx, resnet in enumerate(self.resnets):\n",
    "            resnet.fc = self.resnet_fcs[idx]\n",
    "            resnet.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "            self.add_module('resnet{}'.format(idx), resnet)\n",
    "    \n",
    "        # Replace pooling layer with Adaptive Pooling\n",
    "#         self.resnet1.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.resnet2.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.resnet3.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "#         self.embeddingpool = nn.MaxPool1d(5, stride=3)\n",
    "        \n",
    "#         self.rnfc1 = nn.Linear(1000, 128)\n",
    "#         self.rnfc2 = nn.Linear(1000, 128)\n",
    "#         self.rnfc3 = nn.Linear(1000, 128)\n",
    "        \n",
    "        self.embeddingconv = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.kaiming_normal_(self.embeddingconv.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        for fc in self.resnet_fcs:\n",
    "            nn.init.xavier_uniform_(fc.weight)\n",
    "        \n",
    "    def forward(self, images):\n",
    "#         image1embedding = self.resnet1(image1).unsqueeze(1)\n",
    "#         image2embedding = self.resnet2(image2).unsqueeze(1)\n",
    "#         image3embedding = self.resnet3(image3).unsqueeze(1)\n",
    "        \n",
    "#         print(image1embedding.size())\n",
    "        \n",
    "#         embedding_image = torch.cat(\n",
    "#             (self.embeddingpool(image1embedding),\n",
    "#              self.embeddingpool(image2embedding),\n",
    "#              self.embeddingpool(image3embedding)),\n",
    "#             dim=1\n",
    "#         )\n",
    "        \n",
    "#         embedding_image = torch.cat(\n",
    "#             (image1embedding,\n",
    "#              image2embedding,\n",
    "#              image3embedding),\n",
    "#             dim=1\n",
    "#         )\n",
    "        \n",
    "#         print(embedding_image.size())\n",
    "\n",
    "        embeddings = [\n",
    "            resnet(image).unsqueeze(1)\n",
    "            for image, resnet in zip(images, self.resnets)\n",
    "        ]\n",
    "        \n",
    "        embedding_image = torch.cat(embeddings, dim=1)\n",
    "        \n",
    "        embedding_image = embedding_image.unsqueeze(1)\n",
    "        \n",
    "#         print(embedding_image.size())\n",
    "        out = self.embeddingconv(embedding_image)\n",
    "#         print(out.size())\n",
    "        out = self.relu(out)\n",
    "#         print(out.size())\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "#         out = nn.LogSoftmax(1)(out)\n",
    "#         out = self.sigmoid(out)\n",
    "#         out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "#     def parameters(self):\n",
    "#         return [self.embeddingconv.parameters(), self.fc.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:12.142939Z",
     "start_time": "2019-02-08T20:06:11.127866Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet = VideoNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:13.088301Z",
     "start_time": "2019-02-08T20:06:13.039205Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:44.592215Z",
     "start_time": "2019-02-08T20:06:44.564790Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:47.938674Z",
     "start_time": "2019-02-08T20:06:47.861973Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet = vnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T21:49:57.211657Z",
     "start_time": "2019-02-11T21:49:57.017596Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, dataloader=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_inputs = 0.0\n",
    "            \n",
    "            true_positive = 0.\n",
    "            false_positive = 0.\n",
    "            true_negative = 0.\n",
    "            false_negative = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, (inputs, labels) in enumerate(dataloader):\n",
    "#                 if idx > 100:\n",
    "#                     break\n",
    "#                 print(\"Start loop {}\".format(datetime.datetime.now()))\n",
    "#                 crit = nn.BCELoss(\n",
    "#                     weight = torch.tensor([\n",
    "#                         1.0 if l.item() == 1 else .25\n",
    "#                         for l in labels\n",
    "#                     ]).to(device)\n",
    "#                 )\n",
    "                inputs = [i.to(device) for i in inputs]\n",
    "                labels = labels.to(device)\n",
    "#                 print(\"Moved inputs {}\".format(datetime.datetime.now()))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    batch_size = labels.size(0)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs.view(1, 4), labels.view(1, 4))\n",
    "#                     loss=torch.tensor([[0]]).to(device)\n",
    "#                     print(outputs.view(1, batch_size), labels.view(1, batch_size))\n",
    "#                     loss=criterion(outputs, labels)\n",
    "                    loss=criterion(outputs.view(1, batch_size), labels.float().view(1, batch_size))\n",
    "#                     print(outputs.view(1, 4), labels.float().view(1, 4), loss)\n",
    "#                     if False:\n",
    "                    if idx == 0:\n",
    "                        print(outputs, labels, loss)\n",
    "#                     print(labels)\n",
    "#                     print(loss)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                \n",
    "#                     for p, l in zip(preds, labels):\n",
    "#                         if p.item() == l.item():\n",
    "#                             if l.item() == 1:\n",
    "#                                 true_positive += 1.\n",
    "#                             else:\n",
    "#                                 true_negative += 1.\n",
    "#                         else:\n",
    "#                             if p.item() == 1:\n",
    "#                                 false_positive += 1.\n",
    "#                             else:\n",
    "#                                 false_negative += 1.\n",
    "#                         total_inputs += 1\n",
    "\n",
    "                    for o, l in zip(outputs, labels):\n",
    "                        if o.item() > 0.:\n",
    "                            if l.item() == 1:\n",
    "                                true_positive += 1.\n",
    "                            else:\n",
    "                                false_positive += 1.\n",
    "                        else:\n",
    "                            if l.item() == 1:\n",
    "                                false_negative += 1.\n",
    "                            else:\n",
    "                                true_negative += 1.\n",
    "                        total_inputs += 1\n",
    "                            \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs[0].size(0)\n",
    "                    running_corrects = true_positive + true_negative\n",
    "#                     print(running_corrects, true_positive, true_negative, total_inputs)\n",
    "\n",
    "#                 print(\"End loop {}\".format(datetime.datetime.now()))\n",
    "\n",
    "            epoch_loss = running_loss / total_inputs #/ len(dataset)\n",
    "            epoch_acc = running_corrects / total_inputs #/ len(dataset)\n",
    "            if true_positive + false_positive != 0:\n",
    "                precision = true_positive / (true_positive + false_positive)\n",
    "            else:\n",
    "                precision = 0.\n",
    "            if true_positive + false_negative != 0:\n",
    "                recall = true_positive / (true_positive + false_negative)\n",
    "            else:\n",
    "                recall = 0.\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, precision, recall))\n",
    "            print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "                true_positive, true_negative, false_positive, false_negative\n",
    "            ))\n",
    "\n",
    "            # deep copy the model\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:54.502704Z",
     "start_time": "2019-02-08T20:06:54.460626Z"
    }
   },
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([.1, 1.]).to(device))\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.NLLLoss(weight=torch.tensor([.01, .99]).to(device))\n",
    "# criterion = nn.NLLLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:56.842427Z",
     "start_time": "2019-02-08T20:06:56.795969Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(vnet.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:06:57.716954Z",
     "start_time": "2019-02-08T20:06:57.677055Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:12:42.062923Z",
     "start_time": "2019-02-08T20:07:23.622046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_model(vnet, criterion, optimizer, exp_lr_scheduler, num_epochs=100, dataloader=dataloader_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T21:49:59.992369Z",
     "start_time": "2019-02-11T21:49:59.874500Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, dataloader):\n",
    "    since = time.time()\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_inputs = 0.0\n",
    "\n",
    "    true_positive = 0.\n",
    "    false_positive = 0.\n",
    "    true_negative = 0.\n",
    "    false_negative = 0.\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for idx, (inputs, labels) in tqdm(enumerate(dataloader)):\n",
    "        inputs = [i.to(device) for i in inputs]\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            batch_size = labels.size(0)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss=criterion(outputs, labels)\n",
    "            loss=criterion(outputs.view(1, batch_size), labels.float().view(1, batch_size))\n",
    "#             if False:\n",
    "            if idx == 0:\n",
    "                print(outputs, labels, loss)\n",
    "#             print(labels)\n",
    "#             print(loss)\n",
    "                \n",
    "                \n",
    "#             for p, l in zip(preds, labels):\n",
    "#                 if p.item() == l.item():\n",
    "#                     if l.item() == 1:\n",
    "#                         true_positive += 1.\n",
    "#                     else:\n",
    "#                         true_negative += 1.\n",
    "#                 else:\n",
    "#                     if p.item() == 1:\n",
    "#                         false_positive += 1.\n",
    "#                     else:\n",
    "#                         false_negative += 1.\n",
    "#                 total_inputs += 1\n",
    "\n",
    "            for o, l in zip(outputs, labels):\n",
    "                if o.item() > 0.:\n",
    "                    if l.item() == 1:\n",
    "                        true_positive += 1.\n",
    "                    else:\n",
    "                        false_positive += 1.\n",
    "                else:\n",
    "                    if l.item() == 1:\n",
    "                        false_negative += 1.\n",
    "                    else:\n",
    "                        true_negative += 1.\n",
    "                total_inputs += 1\n",
    "                results.append((o.item(), l.item()))\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs[0].size(0)\n",
    "        running_corrects = true_positive + true_negative\n",
    "#     print(running_corrects, true_positive, true_negative, total_inputs)\n",
    "\n",
    "    epoch_loss = running_loss / total_inputs #/ len(dataset)\n",
    "    epoch_acc = running_corrects / total_inputs #/ len(dataset)\n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0.\n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0.\n",
    "\n",
    "    print('Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc, precision, recall))\n",
    "    print('TP: {} TN: {} FP: {} FN: {}'.format(\n",
    "        true_positive, true_negative, false_positive, false_negative\n",
    "    ))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:20:13.979768Z",
     "start_time": "2019-02-08T19:07:10.245256Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_test = ShotDetectionDataset(shots_gt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:20:14.007452Z",
     "start_time": "2019-02-08T19:20:13.983128Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:17:35.872351Z",
     "start_time": "2019-02-08T20:15:55.679911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results = test_model(model, criterion, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:14:01.051731Z",
     "start_time": "2019-02-08T20:13:47.034951Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results = test_model(model, criterion, dataloader_training_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:14:26.864283Z",
     "start_time": "2019-02-08T20:14:26.817789Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives = []\n",
    "false_positives = []\n",
    "for (output, label), item in zip(training_test_results, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives.append((output, label, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:14:28.244797Z",
     "start_time": "2019-02-08T20:14:28.206518Z"
    }
   },
   "outputs": [],
   "source": [
    "tp_collected = collect(true_positives, lambda tup: tup[2][0])\n",
    "true_positive_intrvls = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in tp_collected[video_id]\n",
    "    ]\n",
    "    for video_id in tp_collected\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:14:28.970603Z",
     "start_time": "2019-02-08T20:14:28.909449Z"
    }
   },
   "outputs": [],
   "source": [
    "fp_collected = collect(false_positives, lambda tup: tup[2][0])\n",
    "false_positive_intrvls = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T18:03:23.200838Z",
     "start_time": "2019-02-07T18:03:22.023321Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(true_positive_intrvls, lambda a, b: []),\n",
    "    jupyter_keybindings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:14:34.952761Z",
     "start_time": "2019-02-08T20:14:33.828560Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T01:30:01.330833Z",
     "start_time": "2019-02-06T01:30:01.078841Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-5-19_529pm_videonet_1to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T17:49:06.096024Z",
     "start_time": "2019-02-06T17:49:05.840036Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_948am_videonet_10to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:16:54.511803Z",
     "start_time": "2019-02-06T18:16:54.190444Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_1016am_videonet_2to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:16:10.898185Z",
     "start_time": "2019-02-07T17:16:10.645534Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2-6-19_5pm_videonet_3to1classbalance_bcewithlogitsloss.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:19:17.421832Z",
     "start_time": "2019-02-08T20:19:17.379476Z"
    }
   },
   "outputs": [],
   "source": [
    "max_window_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:20:23.430936Z",
     "start_time": "2019-02-08T20:19:18.124662Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set_full = ShotDetectionDataset(training_frames, window_size=max_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:21:51.764879Z",
     "start_time": "2019-02-08T20:20:23.434765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set_test_full = ShotDetectionDataset(shots_gt_training, window_size=max_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:21:51.792010Z",
     "start_time": "2019-02-08T20:21:51.767003Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T20:19:03.670377Z",
     "start_time": "2019-02-08T20:19:03.608617Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "training_set_full.window_size = 1\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = 1\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T18:59:45.650704Z",
     "start_time": "2019-02-07T18:59:44.565195Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet1 = VideoNet(window_size=1)\n",
    "vnet1.init_weights()\n",
    "vnet1 = vnet1.to(device)\n",
    "optimizer1 = optim.SGD(vnet1.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler1 = lr_scheduler.StepLR(optimizer1, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:05:39.519724Z",
     "start_time": "2019-02-07T18:59:46.403027Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = train_model(vnet1, criterion, optimizer1, exp_lr_scheduler1, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:10:23.252272Z",
     "start_time": "2019-02-07T19:10:08.262400Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results1 = test_model(model1, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:26:27.199753Z",
     "start_time": "2019-02-07T23:26:26.912194Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model1, '2-7-19_10am_videonet_windowsize1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:13:02.524254Z",
     "start_time": "2019-02-07T19:13:02.467226Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:13:36.406887Z",
     "start_time": "2019-02-07T19:13:34.819413Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet2 = VideoNet(window_size=window_size)\n",
    "vnet2.init_weights()\n",
    "vnet2 = vnet2.to(device)\n",
    "optimizer2 = optim.SGD(vnet2.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler2 = lr_scheduler.StepLR(optimizer2, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:23:40.167763Z",
     "start_time": "2019-02-07T19:13:54.307683Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = train_model(vnet2, criterion, optimizer2, exp_lr_scheduler2, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:24:25.920374Z",
     "start_time": "2019-02-07T19:24:01.502885Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results2 = test_model(model2, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:26:19.499814Z",
     "start_time": "2019-02-07T19:26:19.444557Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives2 = []\n",
    "false_positives2 = []\n",
    "for (output, label), item in zip(training_test_results2, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives2.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives2.append((output, label, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:26:36.724326Z",
     "start_time": "2019-02-07T19:26:36.680493Z"
    }
   },
   "outputs": [],
   "source": [
    "fp_collected2 = collect(false_positives2, lambda tup: tup[2][0])\n",
    "false_positive_intrvls2 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected2[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:27:06.994213Z",
     "start_time": "2019-02-07T19:27:05.844479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls2, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:26:39.688871Z",
     "start_time": "2019-02-07T23:26:39.302400Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model2, '2-7-19_10am_videonet_windowsize2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:28:18.010354Z",
     "start_time": "2019-02-07T19:28:17.970444Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:28:40.548323Z",
     "start_time": "2019-02-07T19:28:38.395276Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet3 = VideoNet(window_size=window_size)\n",
    "vnet3.init_weights()\n",
    "vnet3 = vnet3.to(device)\n",
    "optimizer3 = optim.SGD(vnet3.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler3 = lr_scheduler.StepLR(optimizer3, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:42:05.616739Z",
     "start_time": "2019-02-07T19:28:58.984064Z"
    }
   },
   "outputs": [],
   "source": [
    "model3 = train_model(vnet3, criterion, optimizer3, exp_lr_scheduler3, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:43:09.199476Z",
     "start_time": "2019-02-07T19:42:35.199287Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results3 = test_model(model3, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:44:47.158354Z",
     "start_time": "2019-02-07T19:44:47.106152Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives3 = []\n",
    "false_positives3 = []\n",
    "for (output, label), item in zip(training_test_results3, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives3.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives3.append((output, label, item))\n",
    "fp_collected3 = collect(false_positives3, lambda tup: tup[2][0])\n",
    "false_positive_intrvls3 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected3[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:45:01.337536Z",
     "start_time": "2019-02-07T19:45:00.219164Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls3, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:27:31.474655Z",
     "start_time": "2019-02-07T23:27:30.967831Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model3, '2-7-19_10am_videonet_windowsize3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:46:47.100203Z",
     "start_time": "2019-02-07T19:46:47.057176Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 4\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T19:47:19.057761Z",
     "start_time": "2019-02-07T19:47:16.304699Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet4 = VideoNet(window_size=window_size)\n",
    "vnet4.init_weights()\n",
    "vnet4 = vnet4.to(device)\n",
    "optimizer4 = optim.SGD(vnet4.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler4 = lr_scheduler.StepLR(optimizer4, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:03:58.834939Z",
     "start_time": "2019-02-07T19:47:33.240874Z"
    }
   },
   "outputs": [],
   "source": [
    "model4 = train_model(vnet4, criterion, optimizer4, exp_lr_scheduler4, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:04:42.141671Z",
     "start_time": "2019-02-07T20:03:58.838370Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results4 = test_model(model4, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:49:37.180199Z",
     "start_time": "2019-02-07T20:49:37.128374Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives4 = []\n",
    "false_positives4 = []\n",
    "for (output, label), item in zip(training_test_results4, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives4.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives4.append((output, label, item))\n",
    "fp_collected4 = collect(false_positives4, lambda tup: tup[2][0])\n",
    "false_positive_intrvls4 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected4[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:49:39.012078Z",
     "start_time": "2019-02-07T20:49:37.878916Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls4, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:27:43.305517Z",
     "start_time": "2019-02-07T23:27:42.703859Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model4, '2-7-19_10am_videonet_windowsize4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:51:01.236848Z",
     "start_time": "2019-02-07T20:51:01.192168Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T20:51:29.400795Z",
     "start_time": "2019-02-07T20:51:25.915926Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet5 = VideoNet(window_size=window_size)\n",
    "vnet5.init_weights()\n",
    "vnet5 = vnet5.to(device)\n",
    "optimizer5 = optim.SGD(vnet5.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler5 = lr_scheduler.StepLR(optimizer5, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:10:55.823513Z",
     "start_time": "2019-02-07T20:51:47.301565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model5 = train_model(vnet5, criterion, optimizer5, exp_lr_scheduler5, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:12:08.953741Z",
     "start_time": "2019-02-07T21:11:16.057731Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results5 = test_model(model5, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:13:48.315284Z",
     "start_time": "2019-02-07T21:13:48.252312Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives5 = []\n",
    "false_positives5 = []\n",
    "for (output, label), item in zip(training_test_results5, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives5.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives5.append((output, label, item))\n",
    "fp_collected5 = collect(false_positives5, lambda tup: tup[2][0])\n",
    "false_positive_intrvls5 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected5[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:13:51.102247Z",
     "start_time": "2019-02-07T21:13:49.848801Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls5, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:27:55.324996Z",
     "start_time": "2019-02-07T23:27:54.621723Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model5, '2-7-19_10am_videonet_windowsize5.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:16:11.330001Z",
     "start_time": "2019-02-07T21:16:11.283842Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:16:43.990631Z",
     "start_time": "2019-02-07T21:16:40.238038Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet6 = VideoNet(window_size=window_size)\n",
    "vnet6.init_weights()\n",
    "vnet6 = vnet6.to(device)\n",
    "optimizer6 = optim.SGD(vnet6.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler6 = lr_scheduler.StepLR(optimizer6, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:39:49.928090Z",
     "start_time": "2019-02-07T21:16:59.852945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model6 = train_model(vnet6, criterion, optimizer6, exp_lr_scheduler6, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:07:58.568540Z",
     "start_time": "2019-02-07T23:06:55.833969Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results6 = test_model(model6, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:09:35.701708Z",
     "start_time": "2019-02-07T23:09:35.637848Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives6 = []\n",
    "false_positives6 = []\n",
    "for (output, label), item in zip(training_test_results6, dataset_training_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives6.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives6.append((output, label, item))\n",
    "fp_collected6 = collect(false_positives6, lambda tup: tup[2][0])\n",
    "false_positive_intrvls6 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected6[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected6\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:09:47.616846Z",
     "start_time": "2019-02-07T23:09:46.504932Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls6, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T23:28:08.497739Z",
     "start_time": "2019-02-07T23:28:07.828336Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model6, '2-7-19_10am_videonet_windowsize6.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Size 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:55:36.667061Z",
     "start_time": "2019-02-08T01:55:36.610095Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 7\n",
    "training_set_full.window_size = window_size\n",
    "training_set_loader = DataLoader(training_set_full, batch_size=8, shuffle=True, num_workers=0)\n",
    "training_set_test_full.window_size = window_size\n",
    "training_test_loader = DataLoader(training_set_test_full, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T01:55:42.752970Z",
     "start_time": "2019-02-08T01:55:37.709535Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet7 = VideoNet(window_size=window_size)\n",
    "vnet7.init_weights()\n",
    "vnet7 = vnet7.to(device)\n",
    "optimizer7 = optim.SGD(vnet7.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler7 = lr_scheduler.StepLR(optimizer7, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T02:20:47.838675Z",
     "start_time": "2019-02-08T01:56:55.450153Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model7 = train_model(vnet7, criterion, optimizer7, exp_lr_scheduler7, num_epochs=100, dataloader=training_set_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:02:04.634230Z",
     "start_time": "2019-02-08T18:00:54.581816Z"
    }
   },
   "outputs": [],
   "source": [
    "training_test_results7 = test_model(model7, criterion, training_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:04:50.161116Z",
     "start_time": "2019-02-08T18:04:50.108546Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positives7 = []\n",
    "false_positives7 = []\n",
    "for (output, label), item in zip(training_test_results7, training_set_test_full.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positives7.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positives7.append((output, label, item))\n",
    "fp_collected7 = collect(false_positives7, lambda tup: tup[2][0])\n",
    "false_positive_intrvls7 = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collected7[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collected7\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:05:21.188379Z",
     "start_time": "2019-02-08T18:05:21.108562Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvls7, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T18:05:48.175359Z",
     "start_time": "2019-02-08T18:05:47.230475Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model7, '2-7-19_5pm_videonet_windowsize7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:45:49.391013Z",
     "start_time": "2019-02-08T19:45:48.864428Z"
    }
   },
   "outputs": [],
   "source": [
    "modeltest = torch.load('models/2-7-19_5pm_videonet_windowsize7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:47:32.912539Z",
     "start_time": "2019-02-08T19:45:50.512554Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results = test_model(modeltest, criterion, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:51:10.563852Z",
     "start_time": "2019-02-08T19:51:10.482052Z"
    }
   },
   "outputs": [],
   "source": [
    "true_positivestest = []\n",
    "false_positivestest = []\n",
    "for (output, label), item in zip(test_results, dataset_test.items):\n",
    "    if output >= 0 and label == 1:\n",
    "        true_positivestest.append((output, label, item))        \n",
    "    if output > 0 and label == 0:\n",
    "        false_positivestest.append((output, label, item))\n",
    "tp_collectedtest = collect(true_positivestest, lambda tup: tup[2][0])\n",
    "true_positive_intrvlstest = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in tp_collectedtest[video_id]\n",
    "    ]\n",
    "    for video_id in tp_collectedtest\n",
    "})\n",
    "fp_collectedtest = collect(false_positivestest, lambda tup: tup[2][0])\n",
    "false_positive_intrvlstest = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (item[1], item[1], 0)\n",
    "        for output, label, item in fp_collectedtest[video_id]\n",
    "    ]\n",
    "    for video_id in fp_collectedtest\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:51:37.002103Z",
     "start_time": "2019-02-08T19:51:33.569950Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(true_positive_intrvlstest, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:51:53.465634Z",
     "start_time": "2019-02-08T19:51:52.195496Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(\n",
    "    intrvllists_to_result_with_objects(false_positive_intrvlstest, lambda a, b: []),\n",
    "    jupyter_keybindings=True,\n",
    "    display_captions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:19:22.892835Z",
     "start_time": "2019-02-18T00:19:22.744474Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeepSBDDataset(Dataset):\n",
    "    def __init__(self, shots, window_size=16, stride=8, size=128):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            shots: VideoIntervalCollection of all the intervals to get frames from. If the payload is -1,\n",
    "            then the interval is not an actual shot and just needs to be included in the dataset.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        items = set()\n",
    "        frame_nums = {}\n",
    "        \n",
    "        shot_boundaries = shots.map(\n",
    "            lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    "        ).filter(lambda intrvl: intrvl.payload != -1)\n",
    "        \n",
    "        clips = shots.dilate(1).coalesce().dilate(-1).map(\n",
    "            lambda intrvl: (\n",
    "                intrvl.start - stride - ((intrvl.start - stride) % stride),\n",
    "                intrvl.end + stride - ((intrvl.end + stride) % stride),\n",
    "                intrvl.payload\n",
    "            )\n",
    "        ).dilate(1).coalesce().dilate(-1)\n",
    "        \n",
    "        items_intrvls = {}\n",
    "        for video_id in clips.get_allintervals():\n",
    "            items_intrvls[video_id] = []\n",
    "            for intrvl in clips.get_intervallist(video_id).get_intervals():\n",
    "                items_intrvls[video_id] += [\n",
    "                    (f, f + window_size, 0)\n",
    "                    for f in range(intrvl.start, intrvl.end - stride, stride)\n",
    "                ]\n",
    "        items_col = VideoIntervalCollection(items_intrvls)\n",
    "        \n",
    "        items_w_boundaries = items_col.filter_against(\n",
    "            shot_boundaries,\n",
    "            predicate=during_inv()\n",
    "        ).map(\n",
    "            lambda intrvl: (intrvl.start, intrvl.end, 2)\n",
    "        )\n",
    "        \n",
    "        items_w_labels = items_col.minus(\n",
    "            items_w_boundaries, predicate=equal()\n",
    "        ).set_union(items_w_boundaries)\n",
    "\n",
    "        for video_id in items_w_labels.get_allintervals():\n",
    "            frame_nums[video_id] = set()\n",
    "            for intrvl in items_w_labels.get_intervallist(video_id).get_intervals():\n",
    "                items.add((\n",
    "                    video_id,\n",
    "                    intrvl.start,\n",
    "                    intrvl.end,\n",
    "                    intrvl.payload\n",
    "                ))\n",
    "                for f in range(intrvl.start, intrvl.end):\n",
    "                    frame_nums[video_id].add(f)\n",
    "\n",
    "        self.items = sorted(list(items))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            Scale((128, 128)),\n",
    "            ToTensor(1),\n",
    "            Normalize(get_mean(1), (1, 1, 1))\n",
    "        ])\n",
    "        \n",
    "        # Load frames into memory\n",
    "        self.frames = {\n",
    "            video_id: {\n",
    "                'frame_nums': sorted(list(frame_nums[video_id])),\n",
    "                'frames': [\n",
    "                    self.transform(f)\n",
    "                    for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "                        sorted(list(frame_nums[video_id]))\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "            for video_id in tqdm(frame_nums)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video_id, start_frame, end_frame, label = self.items[idx]\n",
    "        \n",
    "        start_index = self.frames[video_id]['frame_nums'].index(start_frame)\n",
    "        img_tensors = self.frames[video_id]['frames'][start_index:start_index + self.window_size]\n",
    "        \n",
    "#         img_tensors = [\n",
    "#             self.transform(f)\n",
    "#             for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "#                 list(range(frame_num - self.window_size, frame_num + self.window_size + 1))\n",
    "#             )\n",
    "#         ]\n",
    "        \n",
    "        return torch.stack(img_tensors).permute(1, 0, 2, 3), label, (video_id, start_frame, end_frame)\n",
    "#         return label, (video_id, start_frame, end_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:05.172047Z",
     "start_time": "2019-02-18T00:19:26.486552Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbddata = DeepSBDDataset(shots_gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:37.535639Z",
     "start_time": "2019-02-18T00:21:37.478547Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbddataloader = DataLoader(deepsbddata, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:39.183916Z",
     "start_time": "2019-02-18T00:21:39.070977Z"
    }
   },
   "outputs": [],
   "source": [
    "class deepSBD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(deepSBD, self).__init__()\n",
    "        self.conv1=nn.Conv3d(3, 96, kernel_size=3, stride=(1, 2, 2),\n",
    "                               padding=(0,0,0), bias=True)\n",
    "        self.relu1=nn.ReLU(inplace=True)\n",
    "        self.pool1=nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(1,2,2), padding=0)\n",
    "        self.conv2=nn.Conv3d(96, 256, kernel_size=3, stride=(1, 2, 2),\n",
    "                               padding=(0,0,0), bias=True)\n",
    "        self.relu2=nn.ReLU(inplace=True)\n",
    "        self.pool2=nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(1,2,2), padding=0)\n",
    "        self.conv3=nn.Conv3d(256, 384, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=True)\n",
    "        self.relu3=nn.ReLU(inplace=True)\n",
    "        self.conv4=nn.Conv3d(384, 384, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=True)\n",
    "        self.relu4=nn.ReLU(inplace=True)\n",
    "        self.conv5=nn.Conv3d(384, 256, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=True)\n",
    "        self.relu5=nn.ReLU(inplace=True)\n",
    "        self.pool1=nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(1,2,2), padding=0)\n",
    "        self.fc6=nn.Linear(100352, 2048)\n",
    "        self.relu6=nn.ReLU(inplace=True)\n",
    "        self.fc7=nn.Linear(2048, 2048)\n",
    "        self.relu7=nn.ReLU(inplace=True)\n",
    "        self.fc8=nn.Linear(2048, 3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.relu3(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.relu4(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.relu5(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc6(x)\n",
    "        x=self.relu6(x)\n",
    "        x=self.fc7(x)\n",
    "        x=self.relu7(x)\n",
    "        x=self.fc8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:42.196953Z",
     "start_time": "2019-02-18T00:21:41.486338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "__all__ = ['ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnet200']\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3,\n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(out.size(0), planes - out.size(1),\n",
    "                             out.size(2), out.size(3),\n",
    "                             out.size(4)).zero_()\n",
    "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "        zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, sample_size, sample_duration, shortcut_type='B', num_classes=400):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2),\n",
    "                               padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], shortcut_type, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], shortcut_type, stride=2)\n",
    "        last_duration = math.ceil(sample_duration / 16)\n",
    "        last_size = math.ceil(sample_size / 32)\n",
    "        self.avgpool = nn.AvgPool3d((last_duration, last_size, last_size), stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                m.eval()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                bn=nn.BatchNorm3d(planes * block.expansion)\n",
    "                bn.eval()\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                              kernel_size=1, stride=stride, bias=False),\n",
    "                    bn\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_weights(self, base_file):\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            pretrained=torch.load(base_file, map_location=lambda storage, loc: storage)['state_dict']\n",
    "            pretrained={\"{}\".format(s[7:]):v for s,v in pretrained.items()}\n",
    "            current_param=self.state_dict()\n",
    "            pretrained={k:v for k,v in pretrained.items() if k in current_param and k[:2]!='fc'}\n",
    "            current_param.update(pretrained)\n",
    "            print(pretrained.keys())\n",
    "            #print(self.state_dict().keys())\n",
    "            self.load_state_dict(current_param)\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('Sorry only .pth and .pkl files supported.')\n",
    "\n",
    "\n",
    "def get_fine_tuning_parameters(model, ft_begin_index):\n",
    "    if ft_begin_index == 0:\n",
    "        return model.parameters()\n",
    "\n",
    "    ft_module_names = []\n",
    "    for i in range(ft_begin_index, 5):\n",
    "        ft_module_names.append('layer{}'.format(ft_begin_index))\n",
    "    ft_module_names.append('fc')\n",
    "\n",
    "    parameters = []\n",
    "    for k, v in model.named_parameters():\n",
    "        for ft_module in ft_module_names:\n",
    "            if ft_module in k:\n",
    "                parameters.append({'params': v})\n",
    "                break\n",
    "        else:\n",
    "            parameters.append({'params': v, 'lr': 0.0})\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:52.946093Z",
     "start_time": "2019-02-18T00:21:51.181443Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_alexnet_model = deepSBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:57.986497Z",
     "start_time": "2019-02-18T00:21:53.884762Z"
    }
   },
   "outputs": [],
   "source": [
    "alexnet_state_dict = torch.load('models/ClipShots-DeepSBD-Alexnet-final.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:58.734779Z",
     "start_time": "2019-02-18T00:21:58.686205Z"
    }
   },
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "for k, v in alexnet_state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:21:59.741132Z",
     "start_time": "2019-02-18T00:21:59.542300Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_alexnet_model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:00.825960Z",
     "start_time": "2019-02-18T00:22:00.647117Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_alexnet_model = deepsbd_alexnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:01.807619Z",
     "start_time": "2019-02-18T00:22:01.766359Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_alexnet_model = deepsbd_alexnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:04.878891Z",
     "start_time": "2019-02-18T00:22:04.127058Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model = resnet18(num_classes=3,\n",
    "                                sample_size=128,\n",
    "                                sample_duration=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:05.758295Z",
     "start_time": "2019-02-18T00:22:05.549931Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_state_dict = torch.load('models/ClipShots-DeepSBD-Resnet-18-final.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:06.580569Z",
     "start_time": "2019-02-18T00:22:06.534534Z"
    }
   },
   "outputs": [],
   "source": [
    "new_resnet_state_dict = OrderedDict()\n",
    "for k, v in resnet_state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_resnet_state_dict[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:07.510498Z",
     "start_time": "2019-02-18T00:22:07.430521Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model.load_state_dict(new_resnet_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:08.304173Z",
     "start_time": "2019-02-18T00:22:08.245338Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model = deepsbd_resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:09.898272Z",
     "start_time": "2019-02-18T00:22:09.854295Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbd_resnet_model = deepsbd_resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:11.135999Z",
     "start_time": "2019-02-18T00:22:11.093954Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(res_tensor):\n",
    "    res_numpy=res_tensor.data.cpu().numpy()\n",
    "    labels=[]\n",
    "    for row in res_numpy:\n",
    "        labels.append(np.argmax(row))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:12.741768Z",
     "start_time": "2019-02-18T00:22:12.686760Z"
    }
   },
   "outputs": [],
   "source": [
    "def prf1_array(pos_label, neg_label, gt, preds):\n",
    "    tp = 0.\n",
    "    fp = 0.\n",
    "    tn = 0.\n",
    "    fn = 0.\n",
    "    \n",
    "    for truth, pred in zip(gt, preds):\n",
    "        if truth == pred:\n",
    "            if pred == pos_label:\n",
    "                tp += 1.\n",
    "            else:\n",
    "                tn += 1.\n",
    "        else:\n",
    "            if pred == pos_label:\n",
    "                fp += 1.\n",
    "            else:\n",
    "                fn += 1.\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "    \n",
    "    return (precision, recall, f1, tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:13.885375Z",
     "start_time": "2019-02-18T00:22:13.826011Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_deepsbd(model, dataloader):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    outputs = []\n",
    "    for clip_tensor, l, _ in tqdm(dataloader):\n",
    "        o = model(clip_tensor.to(device))\n",
    "\n",
    "        preds += get_label(o)\n",
    "        labels += l.data.numpy().tolist()\n",
    "        outputs += o.cpu().data.numpy().tolist()\n",
    "    \n",
    "    preds = [2 if p == 2 else 0 for p in preds]\n",
    "        \n",
    "    precision, recall, f1, tp, tn, fp, fn = prf1_array(2, 0, labels, preds)\n",
    "    print(\"Precision: {}, Recall: {}, F1: {}\".format(precision, recall, f1))\n",
    "    print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(tp, tn, fp, fn))\n",
    "    \n",
    "    return preds, labels, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:20.232931Z",
     "start_time": "2019-02-18T00:22:15.454795Z"
    }
   },
   "outputs": [],
   "source": [
    "training_preds, training_labels, training_outputs = test_deepsbd(deepsbd_alexnet_model, deepsbddataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T00:22:31.282242Z",
     "start_time": "2019-02-18T00:22:23.381978Z"
    }
   },
   "outputs": [],
   "source": [
    "training_preds_rn, training_labels_rn, training_outputs_rn = test_deepsbd(deepsbd_resnet_model, deepsbddataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClipShots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T21:19:28.165933Z",
     "start_time": "2019-02-15T21:19:28.121847Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:58:31.623301Z",
     "start_time": "2019-02-14T17:58:31.160313Z"
    }
   },
   "outputs": [],
   "source": [
    "# load up ground truth from the clipshots data\n",
    "with open('/app/data/ClipShots/annotations/train.json', 'r') as f:\n",
    "    train_gt = json.load(f)\n",
    "with open('/app/data/ClipShots/annotations/test.json', 'r') as f:\n",
    "    test_gt = json.load(f)\n",
    "with open('/app/data/ClipShots/annotations/only_gradual.json', 'r') as f:\n",
    "    only_gradual_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T18:05:29.610454Z",
     "start_time": "2019-02-14T18:05:29.542224Z"
    }
   },
   "outputs": [],
   "source": [
    "# load up video lists\n",
    "with open('/app/data/ClipShots/video_lists/train.txt', 'r') as f:\n",
    "    train_videos = [\n",
    "        l.strip() for l in f.readlines()\n",
    "    ]\n",
    "with open('/app/data/ClipShots/video_lists/test.txt', 'r') as f:\n",
    "    test_videos = [\n",
    "        l.strip() for l in f.readlines()\n",
    "    ]\n",
    "with open('/app/data/ClipShots/video_lists/only_gradual.txt', 'r') as f:\n",
    "    only_gradual_videos = [\n",
    "        l.strip() for l in f.readlines()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T21:20:00.570105Z",
     "start_time": "2019-02-15T21:20:00.527125Z"
    }
   },
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                return img.convert('RGB')\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:56:01.413808Z",
     "start_time": "2019-02-15T22:56:00.678231Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        for t in self.transforms:\n",
    "            t.randomize_parameters()\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``PIL.Image`` or ``numpy.ndarray`` to tensor.\n",
    "    Converts a PIL.Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm_value=255):\n",
    "        self.norm_value = norm_value\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL.Image or numpy.ndarray): Image to be converted to tensor.\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
    "            # backward compatibility\n",
    "            return img.float().div(self.norm_value)\n",
    "\n",
    "        if accimage is not None and isinstance(pic, accimage.Image):\n",
    "            nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n",
    "            pic.copyto(nppic)\n",
    "            return torch.from_numpy(nppic)\n",
    "\n",
    "        # handle PIL Image\n",
    "        if pic.mode == 'I':\n",
    "            img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
    "        elif pic.mode == 'I;16':\n",
    "            img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
    "        else:\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "        # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "        if pic.mode == 'YCbCr':\n",
    "            nchannel = 3\n",
    "        elif pic.mode == 'I;16':\n",
    "            nchannel = 1\n",
    "        else:\n",
    "            nchannel = len(pic.mode)\n",
    "        img = img.view(pic.size[1], pic.size[0], nchannel)\n",
    "        # put it from HWC to CHW format\n",
    "        # yikes, this transpose takes 80% of the loading time/CPU\n",
    "        img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        if isinstance(img, torch.ByteTensor):\n",
    "            return img.float().div(self.norm_value)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel - mean) / std\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Scale(object):\n",
    "    \"\"\"Rescale the input PIL.Image to the given size.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (w, h), output size will be matched to this. If size is an int,\n",
    "            smaller edge of the image will be matched to this number.\n",
    "            i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be scaled.\n",
    "        Returns:\n",
    "            PIL.Image: Rescaled image.\n",
    "        \"\"\"\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            return img.resize(self.size, self.interpolation)\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Crops the given PIL.Image at the center.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL.Image: Cropped image.\n",
    "        \"\"\"\n",
    "        w, h = img.size\n",
    "        th, tw = self.size\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CornerCrop(object):\n",
    "    def __init__(self, size, crop_position=None):\n",
    "        self.size = size\n",
    "        if crop_position is None:\n",
    "            self.randomize = True\n",
    "        else:\n",
    "            self.randomize = False\n",
    "        self.crop_position = crop_position\n",
    "        self.crop_positions = ['c', 'tl', 'tr', 'bl', 'br']\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width = img.size[0]\n",
    "        image_height = img.size[1]\n",
    "\n",
    "        if self.crop_position == 'c':\n",
    "            th, tw = (self.size, self.size)\n",
    "            x1 = int(round((image_width - tw) / 2.))\n",
    "            y1 = int(round((image_height - th) / 2.))\n",
    "            x2 = x1 + tw\n",
    "            y2 = y1 + th\n",
    "        elif self.crop_position == 'tl':\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "            x2 = self.size\n",
    "            y2 = self.size\n",
    "        elif self.crop_position == 'tr':\n",
    "            x1 = image_width - self.size\n",
    "            y1 = 0\n",
    "            x2 = image_width\n",
    "            y2 = self.size\n",
    "        elif self.crop_position == 'bl':\n",
    "            x1 = 0\n",
    "            y1 = image_height - self.size\n",
    "            x2 = self.size\n",
    "            y2 = image_height\n",
    "        elif self.crop_position == 'br':\n",
    "            x1 = image_width - self.size\n",
    "            y1 = image_height - self.size\n",
    "            x2 = image_width\n",
    "            y2 = image_height\n",
    "\n",
    "        img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        if self.randomize:\n",
    "            self.crop_position = self.crop_positions[\n",
    "                random.randint(0, len(self.crop_positions) - 1)]\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL.Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if self.p < 0.5:\n",
    "            return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        self.p = random.random()\n",
    "\n",
    "\n",
    "class MultiScaleCornerCrop(object):\n",
    "    \"\"\"Crop the given PIL.Image to randomly selected size.\n",
    "    A crop of size is selected from scales of the original size.\n",
    "    A position of cropping is randomly selected from 4 corners and 1 center.\n",
    "    This crop is finally resized to given size.\n",
    "    Args:\n",
    "        scales: cropping scales of the original size\n",
    "        size: size of the smaller edge\n",
    "        interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scales, size, interpolation=Image.BILINEAR):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "        self.crop_positions = ['c', 'tl', 'tr', 'bl', 'br']\n",
    "\n",
    "    def __call__(self, img):\n",
    "        min_length = min(img.size[0], img.size[1])\n",
    "        crop_size = int(min_length * self.scale)\n",
    "\n",
    "        image_width = img.size[0]\n",
    "        image_height = img.size[1]\n",
    "\n",
    "        if self.crop_position == 'c':\n",
    "            center_x = image_width // 2\n",
    "            center_y = image_height // 2\n",
    "            box_half = crop_size // 2\n",
    "            x1 = center_x - box_half\n",
    "            y1 = center_y - box_half\n",
    "            x2 = center_x + box_half\n",
    "            y2 = center_y + box_half\n",
    "        elif self.crop_position == 'tl':\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "            x2 = crop_size\n",
    "            y2 = crop_size\n",
    "        elif self.crop_position == 'tr':\n",
    "            x1 = image_width - crop_size\n",
    "            y1 = 0\n",
    "            x2 = image_width\n",
    "            y2 = crop_size\n",
    "        elif self.crop_position == 'bl':\n",
    "            x1 = 0\n",
    "            y1 = image_height - crop_size\n",
    "            x2 = crop_size\n",
    "            y2 = image_height\n",
    "        elif self.crop_position == 'br':\n",
    "            x1 = image_width - crop_size\n",
    "            y1 = image_height - crop_size\n",
    "            x2 = image_width\n",
    "            y2 = image_height\n",
    "\n",
    "        img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        return img.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.crop_position = self.crop_positions[random.randint(0, len(self.scales) - 1)]\n",
    "\n",
    "def get_mean(norm_value=255):\n",
    "    return [114.7748 / norm_value, 107.7354 / norm_value, 99.4750 / norm_value]\n",
    "\n",
    "def get_train_spatial_transform(opt):\n",
    "    return Compose([MultiScaleCornerCrop(opt.scales, opt.sample_size),\n",
    "                                     RandomHorizontalFlip(),\n",
    "                                     ToTensor(opt.norm_value),\n",
    "                                     Normalize(get_mean(opt.norm_value), [1, 1, 1])])\n",
    "\n",
    "def get_test_spatial_transform(opt):\n",
    "    return Compose([Scale((opt.spatial_size,opt.spatial_size)),\n",
    "                    ToTensor(opt.norm_value),\n",
    "                    Normalize(get_mean(opt.norm_value), [1, 1, 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T23:07:17.779894Z",
     "start_time": "2019-02-15T23:07:17.623753Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeepSBDClipShotsDataset(Dataset):\n",
    "    def __init__(self, root_path, video_list, annotations, window_size=16, stride=8, size=128):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            root_path: path to the folder that holds the videos\n",
    "            shots: list of video names\n",
    "            annotations: dict mapping video names to dicts of 'frame_num' and 'transitions' -\n",
    "                frame_num is the number of frames in the video, transitions is a list of arrays of\n",
    "                length two with start/end\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.root_path = root_path\n",
    "        items = set()\n",
    "        frame_nums = {}\n",
    "        \n",
    "        for video in video_list:\n",
    "            frame_nums[video] = set()\n",
    "            items_intrvllist = IntervalList([\n",
    "                (f, f+16, 0)\n",
    "                for f in range(0, int(annotations[video]['frame_num']), stride)\n",
    "            ])\n",
    "            transitions = IntervalList([\n",
    "                (t[0], t[1], 0)\n",
    "                for t in annotations[video]['transitions']\n",
    "            ])\n",
    "            items_w_cuts = items_intrvllist.filter_against(\n",
    "                transitions.filter_length(max_length=1),\n",
    "                predicate=during_inv(),\n",
    "                working_window=1\n",
    "            ).map(\n",
    "                lambda intrvl: (\n",
    "                    intrvl.start,\n",
    "                    intrvl.end,\n",
    "                    2\n",
    "                )\n",
    "            )\n",
    "            items_w_transitions = items_intrvllist.filter_against(\n",
    "                transitions.filter_length(min_length=2),\n",
    "                predicate=during_inv(),\n",
    "                working_window=1\n",
    "            ).map(\n",
    "                lambda intrvl: (\n",
    "                    intrvl.start,\n",
    "                    intrvl.end,\n",
    "                    1\n",
    "                )\n",
    "            )\n",
    "            final_items = items_intrvllist.minus(\n",
    "                items_w_cuts, predicate = equal()\n",
    "            ).set_union(items_w_cuts).minus(\n",
    "                items_w_transitions, predicate = equal()\n",
    "            ).set_union(items_w_transitions)\n",
    "            for intrvl in final_items.get_intervals():\n",
    "                items.add((\n",
    "                    video,\n",
    "                    intrvl.start,\n",
    "                    intrvl.end,\n",
    "                    intrvl.payload\n",
    "                ))\n",
    "            \n",
    "            for i in range(0, int(annotations[video]['frame_num'])):\n",
    "                frame_nums[video].add(i)\n",
    "\n",
    "        self.items = sorted(list(items))\n",
    "        \n",
    "        self.transform = get_test_spatial_transform(Opt(128, 1))\n",
    "        \n",
    "        # Load frames into memory. NEED TO REWRITE THIS!\n",
    "#         self.frames = {\n",
    "#             video_id: {\n",
    "#                 'frame_nums': sorted(list(frame_nums[video_id])),\n",
    "#                 'frames': [\n",
    "#                     self.transform(f)\n",
    "#                     for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "#                         sorted(list(frame_nums[video_id]))\n",
    "#                     )\n",
    "#                 ]\n",
    "#             }\n",
    "#             for video_id in tqdm(frame_nums)\n",
    "#         }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video, start_frame, end_frame, label = self.items[idx]\n",
    "        \n",
    "#         start_index = self.items[video_id]['frame_nums'].index(start_frame)\n",
    "#         img_tensors = self.frames[video_id]['frames'][start_index:start_index + self.window_size]\n",
    "        \n",
    "#         img_tensors = [\n",
    "#             self.transform(f)\n",
    "#             for f in Video.objects.get(id=video_id).for_scannertools().frames(\n",
    "#                 list(range(frame_num - self.window_size, frame_num + self.window_size + 1))\n",
    "#             )\n",
    "#         ]\n",
    "\n",
    "        imgs = []\n",
    "        for i in range(start_frame, end_frame):\n",
    "            img = pil_loader(os.path.join(self.root_path, video, 'image_{}.jpg'.format(i)))\n",
    "            if img is not None:\n",
    "                imgs.append(self.transform(img))\n",
    "        if len(imgs) == 0:\n",
    "            return None\n",
    "                \n",
    "        while len(imgs) < self.window_size:\n",
    "            imgs.append(imgs[-1])\n",
    "            \n",
    "        return torch.stack(imgs).permute(1, 0, 2, 3), label, (video, start_frame, end_frame)\n",
    "#         return label, (video_id, start_frame, end_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T23:07:20.660831Z",
     "start_time": "2019-02-15T23:07:20.517315Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbdclipshot_dataset_train = DeepSBDClipShotsDataset(\n",
    "    '/app/data/ClipShots/frames/train',\n",
    "    train_videos[:1],\n",
    "    train_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:59:56.733714Z",
     "start_time": "2019-02-15T22:59:56.690583Z"
    }
   },
   "outputs": [],
   "source": [
    "train_videos[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:52:44.901273Z",
     "start_time": "2019-02-15T22:52:44.857478Z"
    }
   },
   "outputs": [],
   "source": [
    "im = pil_loader('/app/data/ClipShots/frames/train/4001498009.mp4/image_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:52:55.459373Z",
     "start_time": "2019-02-15T22:52:55.418179Z"
    }
   },
   "outputs": [],
   "source": [
    "print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:57:40.370007Z",
     "start_time": "2019-02-15T22:57:40.331759Z"
    }
   },
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self, spatial_size, norm_value):\n",
    "        self.spatial_size = spatial_size\n",
    "        self.norm_value = norm_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:58:03.661719Z",
     "start_time": "2019-02-15T22:58:03.533743Z"
    }
   },
   "outputs": [],
   "source": [
    "get_test_spatial_transform(Opt(128, 1))(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:59:06.177116Z",
     "start_time": "2019-02-15T22:59:06.049779Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((114.7748, 107.7354, 99.475), (1, 1, 1))\n",
    "        ])(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:20:14.515208Z",
     "start_time": "2019-02-15T22:20:14.471501Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gt['4001498009.mp4']['frame_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T23:07:25.271694Z",
     "start_time": "2019-02-15T23:07:25.233654Z"
    }
   },
   "outputs": [],
   "source": [
    "deepsbdclipshot_train_loader = DataLoader(deepsbdclipshot_dataset_train, batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T23:08:16.156565Z",
     "start_time": "2019-02-15T23:07:26.023930Z"
    }
   },
   "outputs": [],
   "source": [
    "a, b, c = test_deepsbd(deepsbd_resnet_model, deepsbdclipshot_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T23:09:06.276391Z",
     "start_time": "2019-02-15T23:08:16.159603Z"
    }
   },
   "outputs": [],
   "source": [
    "aa, bb, cc = test_deepsbd(deepsbd_alexnet_model, deepsbdclipshot_train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model/loss: raw output of last FC layer to BCEWithLogitsLoss\n",
    "\n",
    "Training with perfectly balanced classes - selected 58 positive examples from training dataset and randomly selected 58 negative examples:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 26.7%/24.4%. Confusion matrix `TP: 139.0 TN: 52399.0 FP: 381.0 FN: 430.0`. Output of model had absolute value < 0.5.\n",
    "* Saved in `2-5-19_529pm_videonet_1to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Training with 10:1 class imbalance - 58 positive examples, 580 randomly selected negative examples:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 57.9%/1.9%. Confusion matrix `TP: 11.0 TN: 52772.0 FP: 8.0 FN: 558.0`. Output of model had absolute value around 5-10.\n",
    "* Saved in `2-6-19_948am_videonet_10to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Training with 2:1 class imbalance - 58 positive examples, 58 randomly selected negative examples, 58 examples from the end of shots:\n",
    "* Achieved 100% accuracy on train.\n",
    "* On test, precision/recall at 18.2%/3.9%. Confusion matrix `TP: 22.0 TN: 52681.0 FP: 99.0 FN: 547.0`. Output of model had absolute value < 2.\n",
    "* Saved in `2-6-19_1016am_videonet_2to1classbalance_bcewithlogitsloss.pth`.\n",
    "\n",
    "Issue: if you train on a subset of frames from the training clips, you won't do great on the full range of frames from the training clips. I.e. if you train on all the shot transitions, along with some random selected non-transition frames, you'll be able to identify all the shot transitions in your training clips, but you'll also get a bunch of false positives.\n",
    "\n",
    "Training with a 3:1 class imbalance and 97 positive examples - plus 97 randomly selected negative examples. 97 examples from the end of shots, and 97 examples from the frame right after each shot transition.\n",
    "* 100% accuracy on the training set.\n",
    "* On the full set of training clips, 100% recall with 66% precision.\n",
    "* On the set of training clips, hallucinating that many frames in a row are shot boundaries. Confusion matrix `TP: 97.0 TN: 7155.0 FP: 49.0 FN: 0.0`.\n",
    "* Saved in `2-6-19_5pm_videonet_3to1classbalance_bcewithlogitsloss.pth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:47:44.853381Z",
     "start_time": "2019-02-04T17:47:44.756804Z"
    }
   },
   "outputs": [],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    inputs = [i.to(device) for i in inputs]\n",
    "    labels = labels.to(device)\n",
    "    outputs = vnet(inputs[0], inputs[1], inputs[2])\n",
    "    print(outputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:33:24.309227Z",
     "start_time": "2019-02-02T07:33:24.259449Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(\n",
    "    torch.tensor([\n",
    "        [0.3, 0.7],\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.3]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        1, 0, 0, 0\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:46:43.148824Z",
     "start_time": "2019-02-02T07:46:43.115481Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([.01, 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:54:03.467426Z",
     "start_time": "2019-02-04T17:54:03.418652Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=torch.tensor([1., .5]).to(device))(\n",
    "    torch.tensor(\n",
    "        [[-0.9855, 1.1573]]\n",
    "    ).to(device),\n",
    "    torch.tensor([1]).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:47:05.924229Z",
     "start_time": "2019-02-02T07:47:05.875365Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(\n",
    "    torch.tensor([\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2],\n",
    "        [0.8, 0.2]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        1, 0, 0, 0\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.679659Z",
     "start_time": "2019-01-30T18:46:21.401945Z"
    }
   },
   "outputs": [],
   "source": [
    "#tenlayer_resnet = models.ResNet(models.resnet.BasicBlock, [1, 1, 1, 1], num_classes=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.725369Z",
     "start_time": "2019-01-30T18:46:21.682349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the avgpool layer with an AdaptiveAvgPool so we don't have to worry about input size\n",
    "#tenlayer_resnet.avgpool = nn.AdaptiveAvgPool2d((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.770551Z",
     "start_time": "2019-01-30T18:46:21.727728Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(tenlayer_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.814927Z",
     "start_time": "2019-01-30T18:46:21.773056Z"
    }
   },
   "outputs": [],
   "source": [
    "#params = list(tenlayer_resnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.861630Z",
     "start_time": "2019-01-30T18:46:21.817094Z"
    }
   },
   "outputs": [],
   "source": [
    "#len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:21.921166Z",
     "start_time": "2019-01-30T18:46:21.864281Z"
    }
   },
   "outputs": [],
   "source": [
    "#params[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:25.853366Z",
     "start_time": "2019-01-30T18:46:21.923954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load up an image and run it through the network\n",
    "vid_id = list(shots_gt.get_allintervals().keys())[0]\n",
    "frame = shots_gt.get_intervallist(vid_id).get_intervals()[0].start\n",
    "img = cv2.cvtColor(load_frame(Video.objects.get(id=vid_id), frame, []), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:25.930315Z",
     "start_time": "2019-01-30T18:46:25.855973Z"
    }
   },
   "outputs": [],
   "source": [
    "#img_tensor = transforms.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:27.508647Z",
     "start_time": "2019-01-30T18:46:25.932776Z"
    }
   },
   "outputs": [],
   "source": [
    "#tenlayer_resnet(img_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:21.242891Z",
     "start_time": "2019-02-04T17:46:16.791137Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = [\n",
    "   cv2.cvtColor(load_frame(Video.objects.get(id=123), f, []), cv2.COLOR_BGR2RGB)\n",
    "   for f in range(14455-1, 14455+2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:31.789691Z",
     "start_time": "2019-02-02T06:52:31.109122Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:33.365579Z",
     "start_time": "2019-02-02T06:52:32.661208Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:35.229727Z",
     "start_time": "2019-02-02T06:52:34.508177Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:21.313660Z",
     "start_time": "2019-02-04T17:46:21.270556Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:22.144299Z",
     "start_time": "2019-02-04T17:46:22.066566Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tensors = [\n",
    "    transform(npimg).unsqueeze(0).to(device)\n",
    "    for npimg in imgs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:21:09.512104Z",
     "start_time": "2019-02-02T07:21:09.033686Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:25.355822Z",
     "start_time": "2019-02-04T17:46:25.287032Z"
    }
   },
   "outputs": [],
   "source": [
    "o = vnet(img_tensors[0], img_tensors[1], img_tensors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:46:26.343946Z",
     "start_time": "2019-02-04T17:46:26.294723Z"
    }
   },
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T07:17:37.130594Z",
     "start_time": "2019-02-02T07:17:37.062589Z"
    }
   },
   "outputs": [],
   "source": [
    "model(img_tensors[0], img_tensors[1], img_tensors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:52:42.732433Z",
     "start_time": "2019-02-02T06:52:42.687175Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.max(o, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:07:44.130846Z",
     "start_time": "2019-01-30T19:07:44.083431Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShotDetectionDataset(Dataset):\n",
    "    def __init__(self, shots, window_size=1, height=224):\n",
    "        \"\"\"Constrcutor for ShotDetectionDataset.\n",
    "        \n",
    "        Args:\n",
    "            shots: VideoIntervalCollection of all the intervals to get frames from.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        frames = set()\n",
    "        \n",
    "        for video_id in shots.get_allintervals():\n",
    "            for intrvl in shots.get_intervallist(video_id).get_intervals():\n",
    "                for f in range(intrvl.start, intrvl.end + 1):\n",
    "                    frames.add((video_id, f, 1 if f == intrvl.start else 0))\n",
    "        self.frames = sorted(list(frames))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Indexed by video ID, then frame number\n",
    "        Returns self.window_size frames before the indexed frame to self.window_size\n",
    "            frames after the indexed frame\n",
    "        \"\"\"\n",
    "        video_id, frame_num, label = self.frames[idx]\n",
    "        npimgs = [\n",
    "            cv2.cvtColor(load_frame(Video.objects.get(id=video_id), f, []), cv2.COLOR_BGR2RGB)\n",
    "            for f in range(frame_num-self.window_size, frame_num+self.window_size + 1)\n",
    "        ]\n",
    "        img_tensors = [\n",
    "            self.transform(npimg)\n",
    "            for npimg in imgs\n",
    "        ]\n",
    "        \n",
    "        return img_tensors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:07:47.796617Z",
     "start_time": "2019-01-30T19:07:47.759909Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ShotDetectionDataset(shots_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:46:33.152379Z",
     "start_time": "2019-01-30T18:46:33.107682Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:01:14.638644Z",
     "start_time": "2019-01-30T18:00:59.269639Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:08:36.982721Z",
     "start_time": "2019-01-30T19:08:36.931067Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:10:01.921632Z",
     "start_time": "2019-01-30T19:09:28.114952Z"
    }
   },
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    sample, label = sample_batched\n",
    "    print(i_batch, len(sample))\n",
    "    print(sample[0].size())\n",
    "    print(label)\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:54:11.945930Z",
     "start_time": "2019-01-30T18:54:10.426271Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet(sample_batched[0], sample_batched[1], sample_batched[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:54:50.597303Z",
     "start_time": "2019-01-30T18:54:50.553861Z"
    }
   },
   "outputs": [],
   "source": [
    "vnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:56:40.575775Z",
     "start_time": "2019-01-30T18:56:39.106132Z"
    }
   },
   "outputs": [],
   "source": [
    "outs = vnet(sample_batched[0], sample_batched[1], sample_batched[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:56:47.355993Z",
     "start_time": "2019-01-30T18:56:47.312049Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.max(outs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:17:04.058988Z",
     "start_time": "2019-01-30T19:17:04.019402Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(vnet.modules()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
