{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T07:56:42.116477Z",
     "start_time": "2019-01-12T07:55:44.463627Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from esper.rekall import intrvllists_to_result_with_objects, bbox_to_result_object\n",
    "from esper.stdlib import face_landmarks_to_dict\n",
    "def two_faces_up_close():\n",
    "    from query.models import Face\n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.captions import get_all_segments\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.4\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.7\n",
    "    MIN_FACE_ANGLE = 0.2\n",
    "    \n",
    "    def map_payload(func):\n",
    "        def map_fn(intvl):\n",
    "            intvl.payload = func(intvl.payload)\n",
    "            return intvl\n",
    "        return map_fn\n",
    "    \n",
    "    def get_landmarks(faces):\n",
    "        ids = [face['id'] for face in faces]\n",
    "        landmarks = flw.get(Face.objects.filter(id__in=ids))\n",
    "        for face, landmark in zip(faces, landmarks):\n",
    "            face['landmarks'] = landmark\n",
    "        return faces\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(probability__gte=MIN_FACE_CONFIDENCE, frame__video_id__gte=0, frame__video_id__lte=72).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT)\n",
    "\n",
    "    faces = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs,\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'id': 'id'})\n",
    "        ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    graph = {\n",
    "        'nodes': [\n",
    "            { 'name': 'face_left', 'predicates': [] },\n",
    "            { 'name': 'face_right', 'predicates': [] },\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'face_left', 'end':'face_right', 'predicates': [\n",
    "                lambda f1, f2: f1['x2'] < f2['x2'] and f1['x1']<f2['x1'], # Left face on the left\n",
    "                lambda f1, f2: f1['x2'] - f2['x1'] > MIN_FACE_OVERLAP_X, # Faces overlap\n",
    "                lambda f1, f2: min(f1['y2'], f2['y2'])-max(f1['y1'], f1['y1']) > MIN_FACE_OVERLAP_Y,\n",
    "                lambda f1, f2: f1['y2'] > f2['y1'] and f1['y1'] < f2['y2'],  # No face is entirely above another\n",
    "                same_height(MAX_FACE_HEIGHT_DIFF),\n",
    "                lambda f1, f2: (f1['x2']-f2['x1'])/max(f1['x2']-f1['x1'], f2['x2']-f2['x1']) < MAX_FACE_OVERLAP_X_FRACTION\n",
    "            ]},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "    \n",
    "    # Face is profile if both eyes are on the same side of the nose bridge horizontally.\n",
    "    def is_left_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = min(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] >= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] >= nose_x)\n",
    "        return left and right\n",
    "    def is_right_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = max(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] <= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] <= nose_x)\n",
    "        return left and right\n",
    "    \n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    \n",
    "    # Positive if facing right\n",
    "    def signed_face_angle(lm):\n",
    "        center_line_indices = [27,28,32,33,34,51,62,66,57]\n",
    "        data = lm.landmarks[center_line_indices]\n",
    "        fit = np.polyfit(data[:,0], data[:,1], 1)\n",
    "        # y = ax+b\n",
    "        a,b = fit[0], fit[1]\n",
    "        A = project_point_to_line(lm.landmarks[center_line_indices[0]], a,-1,b)\n",
    "        B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a,-1,b)\n",
    "        AB = B-A\n",
    "        AB = AB / np.linalg.norm(AB)\n",
    "        C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "        AC = C-A\n",
    "        AC = AC / np.linalg.norm(AC)\n",
    "        return np.cross(AB, AC)\n",
    "\n",
    "        \n",
    "    graph2 = {\n",
    "        'nodes': [\n",
    "            {'name': 'left', 'predicates': [\n",
    "                lambda f: signed_face_angle(f['landmarks']) > MIN_FACE_ANGLE\n",
    "#                 is_right_profile\n",
    "            ]},\n",
    "            {'name': 'right', 'predicates': [\n",
    "                lambda f: signed_face_angle(f['landmarks']) < -MIN_FACE_ANGLE\n",
    "#                 is_left_profile\n",
    "            ]},\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'left', 'end':'right', 'predicates':[\n",
    "                lambda l, r: mouths_are_close(l['landmarks'], r['landmarks']),\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mf_up_close = faces.filter(payload_satisfies(\n",
    "        scene_graph(graph, exact=True))).map(map_payload(get_landmarks)).filter(\n",
    "        payload_satisfies(scene_graph(graph2, exact=True)))\n",
    "    vids = mf_up_close.get_allintervals().keys()\n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face')\n",
    "    ).all()\n",
    "    total = shots_qs.count()\n",
    "    print(\"Total shots:\", total)\n",
    "    # use emtpy list as payload\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        with_payload=lambda row:[],\n",
    "        progress=True,\n",
    "        total=total\n",
    "    )\n",
    "    kissing_shots = mf_up_close.join(\n",
    "      shots,\n",
    "      lambda kiss, shot: [(kiss.get_start(), shot.get_end(), kiss.get_payload())],\n",
    "      predicate=overlaps(),\n",
    "      working_window=1\n",
    "    ).coalesce()\n",
    "    \n",
    "    # Getting faces in the shot\n",
    "    def wrap_in_list(intvl):\n",
    "        intvl.payload = [intvl.payload]\n",
    "        return intvl\n",
    "    \n",
    "    print(\"Getting faces...\")\n",
    "    faces_qs2 = Face.objects.filter(frame__video_id__in=vids,probability__gte=MIN_FACE_CONFIDENCE)\n",
    "    total = faces_qs2.count()\n",
    "    faces2 = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs2.annotate(\n",
    "            min_frame=F('frame__number'),\n",
    "            max_frame=F('frame__number'),\n",
    "            video_id=F('frame__video_id')\n",
    "        ),\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'frame': 'min_frame'})\n",
    "        ])),\n",
    "        progress=True,\n",
    "        total = total\n",
    "    ).coalesce(payload_merge_op=payload_plus).map(wrap_in_list)\n",
    "    \n",
    "    def clip_to_last_frame_with_two(intvl):\n",
    "        faces = intvl.get_payload()[1]\n",
    "        two_faces = [(f[0], f[1]) for f in faces if len(f)==2]\n",
    "        two_high_faces = [(a, b) for a, b in two_faces if min(a['y2']-a['y1'],b['y2']-b['y1'])>=MIN_FACE_HEIGHT]\n",
    "        frame = [a['frame'] for a,b in two_high_faces]\n",
    "        \n",
    "        if len(frame) > 0:\n",
    "            intvl.end = frame[-1]\n",
    "        return intvl\n",
    "    \n",
    "    clipped_kissing_shots = kissing_shots.merge(\n",
    "        faces2,\n",
    "        payload_merge_op = lambda p1, p2: (p1, p2),\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(payload_merge_op=lambda p1, p2: (p1[0], p1[1]+p2[1])).map(\n",
    "        clip_to_last_frame_with_two).filter_length(min_length=12)\n",
    "    \n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    caption_results = VideoIntervalCollection({\n",
    "        video_id: [(\n",
    "            word[0] * fps_map[video_id], # start frame\n",
    "            word[1] * fps_map[video_id], # end frame\n",
    "            word[2]) # payload is the word\n",
    "            for word in words]\n",
    "        for video_id, words in results\n",
    "    })\n",
    "    kissing_without_words = clipped_kissing_shots.minus(\n",
    "            caption_results)\n",
    "    kissing_final = kissing_without_words.map(\n",
    "            lambda intvl: (int(intvl.start),\n",
    "                int(intvl.end), intvl.payload)\n",
    "            ).coalesce().filter_length(min_length=12)\n",
    "    \n",
    "    return kissing_final\n",
    "\n",
    "def payload_to_objects(p, video_id):\n",
    "    return [face_landmarks_to_dict(face['landmarks']) for face in p[0]] + [\n",
    "                   bbox_to_result_object(face, video_id) for face in p[0]]\n",
    "\n",
    "intervals = two_faces_up_close()\n",
    "esper_widget(intrvllists_to_result_with_objects(intervals.get_allintervals(),\n",
    "                lambda p, video_id: payload_to_objects(p, video_id), stride=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T07:56:57.533356Z",
     "start_time": "2019-01-12T07:56:42.120523Z"
    }
   },
   "outputs": [],
   "source": [
    "# dict from video_id to list of frames that I would consider a kiss\n",
    "ground_truth_dict = dict([\n",
    "    (1, [(11820, 11897)]),\n",
    "    (9, [(54540, 54636)]),\n",
    "    (24, [(97476, 97596), (142176, 142224)]),\n",
    "    (28, [(205020, 205073)]),\n",
    "    (32, [(133080, 133155)]),\n",
    "    (33, [(19128, 19200), (19296, 19440)]),\n",
    "    (43, [(138948, 139026)]),\n",
    "    (47, [(3204,3324), (55824, 55860)]),\n",
    "    (55, [(112776, 113064), (155604, 155669)]),\n",
    "    (59, [(43572, 43680), (93384, 93408), (126672, 126732), (192984, 193056)]),\n",
    "    (62, [(18492, 18516), (18851,18936), (19392, 19447)]),\n",
    "    (65, [(121331,121652)]),\n",
    "    (66, [(171408, 171672)]),\n",
    "    (70, [(140604, 140640)]),\n",
    "    (72, [(115428, 115716), (135436, 135600), (138780,138793)])\n",
    "])\n",
    "\n",
    "from esper.prelude import *\n",
    "from rekall.interval_list import IntervalList, Interval\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "import esper.face_landmarks_wrapper as flw\n",
    "import esper.pose_wrapper as pw\n",
    "from esper.rekall import intrvllists_to_result_with_objects, bbox_to_result_object\n",
    "from rekall.temporal_predicates import overlaps\n",
    "from esper.stdlib import pose_to_dict, face_landmarks_to_dict\n",
    "\n",
    "def find_faces_and_poses(vid, frames):\n",
    "    result = {}\n",
    "    qs = Face.objects.select_related('frame').filter(frame__video_id=vid, frame__number__in=frames)\n",
    "    pqs = PoseMeta.objects.select_related('frame').filter(frame__video_id=vid, frame__number__in=frames)\n",
    "    if qs.count() > 0:\n",
    "        lms = flw.get(qs)\n",
    "        for face, lm in zip(qs, lms):\n",
    "            frame = face.frame.number\n",
    "            if frame not in result:\n",
    "                result[frame] = {}\n",
    "            if 'face' not in result[frame]:\n",
    "                result[frame]['face'] = []\n",
    "            result[frame]['face'].append({\n",
    "                'x1': face.bbox_x1,\n",
    "                'x2': face.bbox_x2,\n",
    "                'y1': face.bbox_y1,\n",
    "                'y2': face.bbox_y2,\n",
    "                'landmarks': lm\n",
    "            })\n",
    "    if pqs.count() > 0:\n",
    "        poses = pw.get(pqs)\n",
    "        for pose, meta in zip(poses, pqs):\n",
    "            frame = meta.frame.number\n",
    "            if frame not in result:\n",
    "                result[frame] = {}\n",
    "            if 'pose' not in result[frame]:\n",
    "                result[frame]['pose'] = []\n",
    "            result[frame]['pose'].append(pose)\n",
    "    for frame in result:\n",
    "        if 'face' not in result[frame]:\n",
    "            result[frame]['face'] = []\n",
    "        if 'pose' not in result[frame]:\n",
    "            result[frame]['pose'] = []\n",
    "    return result\n",
    "\n",
    "def find_all_faces_and_poses(intvl):\n",
    "    vid = intvl.payload\n",
    "    frames = list(range(intvl.start, intvl.end))\n",
    "    intvl.payload = find_faces_and_poses(vid, frames)\n",
    "    return intvl\n",
    "\n",
    "    \n",
    "def add_face_and_pose(intvl):\n",
    "    vid = intvl.payload\n",
    "    intvl.payload = {}\n",
    "    qs = Face.objects.filter(frame__video_id=vid, frame__number=intvl.start)\n",
    "    pqs = PoseMeta.objects.filter(frame__video_id=vid, frame__number=intvl.start)\n",
    "    if qs.count() > 0:\n",
    "        lms = flw.get(qs)\n",
    "        intvl.payload['face'] = [{\n",
    "            'x1': face.bbox_x1,\n",
    "            'x2': face.bbox_x2,\n",
    "            'y1': face.bbox_y1,\n",
    "            'y2': face.bbox_y2,\n",
    "            'landmarks': lm\n",
    "        } for face,lm in zip(qs, lms)]\n",
    "    else:\n",
    "        intvl.payload['face'] = []\n",
    "    if pqs.count() > 0:\n",
    "        intvl.payload['pose'] = pw.get(pqs)        \n",
    "    else:\n",
    "        intvl.payload['pose'] = []\n",
    "    if len(intvl.payload['face']) == 0 and len(intvl.payload['pose'])==0:\n",
    "        intvl.payload=None\n",
    "    return intvl\n",
    "\n",
    "def get_per_frame_ground_truth_shots(lax=6):\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in=ground_truth_dict.keys(),\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face'))\n",
    "\n",
    "    shots = VideoIntervalCollection.from_django_qs(shots_qs, with_payload=lambda row: row.video_id)\n",
    "    ground_truth = VideoIntervalCollection(dict((vid,\n",
    "                    IntervalList([(t[0], t[1], vid) for t in ts])) for vid, ts in ground_truth_dict.items()))\n",
    "    shots = shots.merge(ground_truth, predicate=overlaps(), working_window=1).coalesce().map(find_all_faces_and_poses)\n",
    "    result = {}\n",
    "    for vid, intvls in shots.get_allintervals().items():\n",
    "        frames = [(frame, frame, intvl.payload.get(\n",
    "            frame, {'face':[], 'pose':[]})) for intvl in intvls.intrvls for frame in range(intvl.start-lax, intvl.end+lax+1)\n",
    "                 if frame < intvl.start or frame > intvl.end or frame in intvl.payload]\n",
    "        result[vid] = IntervalList(frames)\n",
    "    return VideoIntervalCollection(result)\n",
    "    \n",
    "    \n",
    "# ground_truth_per_frame = VideoIntervalCollection(dict((vid,\n",
    "#                     IntervalList([(time, time, vid) for t in ts for time in range(\n",
    "#                         t[0], t[1]+1)])) for vid, ts in ground_truth_dict.items())).map(\n",
    "#     add_face_and_pose).filter(lambda intvl: intvl.payload is not None)\n",
    "\n",
    "ground_truth = VideoIntervalCollection(dict((vid,\n",
    "                    IntervalList([(t[0], t[1], vid) for t in ts])) for vid, ts in ground_truth_dict.items()))\n",
    "\n",
    "esper_widget(intrvllists_to_result_with_objects(get_per_frame_ground_truth_shots().get_allintervals(),\n",
    "    payload_to_objs=lambda p,v:[face_landmarks_to_dict(face['landmarks']) for face in p['face']] + [\n",
    "                   bbox_to_result_object(face, v) for face in p['face']] + [\n",
    "                    pose_to_dict(pose) for pose in p['pose']\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T07:56:57.631780Z",
     "start_time": "2019-01-12T07:56:57.537286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns precision, recall, precision_per_item, recall_per_item\n",
    "def compute_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    total_query_time = 0\n",
    "    total_query_segments = 0\n",
    "    total_ground_truth_time = 0\n",
    "    total_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        total_query_time += query_intrvllists[video].coalesce().get_total_time()\n",
    "        total_query_segments += query_intrvllists[video].size()\n",
    "    for video in ground_truth_intrvllists:\n",
    "        total_ground_truth_time += ground_truth_intrvllists[video].coalesce().get_total_time()\n",
    "        total_ground_truth_segments += ground_truth_intrvllists[video].size()\n",
    "        \n",
    "    total_overlap_time = 0\n",
    "    overlapping_query_segments = 0\n",
    "    overlapping_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        if video in ground_truth_intrvllists:\n",
    "            query_list = query_intrvllists[video]\n",
    "            gt_list = ground_truth_intrvllists[video]\n",
    "            \n",
    "            total_overlap_time += query_list.overlaps(gt_list).coalesce().get_total_time()\n",
    "            overlapping_query_segments += query_list.filter_against(gt_list, predicate=overlaps()).size()\n",
    "            overlapping_ground_truth_segments += gt_list.filter_against(query_list, predicate=overlaps()).size()\n",
    "    \n",
    "    if total_query_time == 0:\n",
    "        precision = 1.0\n",
    "        precision_per_item = 1.0\n",
    "    else:\n",
    "        precision = total_overlap_time / total_query_time\n",
    "        precision_per_item = overlapping_query_segments / total_query_segments\n",
    "    \n",
    "    if total_ground_truth_time == 0:\n",
    "        recall = 1.0\n",
    "        recall_per_item = 1.0\n",
    "    else:\n",
    "        recall = total_overlap_time / total_ground_truth_time\n",
    "        recall_per_item = overlapping_ground_truth_segments / total_ground_truth_segments\n",
    "    \n",
    "    return precision, recall, precision_per_item, recall_per_item\n",
    "\n",
    "result = compute_statistics(intervals.get_allintervals(), ground_truth.get_allintervals())\n",
    "print(result, 2/(1/result[0]+1/result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shots with overlapping faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T06:37:31.737691Z",
     "start_time": "2019-01-12T06:35:37.929756Z"
    }
   },
   "outputs": [],
   "source": [
    "# payloads are:\n",
    "# faces: list of {frame_number, list of faces}\n",
    "# poses: list of {frame_number, list of poses}\n",
    "# vid: video_id\n",
    "# overlap: frame numbers with overlapping face ids\n",
    "def shots_with_overlapping_faces():\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.4\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_HEIGHT_DIFF=0.1\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.7\n",
    "    \n",
    "    from rekall.parsers import in_array, merge_dict_parsers, bbox_payload_parser, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_first, payload_plus, merge_named_payload\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    \n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(\n",
    "        frame__regularly_sampled=True,\n",
    "        probability__gte=MIN_FACE_CONFIDENCE, frame__video_id__gte=0, frame__video_id__lte=72\n",
    "    ).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2') - F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')\n",
    "    )\n",
    "\n",
    "    # payload: list of faces\n",
    "    faces = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs.filter(height__gte=MIN_FACE_HEIGHT),\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'id': 'id'})\n",
    "        ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    graph = {\n",
    "        'nodes': [\n",
    "            { 'name': 'face_left', 'predicates': [] },\n",
    "            { 'name': 'face_right', 'predicates': [] },\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'face_left', 'end':'face_right', 'predicates': [\n",
    "                lambda f1, f2: f1['x2'] < f2['x2'] and f1['x1']<f2['x1'], # Left face on the left\n",
    "                lambda f1, f2: f1['x2'] - f2['x1'] > MIN_FACE_OVERLAP_X, # Faces overlap\n",
    "                lambda f1, f2: (f1['x2'] - f2['x1']) / max(f1['x2']-f1['x1'], f2['x2']-f2['x1']) < MAX_FACE_OVERLAP_X_FRACTION,\n",
    "                lambda f1, f2: min(f1['y2'], f2['y2'])-max(f1['y1'], f1['y1']) > MIN_FACE_OVERLAP_Y,\n",
    "                lambda f1, f2: abs(f2['y2']-f2['y1']-f1['y2']+f1['y1']) <= MAX_FACE_HEIGHT_DIFF,\n",
    "                lambda f1, f2: f1['x1'] < 0.5 and f2['x2'] > 0.5, # boxes should not all be on one side of the screen.\n",
    "            ]},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    def get_two_face_ids(intvl):\n",
    "        faces = intvl.payload\n",
    "        assert(len(faces) == 2)\n",
    "        f1, f2 = faces[0], faces[1]\n",
    "        if f1['x2'] >= f2['x2']:\n",
    "            f1, f2 = f2, f1\n",
    "        intvl.payload = (f1['id'], f2['id'], intvl.start)\n",
    "        return intvl\n",
    "    \n",
    "    # payload: list of overlapping face_ids, frame_number tuples\n",
    "    overlapping_faces = faces.filter(payload_satisfies(scene_graph(graph, exact=True))).map(get_two_face_ids)\n",
    "    vids = overlapping_faces.get_allintervals().keys()\n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face')\n",
    "    ).all()\n",
    "    total = shots_qs.count()\n",
    "    print(\"Total shots:\", total)\n",
    "    # payload: vid\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        with_payload=lambda row:row.video_id,\n",
    "        progress=True,\n",
    "        total=total\n",
    "    )\n",
    "    \n",
    "    # Get shots with overlapping faces\n",
    "    # payload: vid and overlap\n",
    "    overlapped_shots = overlapping_faces.merge(\n",
    "      shots,\n",
    "      payload_merge_op = lambda face_id_and_frame, vid: {\n",
    "          'vid': vid,\n",
    "          'overlap': [face_id_and_frame]\n",
    "      },\n",
    "      predicate=overlaps(),\n",
    "      working_window=1\n",
    "    ).coalesce(payload_merge_op=merge_named_payload({\n",
    "        'vid': payload_first,\n",
    "        'overlap': payload_plus,\n",
    "    }))\n",
    "    \n",
    "    # Get all faces\n",
    "    print(\"Adding all faces\")\n",
    "    def add_frame_number(intvl):\n",
    "        faces = intvl.payload\n",
    "        intvl.payload = {\n",
    "            \"frame\": intvl.start,\n",
    "            \"faces\": faces\n",
    "        }\n",
    "        return intvl\n",
    "    # payload: frame, list of faces\n",
    "    faces = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs.filter(frame__video_id__in=vids),\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'id': 'id'})\n",
    "        ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus).map(add_frame_number)\n",
    "    \n",
    "    # payload: vid, overlap, faces: list of \"frame number and faces\", poses: []\n",
    "    overlapped_shots_with_faces = overlapped_shots.merge(\n",
    "        faces,\n",
    "        payload_merge_op = lambda vid_and_overlap, frame_and_faces: {\n",
    "            'vid': vid_and_overlap['vid'],\n",
    "            'overlap': vid_and_overlap['overlap'],\n",
    "            'faces': [frame_and_faces],\n",
    "            'poses': [],\n",
    "        },\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(payload_merge_op=merge_named_payload({\n",
    "        'vid': payload_first,\n",
    "        'overlap': payload_first,\n",
    "        'faces': payload_plus,\n",
    "        'poses': payload_plus\n",
    "    }))\n",
    "    \n",
    "    print(\"Adding poses\")\n",
    "    poses_qs = PoseMeta.objects.filter(\n",
    "        frame__regularly_sampled=True,\n",
    "        frame__video_id__in=vids).annotate(\n",
    "        min_frame=F(\"frame__number\"),\n",
    "        max_frame=F('frame__number'),\n",
    "        video_id=F('frame__video_id'))\n",
    "    def add_frame_number_for_pose(intvl):\n",
    "        poses = intvl.payload\n",
    "        intvl.payload = {\n",
    "            \"frame\": intvl.start,\n",
    "            \"poses\": poses\n",
    "        }\n",
    "        return intvl\n",
    "    # payload: frame, list of poses\n",
    "    poses = VideoIntervalCollection.from_django_qs(\n",
    "        poses_qs,\n",
    "        with_payload=lambda row: [row]\n",
    "    ).coalesce(payload_merge_op=payload_plus).map(add_frame_number_for_pose)\n",
    "    \n",
    "    def merge_poses_into_dict(d, poses):\n",
    "        ret = d.copy()\n",
    "        ret['poses'] = [poses]\n",
    "        return ret\n",
    "    # payload: vid, overlap, frames: list of \"frame number and faces and poses\"\n",
    "    overlapped_shots_with_faces_and_poses = overlapped_shots_with_faces.merge(\n",
    "        poses,\n",
    "        payload_merge_op = merge_poses_into_dict,\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(payload_merge_op=merge_named_payload({\n",
    "        'vid': payload_first,\n",
    "        'overlap': payload_first,\n",
    "        'faces': payload_first,\n",
    "        'poses': payload_plus\n",
    "    })).set_union(overlapped_shots_with_faces).coalesce(payload_merge_op=merge_named_payload({\n",
    "        'vid': payload_first,\n",
    "        'overlap': payload_first,\n",
    "        'faces': payload_first,\n",
    "        'poses': lambda p1, p2: p1 if len(p1)>len(p2) else p2\n",
    "    }))\n",
    "\n",
    "    \n",
    "    return overlapped_shots_with_faces_and_poses\n",
    "\n",
    "def payload_to_objs_for_shots_with_overlapping_faces(payload, vid):\n",
    "    ret = []\n",
    "    _, _, frame = payload['overlap'][0]\n",
    "    for f in payload['faces']:\n",
    "        if f['frame'] == frame:\n",
    "            ret += [bbox_to_result_object(face,vid) for face in f['faces']]\n",
    "    return ret\n",
    "\n",
    "# esper_widget(intrvllists_to_result_with_objects(shots_with_overlapping_faces().get_allintervals(),\n",
    "#                     payload_to_objs_for_shots_with_overlapping_faces),\n",
    "#              show_middle_frame=False, disable_captions=True)\n",
    "collection = shots_with_overlapping_faces()\n",
    "result = compute_statistics(collection.get_allintervals(), ground_truth.get_allintervals())\n",
    "print(result, 2/(1/result[0]+1/result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T06:37:58.578033Z",
     "start_time": "2019-01-12T06:37:57.565970Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_non_recalled(collection):\n",
    "    return esper_widget(intrvllists_to_result_with_objects(ground_truth.minus(collection).get_allintervals(),\n",
    "                                               lambda p,v:[]), show_middle_frame=False, disable_captions=True)\n",
    "display_non_recalled(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T00:40:49.471411Z",
     "start_time": "2019-01-12T00:40:49.443392Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_vid(collection, vid):\n",
    "    return esper_widget(intrvllists_to_result_with_objects({vid: collection.get_intervallist(vid)},\n",
    "                                               lambda p,v:[]), show_middle_frame=False, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shots with overlapping faces and opposing faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T06:38:26.199376Z",
     "start_time": "2019-01-12T06:38:13.997691Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_collection_with_opposing_faces(collection):\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    import esper.pose_wrapper as pw\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    \n",
    "    MIN_FACE_ANGLE = 0.2\n",
    "    MIN_FACE_HEIGHT = 0.3\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_DIST_X = 0\n",
    "\n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    \n",
    "    # Returns (a,b,c) which defines ax+by+c=0\n",
    "    def find_best_line_fit(xs, ys):\n",
    "        fit1 = np.polyfit(xs, ys, 1)\n",
    "        error1 = np.sum((np.poly1d(fit1)(xs)-ys)**2)\n",
    "        fit2 = np.polyfit(ys, xs, 1)\n",
    "        error2 = np.sum((np.poly1d(fit2)(ys)-xs)**2)\n",
    "        if error1 < error2:\n",
    "            # fit1[0]x+fit1[1]=y\n",
    "            return fit1[0], -1, fit1[1]\n",
    "        # fit2[0]y+fit2[1]=x\n",
    "        return -1, fit2[0], fit2[1]\n",
    "    \n",
    "    # Positive if facing left\n",
    "    def signed_face_angle(lm):\n",
    "        center_line_indices = [27,28, 32, 33,34, 51,62,66,57]\n",
    "        data = lm.landmarks[center_line_indices]\n",
    "        a, b, c = find_best_line_fit(data[:,0], data[:,1])\n",
    "        A = project_point_to_line(lm.landmarks[center_line_indices[0]], a, b, c)\n",
    "        B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a, b, c)\n",
    "        AB = B-A\n",
    "        AB = AB / np.linalg.norm(AB)\n",
    "        C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "        AC = C-A\n",
    "        AC = AC / np.linalg.norm(AC)\n",
    "        return np.cross(AB, AC)\n",
    "    \n",
    "    def map_payload(func):\n",
    "        def fn(intvl):\n",
    "            intvl.payload = func(intvl.payload)\n",
    "            return intvl\n",
    "        return fn        \n",
    "    \n",
    "    # face_pair: a list of (left_face, right_face, frame).\n",
    "    # opposing_face_frames: a list of frames\n",
    "    def add_face_pairs_to_payload(p):\n",
    "        # return left_face, right_face\n",
    "        def get_face_pair(fs):\n",
    "            def height(f):\n",
    "                return f['y2']-f['y1']\n",
    "            fs = [f for f in fs if height(f) > MIN_FACE_HEIGHT]\n",
    "            if len(fs) != 2:\n",
    "                return None, None\n",
    "            f1, f2 = fs[0], fs[1]\n",
    "            if f2['x2']<f1['x2'] and f2['x1'] < f1['x1']:\n",
    "                f1, f2 = f2, f1\n",
    "            if f1['x2']<f2['x2'] and f1['x1']<f2['x1'] and min(\n",
    "                f1['y2'],f2['y2'])-max(f1['y1'],f2['y1']) > MIN_FACE_OVERLAP_Y and (\n",
    "                f2['x1']-f1['x2']<MAX_FACE_DIST_X):\n",
    "                return f1, f2\n",
    "            return None, None\n",
    "                   \n",
    "        faces = p['faces']\n",
    "        p['face_pairs'] = []\n",
    "        p['opposing_face_frames'] = []\n",
    "        overlapped_frames = dict((val[2], (val[0], val[1])) for val in p['overlap'])\n",
    "        fids = []\n",
    "        for frame_and_faces in faces:\n",
    "            frame = frame_and_faces['frame']\n",
    "            if frame in overlapped_frames:\n",
    "                ids = overlapped_frames[frame]\n",
    "                fs = [face for face in frame_and_faces['faces'] if face['id'] in ids]\n",
    "            else:\n",
    "                fs = frame_and_faces['faces']\n",
    "            left, right = get_face_pair(fs)\n",
    "            if left is not None and right is not None:\n",
    "                p['face_pairs'].append((left, right, frame))\n",
    "                fids += [left['id'], right['id']]\n",
    "        landmarks = flw.get_from_face_ids(fids)\n",
    "        index = 0\n",
    "        for left, right, frame in p['face_pairs']:\n",
    "            left['landmarks'] = landmarks[index]\n",
    "            right['landmarks'] = landmarks[index+1]\n",
    "            if signed_face_angle(left['landmarks'])  < -MIN_FACE_ANGLE and (\n",
    "               signed_face_angle(right['landmarks']) > MIN_FACE_ANGLE):\n",
    "                p['opposing_face_frames'].append(frame)\n",
    "            index += 2\n",
    "       \n",
    "        return p\n",
    "    \n",
    "    def oppose_pose(p1, p2):\n",
    "        # First use shoulder vectors\n",
    "        # if shoulder vectors are opposite, then they are opposing\n",
    "        from esper.pose_wrapper import PoseWrapper\n",
    "        def get_vector(pts, l, r):\n",
    "            if np.all(pts[[l,r],2]>0):\n",
    "                return pts[r, :2] - pts[l, :2]\n",
    "            return None\n",
    "        pts1 = p1.pose_keypoints()\n",
    "        pts2 = p2.pose_keypoints()\n",
    "        l, r = PoseWrapper.LShoulder, PoseWrapper.RShoulder\n",
    "        v1 = get_vector(pts1, l, r)\n",
    "        v2 = get_vector(pts2, l, r)\n",
    "        if v1 is not None and v2 is not None and np.dot(v1, v2) < 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # pose_pairs: list of (pose1, pose2, frame)\n",
    "    # opposing_pose_frames: list of frames\n",
    "    def add_pose_pairs_to_payload(p):\n",
    "        poses = p['poses']\n",
    "        pids = []\n",
    "        pose_frames = []\n",
    "        p['opposing_pose_frames'] = []\n",
    "        for frame_and_poses in poses:\n",
    "            frame = frame_and_poses['frame']\n",
    "            ps = frame_and_poses['poses']\n",
    "            if len(ps) == 2:\n",
    "                pose_frames.append(frame)\n",
    "                pids += [ps[0], ps[1]]\n",
    "        pws = pw.get(pids)\n",
    "        index = 0\n",
    "        p['pose_pairs'] = []\n",
    "        for frame in pose_frames:\n",
    "            p['pose_pairs'].append((pws[index], pws[index+1], frame))\n",
    "            if oppose_pose(pws[index], pws[index+1]):\n",
    "                p['opposing_pose_frames'].append(frame)\n",
    "            index += 2\n",
    "        return p      \n",
    "    \n",
    "    def has_opposing_face(p):\n",
    "        return len(p['opposing_face_frames']) > 0\n",
    "    \n",
    "    def has_opposing_pose(p):\n",
    "        return len(p['opposing_pose_frames'])>0\n",
    "    \n",
    "    # payload: vid, overlap, faces, poses, face_pairs\n",
    "    return collection.map(map_payload(add_face_pairs_to_payload)).map(\n",
    "        map_payload(add_pose_pairs_to_payload)).filter(payload_satisfies(\n",
    "        lambda p: has_opposing_face(p) or has_opposing_pose(p)))\n",
    "\n",
    "collection_with_opposing_faces = filter_collection_with_opposing_faces(collection)\n",
    "result = compute_statistics(collection_with_opposing_faces.get_allintervals(), ground_truth.get_allintervals())\n",
    "print(result, 2/(1/result[0]+1/result[1]))              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T21:36:47.315153Z",
     "start_time": "2019-01-11T21:36:46.392570Z"
    }
   },
   "outputs": [],
   "source": [
    "display_non_recalled(collection_with_opposing_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T21:37:06.878926Z",
     "start_time": "2019-01-11T21:37:04.513265Z"
    }
   },
   "outputs": [],
   "source": [
    "def payload_to_opposing_landmarks_objs(p, v):\n",
    "    from esper.stdlib import face_landmarks_to_dict\n",
    "    from esper.rekall import bbox_to_result_object\n",
    "    if len(p['opposing_face_frames']) == 0:\n",
    "        return []\n",
    "    f = p['opposing_face_frames'][0]\n",
    "    objs = []\n",
    "    for left, right, frame in p['face_pairs']:\n",
    "        if f == frame:\n",
    "            objs += [face_landmarks_to_dict(left['landmarks']), face_landmarks_to_dict(right['landmarks'])]\n",
    "            objs += [bbox_to_result_object(left, p['vid']), bbox_to_result_object(right, p['vid'])]\n",
    "    return objs\n",
    "\n",
    "def payload_to_overlapping_face_objs(p, v):\n",
    "    def add_color(o):\n",
    "        o['gender_id'] = 1\n",
    "        return o\n",
    "    \n",
    "    i1, i2, frame = p['overlap'][0]\n",
    "    objs = []\n",
    "    for faces in p['faces']:\n",
    "        if faces['frame'] == frame:\n",
    "            for f in faces['faces']:\n",
    "                if f['id'] in [i1, i2]:\n",
    "                    objs.append(add_color(bbox_to_result_object(f, v)))\n",
    "    return objs\n",
    "\n",
    "def payload_to_opposing_pose_objs(p,v):\n",
    "    from esper.stdlib import pose_to_dict\n",
    "    if len(p['opposing_pose_frames']) == 0:\n",
    "        return []\n",
    "    f = p['opposing_pose_frames'][0]\n",
    "    objs = []\n",
    "    for p1, p2, frame in p['pose_pairs']:\n",
    "        if f == frame:\n",
    "            objs += [pose_to_dict(p1), pose_to_dict(p2)]\n",
    "    return objs\n",
    "\n",
    "def payload_to_objects_for_collection_with_opposing_people(p,v):\n",
    "    return payload_to_opposing_landmarks_objs(p,v)+payload_to_opposing_pose_objs(p,v)+payload_to_overlapping_face_objs(p,v)\n",
    "\n",
    "esper_widget(intrvllists_to_result_with_objects(collection_with_opposing_faces.get_allintervals(),\n",
    "        payload_to_objects_for_collection_with_opposing_people), show_middle_frame=False, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shots with opposing people close to overlapped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T03:58:31.099893Z",
     "start_time": "2019-01-12T03:58:30.792587Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_collection_with_people_close_to_overlap(collection):\n",
    "    MAX_FRAME_DIFF = 12\n",
    "    MAX_FACE_DIST = 0.05\n",
    "    MAX_FACE_SHOULDER_DEV = 0.4\n",
    "    \n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    # payload: overlap, faces, poses, vid, face_pairs, pose_pairs, opposing_face_frames, opposing_pose_frames\n",
    "    \n",
    "    def get_bbox_corners(box):\n",
    "        return np.array([\n",
    "            [box['x1'],box['y1']],\n",
    "            [box['x1'],box['y2']],\n",
    "            [box['x2'],box['y2']],\n",
    "            [box['x2'],box['y1']],\n",
    "        ])\n",
    "    def get_bbox_center(box):\n",
    "        return np.array([(box['x1']+box['x2'])/2, (box['y1']+box['y2'])/2])\n",
    "    def get_neck(p):\n",
    "        pts = p.pose_keypoints()\n",
    "        if pts[p.NECK,2]>0:\n",
    "            return pts[p.NECK, :2]\n",
    "        if pts[p.LShoulder, 2] == 0 or pts[p.RShoulder, 2] ==0:\n",
    "            return None\n",
    "        return np.mean(pts[[p.LShoulder, p.RShoulder],:2], axis=0)\n",
    "    def check_face_dist(f1, f2, f3, f4):\n",
    "        d13 = np.linalg.norm(get_bbox_center(f1)-get_bbox_center(f3))\n",
    "        d23 = np.linalg.norm(get_bbox_center(f2)-get_bbox_center(f3))\n",
    "        d14 = np.linalg.norm(get_bbox_center(f1)-get_bbox_center(f4))\n",
    "        d24 = np.linalg.norm(get_bbox_center(f2)-get_bbox_center(f4))\n",
    "        return (d13 <= MAX_FACE_DIST and d24 <= MAX_FACE_DIST) or (\n",
    "                d14 <= MAX_FACE_DIST and d23 <= MAX_FACE_DIST)\n",
    "    \n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    # line parameterized by ax+by+c=0\n",
    "    def get_line(p1, p2):\n",
    "        if p1[0]==p2[0]:\n",
    "            return (1, 0, -p1[0])\n",
    "        return p2[1]-p1[1], p1[0]-p2[0], p1[1]*(p2[0]-p1[0])+p1[0]*(p1[1]-p2[1])\n",
    "    \n",
    "    def get_face_projection_dist_on_shoulder(f, p):\n",
    "        cf = get_bbox_center(f)\n",
    "        pts = p.pose_keypoints()\n",
    "        a,b,c = get_line(pts[p.LShoulder,:2], pts[p.RShoulder,:2])\n",
    "        proj = project_point_to_line(cf, a,b,c)\n",
    "        mid = np.mean(pts[[p.LShoulder, p.RShoulder],:2], axis=0)\n",
    "        return np.linalg.norm(proj-mid)/np.linalg.norm(pts[p.RShoulder,:2]-mid)\n",
    "        \n",
    "    def check_face_pose_dist(f1, f2, p3, p4):\n",
    "        d13 = get_face_projection_dist_on_shoulder(f1, p3)\n",
    "        d14 = get_face_projection_dist_on_shoulder(f1, p4)\n",
    "        d23 = get_face_projection_dist_on_shoulder(f2, p3)\n",
    "        d24 = get_face_projection_dist_on_shoulder(f2, p4)\n",
    "        return (d13 <= MAX_FACE_SHOULDER_DEV and d24 <= MAX_FACE_SHOULDER_DEV) or (\n",
    "                d14 <= MAX_FACE_SHOULDER_DEV and d23 <= MAX_FACE_SHOULDER_DEV)\n",
    "    # add payload 'close_face_frame_pair', 'close_face_pose_frame_pair'\n",
    "    def compute_close_to_overlap(intvl):\n",
    "        p = intvl.payload\n",
    "        def find_face(faces,i, frame):\n",
    "            face_list = [fs for fs in faces if fs['frame']==frame][0]['faces']\n",
    "            return [f for f in face_list if f['id']==i][0]\n",
    "        def find_pair(pairs, frame):\n",
    "            return [(left, right) for left, right, f in pairs if f==frame][0]\n",
    "        \n",
    "        p['close_face_frame_pair'] = []\n",
    "        for f in p['opposing_face_frames']:\n",
    "            for fid1, fid2, f2 in p['overlap']:\n",
    "                if abs(f-f2)<=MAX_FRAME_DIFF:\n",
    "                    overlapped1 = find_face(p['faces'], fid1, f2)\n",
    "                    overlapped2 = find_face(p['faces'], fid2, f2)\n",
    "                    face1, face2 = find_pair(p['face_pairs'], f)\n",
    "                    if check_face_dist(overlapped1, overlapped2, face1, face2):\n",
    "                        p['close_face_frame_pair'].append((f2, f))\n",
    "                        \n",
    "        p['close_face_pose_frame_pair'] = []\n",
    "        for f in p['opposing_pose_frames']:\n",
    "            for fid1, fid2, f2 in p['overlap']:\n",
    "                if abs(f-f2)<=MAX_FRAME_DIFF:\n",
    "                    overlapped1 = find_face(p['faces'], fid1, f2)\n",
    "                    overlapped2 = find_face(p['faces'], fid2, f2)\n",
    "                    pose1, pose2 = find_pair(p['pose_pairs'], f)\n",
    "                    if check_face_pose_dist(overlapped1, overlapped2, pose1, pose2):\n",
    "                        p['close_face_pose_frame_pair'].append((f2, f))\n",
    "        return intvl\n",
    "    \n",
    "#     def remove_overlap_pairs_under_height(intvl):\n",
    "#         def find_face(faces,i, frame):\n",
    "#             face_list = [fs for fs in faces if fs['frame']==frame][0]['faces']\n",
    "#             return [f for f in face_list if f['id']==i][0]     \n",
    "#         def height(f):\n",
    "#             return f['y2']-f['y1']\n",
    "        \n",
    "#         p = intvl.payload.copy()\n",
    "#         os = p['overlap']\n",
    "        \n",
    "#         os = [v for v in os if abs(\n",
    "#             height(find_face(p['faces'], v[0], v[2])) - height(\n",
    "#                 find_face(p['faces'], v[1],v[2]))) <= MAX_FACE_HEIGHT_DIFF]\n",
    "#         p['overlap'] = os\n",
    "#         return (intvl.start, intvl.end, p)  \n",
    "        \n",
    "    animation_vids = [v.id for v in Video.objects.filter(genres__name='animation')]\n",
    "    return collection.map(compute_close_to_overlap).filter(payload_satisfies(\n",
    "        lambda p: len(p['close_face_frame_pair']) > 0 or len(p['close_face_pose_frame_pair']) > 0)).filter_length(\n",
    "        min_length=24).filter(payload_satisfies(\n",
    "        lambda p: p['vid'] not in animation_vids))\n",
    "collection_with_opposing_faces_close_to_overlap = filter_collection_with_people_close_to_overlap(\n",
    "    collection_with_opposing_faces)\n",
    "result = compute_statistics(\n",
    "    collection_with_opposing_faces_close_to_overlap.get_allintervals(), ground_truth.get_allintervals())\n",
    "print(result, 2/(1/result[0]+1/result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T02:37:11.267488Z",
     "start_time": "2019-01-12T02:37:10.228679Z"
    }
   },
   "outputs": [],
   "source": [
    "display_non_recalled(collection_with_opposing_faces_close_to_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T04:04:36.417206Z",
     "start_time": "2019-01-12T04:04:35.281545Z"
    }
   },
   "outputs": [],
   "source": [
    "def payload_to_objects_for_collection_with_opposing_faces_close_to_overlap(p,v):\n",
    "    def frame_to_face_objs(p, f):\n",
    "        objs = []\n",
    "        for left, right, frame in p['face_pairs']:\n",
    "            if f == frame:\n",
    "                objs += [face_landmarks_to_dict(left['landmarks']), face_landmarks_to_dict(right['landmarks'])]\n",
    "                objs += [bbox_to_result_object(left, p['vid']), bbox_to_result_object(right, p['vid'])]\n",
    "      \n",
    "        return objs\n",
    "    def frame_to_pose_objs(p, f):\n",
    "        objs = []\n",
    "        for p1, p2, frame in p['pose_pairs']:\n",
    "            if f == frame:\n",
    "                objs += [pose_to_dict(p1), pose_to_dict(p2)]\n",
    "        return objs\n",
    "        \n",
    "    def frame_to_overlap_face(p, frame):\n",
    "        def add_color(o):\n",
    "            o['gender_id'] = 1\n",
    "            return o\n",
    "        i1, i2 = [(i1, i2) for i1, i2, f in p['overlap'] if f==frame][0]\n",
    "        objs = []\n",
    "        for faces in p['faces']:\n",
    "            if faces['frame'] == frame:\n",
    "                for f in faces['faces']:\n",
    "                    if f['id'] in [i1, i2]:\n",
    "                        objs.append(add_color(bbox_to_result_object(f, v)))\n",
    "        return objs\n",
    "    \n",
    "    objs = []\n",
    "    if len(p['close_face_frame_pair'])>0:\n",
    "        overlap_frame, landmark_frame = p['close_face_frame_pair'][0]\n",
    "        objs += frame_to_face_objs(p, landmark_frame)\n",
    "        objs += frame_to_overlap_face(p,overlap_frame)\n",
    "        return objs\n",
    "\n",
    "    if len(p['close_face_pose_frame_pair'])>0:\n",
    "        overlap_frame, pose_frame = p['close_face_pose_frame_pair'][0]\n",
    "        objs += frame_to_pose_objs(p, pose_frame)\n",
    "        objs += frame_to_overlap_face(p, overlap_frame)\n",
    "\n",
    "    return objs\n",
    "\n",
    "esper_widget(intrvllists_to_result_with_objects(collection_with_opposing_faces_close_to_overlap.get_allintervals(),\n",
    "        payload_to_objects_for_collection_with_opposing_faces_close_to_overlap), show_middle_frame=False, disable_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T05:49:08.155562Z",
     "start_time": "2019-01-11T05:49:07.192017Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(collection.filter(lambda intvl: intvl.start==132855).get_allintervals(), lambda p,v:[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T05:21:33.495420Z",
     "start_time": "2019-01-11T05:21:32.613203Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects({65:collection.get_intervallist(65)}, lambda p,v:[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T05:50:44.229111Z",
     "start_time": "2019-01-11T05:50:44.196739Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.get_intervallist(1).intrvls[0].payload['overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:13:41.528731Z",
     "start_time": "2019-01-04T23:13:41.486742Z"
    }
   },
   "outputs": [],
   "source": [
    "faces = Face.objects.filter(probability__gte=0.8, frame__video_id=404, frame__number=10452).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id'),\n",
    "        face_probability=F('probability')).filter(height__gte=0.5)\n",
    "faces[1].labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T00:21:40.664648Z",
     "start_time": "2019-01-05T00:21:35.299142Z"
    }
   },
   "outputs": [],
   "source": [
    "Face.objects.select_related('frame').distinct('frame').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T15:49:18.587880Z",
     "start_time": "2019-01-08T15:49:18.378242Z"
    }
   },
   "outputs": [],
   "source": [
    "Face.objects.filter(frame__number=74952, frame__video__id=245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T15:49:48.977285Z",
     "start_time": "2019-01-08T15:49:48.948986Z"
    }
   },
   "outputs": [],
   "source": [
    "import esper.face_landmarks_wrapper as flw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:29:18.261622Z",
     "start_time": "2019-01-08T22:29:18.206186Z"
    }
   },
   "outputs": [],
   "source": [
    "v=flw.get(Face.objects.filter(frame__number=149532, frame__video__id=156))\n",
    "ls=[]\n",
    "for l in v:\n",
    "    ls.append(l)\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:29:20.195552Z",
     "start_time": "2019-01-08T22:29:20.163549Z"
    }
   },
   "outputs": [],
   "source": [
    "ls[0].left_eye(), ls[0].right_eye(), ls[0].nose_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:29:23.256583Z",
     "start_time": "2019-01-08T22:29:23.222667Z"
    }
   },
   "outputs": [],
   "source": [
    "ls[1].left_eye(), ls[1].right_eye(), ls[1].nose_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:30:29.890048Z",
     "start_time": "2019-01-08T22:30:29.857239Z"
    }
   },
   "outputs": [],
   "source": [
    "ls[1].left_eyebrow(), ls[1].right_eyebrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T07:59:33.810778Z",
     "start_time": "2019-01-09T07:59:33.588020Z"
    }
   },
   "outputs": [],
   "source": [
    "for vid, l in intervals.get_allintervals().items():\n",
    "    print(vid, len(l.intrvls))\n",
    "    for l_ in l.intrvls:\n",
    "        print(l_.start, l_.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:35:39.316553Z",
     "start_time": "2019-01-09T17:35:39.288232Z"
    }
   },
   "outputs": [],
   "source": [
    "faces= intervals.get_intervallist(1).intrvls[0].payload[1]\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:29:45.625618Z",
     "start_time": "2019-01-09T18:29:45.599652Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1=intervals.get_intervallist(32).intrvls[1].payload[0][0]['landmarks']\n",
    "lm2=intervals.get_intervallist(32).intrvls[1].payload[0][1]['landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:29:50.731728Z",
     "start_time": "2019-01-09T18:29:50.702707Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1.nose_bridge(), lm2.nose_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:30:52.928307Z",
     "start_time": "2019-01-09T18:30:52.896288Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1.left_eyebrow(), lm1.right_eyebrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:31:04.410036Z",
     "start_time": "2019-01-09T18:31:04.381919Z"
    }
   },
   "outputs": [],
   "source": [
    "lm2.left_eyebrow(), lm2.right_eyebrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:35:09.260333Z",
     "start_time": "2019-01-09T18:35:09.233240Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T18:40:28.768872Z",
     "start_time": "2019-01-09T18:40:28.477149Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lm2.left_eyebrow()[:,0], lm2.left_eyebrow()[:,1], label=\"lm2 left eyebrow\")\n",
    "plt.plot(lm2.right_eyebrow()[:,0], lm2.right_eyebrow()[:,1], label=\"lm2 right eyebrow\")\n",
    "plt.plot(lm2.right_eye()[:,0], lm2.right_eye()[:,1], label=\"lm2 right eye\")\n",
    "plt.plot(lm2.left_eye()[:,0], lm2.left_eye()[:,1], label=\"lm2 left eye\")\n",
    "plt.plot(lm1.left_eyebrow()[:,0], lm1.left_eyebrow()[:,1], label=\"lm1 left eyebrow\")\n",
    "plt.plot(lm1.right_eyebrow()[:,0], lm1.right_eyebrow()[:,1], label=\"lm1 right eyebrow\")\n",
    "plt.plot(lm1.right_eye()[:,0], lm1.right_eye()[:,1], label=\"lm1 right eye\")\n",
    "plt.plot(lm1.left_eye()[:,0], lm1.left_eye()[:,1], label=\"lm1 left eye\")\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:54:32.097324Z",
     "start_time": "2019-01-10T00:54:32.058347Z"
    }
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for ints in kissing_final.get_allintervals().values():\n",
    "    for i in ints.intrvls:\n",
    "        sum += i.end-i.start\n",
    "sum/24/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:02:05.714540Z",
     "start_time": "2019-01-09T22:02:04.585289Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(intervals.filter_length(min_length=240),\n",
    "                lambda p, video_id:  [face_landmarks_to_dict(face['landmarks']) for face in p[0]] + [\n",
    "                   bbox_to_result_object(face, video_id) for face in p[0]], stride=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:12:57.275058Z",
     "start_time": "2019-01-09T22:12:57.228642Z"
    }
   },
   "outputs": [],
   "source": [
    "intervals.filter_length(min_length=240).get_intervallist(118).intrvls[0].payload[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:35:42.059992Z",
     "start_time": "2019-01-10T01:35:42.027388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line is ax+by+c=0\n",
    "def project_point_to_line(pt, a, b, c):\n",
    "    x0,y0=pt\n",
    "    d=a*a+b*b\n",
    "    x=(b*(b*x0-a*y0)-a*c)/d\n",
    "    y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:35:37.373886Z",
     "start_time": "2019-01-10T01:35:37.288347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Positive if facing right\n",
    "def signed_face_angle(f):\n",
    "    lm = f['landmarks']\n",
    "    center_line_indices = [27,28,32,33,34,51,62,66,57]\n",
    "    data = lm.landmarks[center_line_indices]\n",
    "    fit = np.polyfit(data[:,0], data[:1], 1)\n",
    "    # y = ax+b\n",
    "    a,b = fit[0], fit[1]\n",
    "    A = project_point_to_line(lm.landmarks[center_line_indices[0]], a,-1,b)\n",
    "    B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a,-1,b)\n",
    "    AB = B-A\n",
    "    AB = AB / np.linalg.norm(AB)\n",
    "    C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "    AC = C-A\n",
    "    AC = AC / np.linalg.norm(AC)\n",
    "    return np.cross(AB, AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:49:14.381532Z",
     "start_time": "2019-01-10T00:49:03.776187Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Removing dialogs\")\n",
    "from esper.captions import get_all_segments\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "vids = list(intervals.get_allintervals().keys())\n",
    "print(len(vids))\n",
    "results = get_all_segments(vids)\n",
    "fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "caption_results = VideoIntervalCollection({\n",
    "    video_id: [(\n",
    "        word[0] * fps_map[video_id], # start frame\n",
    "        word[1] * fps_map[video_id], # end frame\n",
    "        word[2][0]) # payload is the word (string)\n",
    "        for word in words]\n",
    "    for video_id, words in results\n",
    "})\n",
    "kissing_without_words = intervals.minus(caption_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:52:54.111891Z",
     "start_time": "2019-01-10T00:52:54.065004Z"
    }
   },
   "outputs": [],
   "source": [
    "kissing_final = kissing_without_words.map(lambda intvl: (int(intvl.start), int(intvl.end), intvl.payload)).coalesce().filter_length(min_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:52:58.691761Z",
     "start_time": "2019-01-10T00:52:56.786460Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result_with_objects(kissing_final.get_allintervals(),\n",
    "                lambda p, video_id:  [face_landmarks_to_dict(face['landmarks']) for face in p[0]] + [\n",
    "                   bbox_to_result_object(face, video_id) for face in p[0]], stride=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:19:12.436518Z",
     "start_time": "2019-01-10T01:19:12.359388Z"
    }
   },
   "outputs": [],
   "source": [
    "kissing_final.get_intervallist(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:42:06.895382Z",
     "start_time": "2019-01-09T22:42:06.859106Z"
    }
   },
   "outputs": [],
   "source": [
    "vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:04:58.340626Z",
     "start_time": "2019-01-10T00:04:58.309379Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.captions import INDEX, LEXICON, DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:09:34.989589Z",
     "start_time": "2019-01-10T00:09:33.364088Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for w in INDEX.tokens(244):\n",
    "    try:\n",
    "        t = LEXICON[w].token\n",
    "        print(t)\n",
    "    except:\n",
    "        print(\"ERROR!\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:07:04.024226Z",
     "start_time": "2019-01-09T23:07:03.984950Z"
    }
   },
   "outputs": [],
   "source": [
    "Video.objects.get(id=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:07:30.186369Z",
     "start_time": "2019-01-09T23:07:30.153592Z"
    }
   },
   "outputs": [],
   "source": [
    "DOCUMENTS[86].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:11:03.911221Z",
     "start_time": "2019-01-09T23:11:03.874622Z"
    }
   },
   "outputs": [],
   "source": [
    "np.log(16777215+1)/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:26:16.180662Z",
     "start_time": "2019-01-09T23:26:16.142040Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_srt(doc_path: str):\n",
    "    import pysrt\n",
    "    try:\n",
    "        subs = pysrt.open(doc_path)\n",
    "    except:\n",
    "        try:\n",
    "            subs = pysrt.open(doc_path, encoding='iso-8859-1')\n",
    "        except:\n",
    "            raise Exception('Cannot parse {}'.format(doc_path))\n",
    "    return subs\n",
    "\n",
    "\n",
    "def get_doc_words(doc_path: str):\n",
    "    from collections import Counter\n",
    "    words = Counter()\n",
    "    try:\n",
    "        subs = load_srt(doc_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return words\n",
    "\n",
    "    for s in subs:\n",
    "        tokens = TOKENIZER.tokens(s.text)\n",
    "        words.update(t for t in tokens if len(t) <= MAX_WORD_LEN)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:26:32.197035Z",
     "start_time": "2019-01-09T23:26:32.160363Z"
    }
   },
   "outputs": [],
   "source": [
    "def _sanitize(t):\n",
    "    import string\n",
    "    return ''.join(filter(lambda x: x in string.printable, t)).strip()\n",
    "\n",
    "\n",
    "class SpacyTokenizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Lazy import\n",
    "        import spacy\n",
    "        self._tokenizer = spacy.load('en', disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "    def tokens(self, text: str):\n",
    "        tokens = (_sanitize(t.text) for t in self._tokenizer(text))\n",
    "        return [t for t in tokens if t]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:26:43.428871Z",
     "start_time": "2019-01-09T23:26:42.841410Z"
    }
   },
   "outputs": [],
   "source": [
    "TOKENIZER=SpacyTokenizer()\n",
    "MAX_WORD_LEN=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:26:50.896893Z",
     "start_time": "2019-01-09T23:26:50.633805Z"
    }
   },
   "outputs": [],
   "source": [
    "c=get_doc_words(\"../data/subs/aligned/86.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:27:25.314966Z",
     "start_time": "2019-01-09T23:27:25.283374Z"
    }
   },
   "outputs": [],
   "source": [
    "c['Byzantium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:51:44.441571Z",
     "start_time": "2019-01-09T23:51:43.978600Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en', disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:00:49.985686Z",
     "start_time": "2019-01-10T01:00:49.891579Z"
    }
   },
   "outputs": [],
   "source": [
    "def all_captions():\n",
    "    from esper.captions import get_all_segments\n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    \n",
    "    video_ids = [17]\n",
    "\n",
    "    # Only aligned captions are in the caption index\n",
    "    results = get_all_segments(video_ids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in video_ids)\n",
    "    caption_results = VideoIntervalCollection({\n",
    "        video_id: [(\n",
    "            word[0] * fps_map[video_id], # start frame\n",
    "            word[1] * fps_map[video_id], # end frame\n",
    "            word[2]) # payload is the word (string)\n",
    "            for word in words]\n",
    "        for video_id, words in results\n",
    "    }).filter(lambda intvl: intvl.start >=11300 and intvl.start <=11500)\n",
    "    \n",
    "    return caption_results\n",
    "\n",
    "debug = all_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:02:55.844808Z",
     "start_time": "2019-01-10T01:02:55.810413Z"
    }
   },
   "outputs": [],
   "source": [
    "[intvl.payload for intvl in debug.get_allintervals()[17].intrvls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:47:23.671687Z",
     "start_time": "2019-01-10T01:47:23.638869Z"
    }
   },
   "outputs": [],
   "source": [
    "11/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:48:09.384075Z",
     "start_time": "2019-01-10T01:48:09.348347Z"
    }
   },
   "outputs": [],
   "source": [
    "6/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:48:15.705271Z",
     "start_time": "2019-01-10T01:48:15.670088Z"
    }
   },
   "outputs": [],
   "source": [
    "600/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:48:21.981046Z",
     "start_time": "2019-01-10T01:48:21.948814Z"
    }
   },
   "outputs": [],
   "source": [
    "11*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:48:27.205294Z",
     "start_time": "2019-01-10T01:48:27.168497Z"
    }
   },
   "outputs": [],
   "source": [
    "14*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:50:29.392172Z",
     "start_time": "2019-01-10T01:50:29.358882Z"
    }
   },
   "outputs": [],
   "source": [
    "10/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T05:21:21.013677Z",
     "start_time": "2019-01-10T05:21:20.980771Z"
    }
   },
   "outputs": [],
   "source": [
    "isinstance((1,2), tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T18:53:27.792271Z",
     "start_time": "2019-01-10T18:53:27.741835Z"
    }
   },
   "outputs": [],
   "source": [
    "import esper.pose_wrapper as pw\n",
    "ps = pw.get(PoseMeta.objects.filter(frame__video_id=184, frame__number=109332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T18:54:03.523560Z",
     "start_time": "2019-01-10T18:54:03.488638Z"
    }
   },
   "outputs": [],
   "source": [
    "ps[0].hand_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T04:29:47.815629Z",
     "start_time": "2019-01-11T04:29:47.775091Z"
    }
   },
   "outputs": [],
   "source": [
    "Face.objects.filter(frame__video_id=72, frame__number=135528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T20:51:46.511864Z",
     "start_time": "2019-01-11T20:51:46.474140Z"
    }
   },
   "outputs": [],
   "source": [
    "t=collection_with_opposing_faces.filter(lambda intvl: intvl.start==81555).get_intervallist(1).intrvls[0].payload['face_pairs'][1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T20:51:52.292405Z",
     "start_time": "2019-01-11T20:51:52.261695Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1 = t[0]['landmarks']\n",
    "lm2 = t[1]['landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T20:47:35.079946Z",
     "start_time": "2019-01-11T20:47:35.004037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line is ax+by+c=0\n",
    "def project_point_to_line(pt, a, b, c):\n",
    "    x0,y0=pt[0], pt[1]\n",
    "    d=a*a+b*b\n",
    "    x=(b*(b*x0-a*y0)-a*c)/d\n",
    "    y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "    return np.array([x,y])\n",
    "\n",
    "# Returns (a,b,c) which defines ax+by+c=0\n",
    "def find_best_line_fit(xs, ys):\n",
    "    fit1 = np.polyfit(xs, ys, 1)\n",
    "    error1 = np.sum((np.poly1d(fit1)(xs)-ys)**2)\n",
    "    fit2 = np.polyfit(ys, xs, 1)\n",
    "    error2 = np.sum((np.poly1d(fit2)(ys)-xs)**2)\n",
    "    if error1 < error2:\n",
    "        # fit1[0]x+fit1[1]=y\n",
    "        return fit1[0], -1, fit1[1]\n",
    "    # fit2[0]y+fit2[1]=x\n",
    "    return -1, fit2[0], fit2[1]\n",
    "\n",
    "def plot_face_fit(lm, data, A, B, C):\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(lm.landmarks[:,0], lm.landmarks[:,1])\n",
    "    ax.scatter(data[:,0], data[:,1])\n",
    "    t = np.array([A, B, C])\n",
    "    ax.scatter(t[:,0],t[:,1])\n",
    "    ax.arrow(A[0], A[1], (B-A)[0], (B-A)[1])\n",
    "    ax.arrow(A[0], A[1], (C-A)[0], (C-A)[1])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Positive if facing right\n",
    "def signed_face_angle(lm):\n",
    "    center_line_indices = [27,28, 32, 33,34, 51,62,66,57]\n",
    "    data = lm.landmarks[center_line_indices]\n",
    "    a, b, c = find_best_line_fit(data[:,0], data[:,1])\n",
    "    A = project_point_to_line(lm.landmarks[center_line_indices[0]], a, b, c)\n",
    "    B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a, b, c)\n",
    "    AB = B-A\n",
    "    AB = AB / np.linalg.norm(AB)\n",
    "    C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "    AC = C-A\n",
    "    AC = AC / np.linalg.norm(AC)\n",
    "    plot_face_fit(lm, data, A, B, C)\n",
    "    return np.cross(AB, AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T20:51:57.338045Z",
     "start_time": "2019-01-11T20:51:57.132770Z"
    }
   },
   "outputs": [],
   "source": [
    "signed_face_angle(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:27:47.918599Z",
     "start_time": "2019-01-11T07:27:47.884683Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1.nose_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:26:59.945514Z",
     "start_time": "2019-01-11T07:26:59.913112Z"
    }
   },
   "outputs": [],
   "source": [
    "lm1.landmarks[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T18:13:05.564022Z",
     "start_time": "2019-01-11T18:13:05.341766Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.axis('equal')\n",
    "ax.invert_yaxis()\n",
    "ax.scatter(lm2.landmarks[:,0], lm2.landmarks[:,1])\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "ax.plot(np.unique(data[:,0]), np.poly1d(np.polyfit(data[:,0], data[:,1], 1))(np.unique(data[:,0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T08:01:58.645201Z",
     "start_time": "2019-01-11T08:01:58.374460Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gca().invert_yaxis()\n",
    "plt.axis('equal')\n",
    "plt.scatter(lm2.landmarks[:,0], lm2.landmarks[:,1])\n",
    "center_line_indices = [27,28,32, 33,34, 51,62,66,57]\n",
    "data = lm2.landmarks[center_line_indices]\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "#plt.scatter(lm2.landmarks[[27,28,32,33,34,51,62,66,57],0], lm2.landmarks[[27,28,32,33,34,51,62,66,57],1])\n",
    "plt.scatter([0.506,0.56, 0.517],[0.380,0.403,0.354])\n",
    "plt.scatter(lm2.landmarks[27,0], lm2.landmarks[27,1])\n",
    "\n",
    "#plt.scatter(lm1.nose_bridge()[:,0], lm1.nose_bridge()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T01:57:21.167779Z",
     "start_time": "2019-01-12T01:57:21.125233Z"
    }
   },
   "outputs": [],
   "source": [
    "#[i.start for i in collection_with_opposing_faces.get_intervallist(59).intrvls]\n",
    "collection.filter(lambda i:i.start==115501).get_intervallist(72).intrvls[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T00:04:06.007628Z",
     "start_time": "2019-01-12T00:04:05.973404Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.pose_wrapper import PoseWrapper\n",
    "print(p1.pose_keypoints()[[p1.LShoulder, p1.RShoulder]])\n",
    "print(p2.pose_keypoints()[[p1.LShoulder, p1.RShoulder]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T19:18:26.158121Z",
     "start_time": "2019-01-11T19:18:26.116765Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_face_pair(fs):\n",
    "    def height(f):\n",
    "        return f['y2']-f['y1']\n",
    "    fs = [f for f in fs if height(f) > 0.3]\n",
    "    if len(fs) != 2:\n",
    "        print(\"too many large faces\")\n",
    "        return None, None\n",
    "    f1, f2 = fs[0], fs[1]\n",
    "    if f2['x2']<f1['x2'] and f2['x1'] < f1['x1']:\n",
    "        f1, f2 = f2, f1\n",
    "    if f1['x2']<f2['x2'] and f1['x1']<f2['x1'] and min(\n",
    "        f1['y2'],f2['y2'])-max(f1['y1'],f2['y1']) > 0.2 and (\n",
    "        f2['x1']-f1['x2']<0.05):\n",
    "        return f1, f2\n",
    "    \n",
    "    print(f1, f2)\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T19:20:34.824128Z",
     "start_time": "2019-01-11T19:20:34.793202Z"
    }
   },
   "outputs": [],
   "source": [
    "get_face_pair([f['faces'] for f in faces if f['frame']==132960][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "none",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
