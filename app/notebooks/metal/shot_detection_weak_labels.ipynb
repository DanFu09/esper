{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/lfs/1/danfu/metal')\n",
    "import metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import IntervalList\n",
    "from rekall.temporal_predicates import *\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from metal.analysis import lf_summary\n",
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "from metal.label_model import LabelModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_folds.pkl', 'rb') as f:\n",
    "    shot_detection_folds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/manually_annotated_shots.pkl', 'rb') as f:\n",
    "    shots = VideoIntervalCollection(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = shots.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_boundaries = shots.map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    ").set_union(\n",
    "    shots.map(lambda intrvl: (intrvl.end + 1, intrvl.end + 1, intrvl.payload))\n",
    ").coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_frames = {\n",
    "    video_id: [\n",
    "        intrvl.start\n",
    "        for intrvl in shot_boundaries.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    for video_id in shot_boundaries.get_allintervals()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = sorted(list(clips.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_video = {\n",
    "    video_id: sorted([\n",
    "        f\n",
    "        for interval in clips.get_intervallist(video_id).get_intervals()\n",
    "        for f in range(interval.start, interval.end + 2)\n",
    "    ])\n",
    "    for video_id in video_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {\n",
    "    video_id: [\n",
    "        1 if f in boundary_frames[video_id] else 2\n",
    "        for f in frames_per_video[video_id]\n",
    "    ] \n",
    "    for video_id in video_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weak Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/frame_counts.pkl', 'rb') as f:\n",
    "    frame_counts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_function_folders = [\n",
    "    '../../data/shot_detection_weak_labels/rgb_hists',\n",
    "    '../../data/shot_detection_weak_labels/hsv_hists',\n",
    "#     '../../data/shot_detection_weak_labels/flow_hists_magnitude', # this is just really really bad\n",
    "    '../../data/shot_detection_weak_labels/flow_hists_diffs',\n",
    "    '../../data/shot_detection_weak_labels/face_counts',\n",
    "    '../../data/shot_detection_weak_labels/face_positions'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_labels_all = []\n",
    "weak_labels_gt_only = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for folder in labeling_function_folders:\n",
    "    labels_for_function_all = {}\n",
    "    labels_for_function_gt_only = {}\n",
    "    for video_id in tqdm(video_ids):\n",
    "        all_frames = IntervalList([\n",
    "            (f+1, f+1, 0)\n",
    "            for f in range(frame_counts[video_id])\n",
    "        ])\n",
    "        with open(os.path.join(folder, '{}.pkl'.format(video_id)), 'rb') as f:\n",
    "            positive_boundaries, negative_boundaries = pickle.load(f)\n",
    "            positive_frames = IntervalList([\n",
    "                (f, f, 1)\n",
    "                for f in positive_boundaries if f <= frame_counts[video_id]\n",
    "            ])\n",
    "            negative_frames = IntervalList([\n",
    "                (f, f, 2)\n",
    "                for f in negative_boundaries if f <= frame_counts[video_id]\n",
    "            ])\n",
    "            frames_w_labels = all_frames.set_union(\n",
    "                positive_frames\n",
    "            ).set_union(\n",
    "                negative_frames\n",
    "            ).coalesce(payload_merge_op = lambda p1, p2: max(p1, p2))\n",
    "            \n",
    "            labels_for_function_all[video_id] = [\n",
    "                intrvl.payload\n",
    "                for intrvl in frames_w_labels.get_intervals()\n",
    "            ]\n",
    "            \n",
    "            labels_for_function_gt_only[video_id] = [\n",
    "                frames_w_labels.get_intervals()[f-1].payload\n",
    "                for f in frames_per_video[video_id]\n",
    "            ]\n",
    "            \n",
    "    weak_labels_all.append(labels_for_function_all)\n",
    "    weak_labels_gt_only.append(labels_for_function_gt_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([\n",
    "    label\n",
    "    for video_id in video_ids\n",
    "    for label in ground_truth[video_id]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in video_ids\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_gt_only\n",
    "]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_summary(L, Y=Y, lf_names = ['RGB hist', 'HSV hist', 'flow hist', 'face counts', 'face positions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Label Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        label\n",
    "        for video_id in test_videos\n",
    "        for label in ground_truth[video_id]\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        [\n",
    "            label\n",
    "            for video_id in test_videos\n",
    "            for label in lf[video_id]\n",
    "        ]\n",
    "        for lf in weak_labels_gt_only\n",
    "    ]).transpose()\n",
    "    \n",
    "    mv = MajorityLabelVoter(seed=123)\n",
    "    scores = mv.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.988\n",
    "Precision: 0.475\n",
    "Recall: 0.970\n",
    "F1: 0.637\n",
    "        y=1    y=2   \n",
    " l=1    131    145   \n",
    " l=2     4    12392  \n",
    " \n",
    "Accuracy: 0.991\n",
    "Precision: 0.760\n",
    "Recall: 0.941\n",
    "F1: 0.841\n",
    "        y=1    y=2   \n",
    " l=1    95     30    \n",
    " l=2     6    3996   \n",
    " \n",
    "Accuracy: 0.995\n",
    "Precision: 0.639\n",
    "Recall: 0.994\n",
    "F1: 0.778\n",
    "        y=1    y=2   \n",
    " l=1    172    97    \n",
    " l=2     1    21015  \n",
    " \n",
    "Accuracy: 0.986\n",
    "Precision: 0.452\n",
    "Recall: 0.980\n",
    "F1: 0.619\n",
    "        y=1    y=2   \n",
    " l=1    99     120   \n",
    " l=2     2    8586   \n",
    " \n",
    "Accuracy: 0.992\n",
    "Precision: 0.621\n",
    "Recall: 0.937\n",
    "F1: 0.747\n",
    "        y=1    y=2   \n",
    " l=1    133    81    \n",
    " l=2     9    11039  \n",
    " \n",
    "Average F1: .724\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Train only on frames that we have gold labels for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    L_train = csr_matrix([\n",
    "        [\n",
    "            label\n",
    "            for video_id in train_videos\n",
    "            for label in lf[video_id]\n",
    "        ]\n",
    "        for lf in weak_labels_gt_only\n",
    "    ]).transpose()\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        label\n",
    "        for video_id in test_videos\n",
    "        for label in ground_truth[video_id]\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        [\n",
    "            label\n",
    "            for video_id in test_videos\n",
    "            for label in lf[video_id]\n",
    "        ]\n",
    "        for lf in weak_labels_gt_only\n",
    "    ]).transpose()\n",
    "    \n",
    "    label_model = LabelModel(k=2, seed=123)\n",
    "    label_model.train_model(L_train, class_balance=(0.01, 0.99), n_epochs=500, log_train_every=50)\n",
    "    label_model.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results per fold:\n",
    "\n",
    "```\n",
    "Accuracy: 0.997\n",
    "Precision: 0.887\n",
    "Recall: 0.874\n",
    "F1: 0.881\n",
    "        y=1    y=2   \n",
    " l=1    118    15    \n",
    " l=2    17    12522  \n",
    "\n",
    "Accuracy: 0.990\n",
    "Precision: 0.984\n",
    "Recall: 0.594\n",
    "F1: 0.741\n",
    "        y=1    y=2   \n",
    " l=1    60      1    \n",
    " l=2    41    4025   \n",
    "\n",
    "Accuracy: 0.999\n",
    "Precision: 0.953\n",
    "Recall: 0.942\n",
    "F1: 0.948\n",
    "        y=1    y=2   \n",
    " l=1    163     8    \n",
    " l=2    10    21104  \n",
    "\n",
    "Accuracy: 0.996\n",
    "Precision: 0.802\n",
    "Recall: 0.842\n",
    "F1: 0.821\n",
    "        y=1    y=2   \n",
    " l=1    85     21    \n",
    " l=2    16    8685   \n",
    "\n",
    "Accuracy: 0.996\n",
    "Precision: 0.946\n",
    "Recall: 0.746\n",
    "F1: 0.835\n",
    "        y=1    y=2   \n",
    " l=1    106     6    \n",
    " l=2    36    11114  \n",
    " \n",
    "Average F1: .845\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Train on entire movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    L_train = csr_matrix([\n",
    "        [\n",
    "            label\n",
    "            for video_id in train_videos\n",
    "            for label in lf[video_id]\n",
    "        ]\n",
    "        for lf in weak_labels_all\n",
    "    ]).transpose()\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        label\n",
    "        for video_id in test_videos\n",
    "        for label in ground_truth[video_id]\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        [\n",
    "            label\n",
    "            for video_id in test_videos\n",
    "            for label in lf[video_id]\n",
    "        ]\n",
    "        for lf in weak_labels_gt_only\n",
    "    ]).transpose()\n",
    "    \n",
    "    label_model = LabelModel(k=2, seed=123)\n",
    "    label_model.train_model(L_train, class_balance=(0.01, 0.99), n_epochs=500, log_train_every=50)\n",
    "    label_model.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])\n",
    "    \n",
    "    Y_readable = [\n",
    "        (video_id, f, 1 if f in boundary_frames[video_id] else 2)\n",
    "        for video_id in test_videos\n",
    "        for f in frames_per_video[video_id]\n",
    "    ]\n",
    "    \n",
    "    predictions = label_model.predict(L_test)\n",
    "    prediction_probs = label_model.predict_proba(L_test)\n",
    "    prediction_probabilities.append([p[0] for p in prediction_probs])\n",
    "    \n",
    "    wrong_predictions = np.where(predictions != Y_test)[0]\n",
    "    \n",
    "    wrong_interval_preds = [\n",
    "        (Y_readable[int(wp)], prediction_probs[int(wp)].tolist())\n",
    "        for wp in wrong_predictions\n",
    "    ]\n",
    "\n",
    "    with open('../../data/failure_cases/metal_frame_only/{}_fold.pkl'.format(i + 1), 'wb') as f:\n",
    "        pickle.dump(wrong_interval_preds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.997\n",
    "Precision: 0.887\n",
    "Recall: 0.874\n",
    "F1: 0.881\n",
    "        y=1    y=2   \n",
    " l=1    118    15    \n",
    " l=2    17    12522  \n",
    "\n",
    "Accuracy: 0.990\n",
    "Precision: 0.984\n",
    "Recall: 0.594\n",
    "F1: 0.741\n",
    "        y=1    y=2   \n",
    " l=1    60      1    \n",
    " l=2    41    4025   \n",
    "\n",
    "Accuracy: 0.999\n",
    "Precision: 0.953\n",
    "Recall: 0.942\n",
    "F1: 0.948\n",
    "        y=1    y=2   \n",
    " l=1    163     8    \n",
    " l=2    10    21104  \n",
    "\n",
    "Accuracy: 0.996\n",
    "Precision: 0.802\n",
    "Recall: 0.842\n",
    "F1: 0.821\n",
    "        y=1    y=2   \n",
    " l=1    85     21    \n",
    " l=2    16    8685   \n",
    "\n",
    "Accuracy: 0.996\n",
    "Precision: 0.946\n",
    "Recall: 0.746\n",
    "F1: 0.835\n",
    "        y=1    y=2   \n",
    " l=1    106     6    \n",
    " l=2    36    11114  \n",
    " \n",
    "Average F1: .845\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, problist in enumerate(prediction_probabilities):\n",
    "    plt.hist(\n",
    "        problist,\n",
    "        log=True)\n",
    "    plt.title('Probability histogram for fold {}'.format(i + 1))\n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classify windows of 16 frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Functions for windows of 16 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct windows of 16 frames for each video\n",
    "windows = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 8)\n",
    "    ]\n",
    "    for video_id in video_ids\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, intersect the windows with ground truth and get ground truth labels for the windows\n",
    "windows_intersecting_ground_truth = windows.filter_against(\n",
    "    clips,\n",
    "    predicate=overlaps()\n",
    ").map(lambda intrvl: (intrvl.start, intrvl.end, 2))\n",
    "windows_with_shot_boundaries = windows_intersecting_ground_truth.filter_against(\n",
    "    shot_boundaries,\n",
    "    predicate = lambda window, shot_boundary:\n",
    "        shot_boundary.start >= window.start and shot_boundary.start < window.end\n",
    ").map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.end, 1)\n",
    ")\n",
    "windows_with_labels = windows_with_shot_boundaries.set_union(\n",
    "    windows_intersecting_ground_truth\n",
    ").coalesce(\n",
    "    predicate = equal(),\n",
    "    payload_merge_op = lambda p1, p2: min(p1, p2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label windows with the weak labels in our labeling functions\n",
    "def label_window(per_frame_weak_labels):\n",
    "    if 1 in per_frame_weak_labels:\n",
    "        return 1\n",
    "    if len([l for l in per_frame_weak_labels if l == 2]) >= len(per_frame_weak_labels) / 2:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "windows_with_weak_labels = windows.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_windows = np.array([\n",
    "    intrvl.payload\n",
    "    for video_id in video_ids\n",
    "    for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([y for y in Y_windows if y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_windows = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in video_ids\n",
    "    for intrvl in windows_with_weak_labels.filter_against(\n",
    "        clips, predicate=overlaps(), working_window=1\n",
    "    ).get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_summary(L_windows, Y=Y_windows, lf_names = ['RGB hist', 'HSV hist', 'flow hist', 'face counts', 'face positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in video_ids\n",
    "    for intrvl in windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_gt_only = windows_with_weak_labels.filter_against(\n",
    "    clips, predicate=overlaps(), working_window=1\n",
    ")\n",
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    mv = MajorityLabelVoter(seed=123)\n",
    "    scores = mv.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.947\n",
    "Precision: 0.785\n",
    "Recall: 0.940\n",
    "F1: 0.856\n",
    "        y=1    y=2   \n",
    " l=1    252    69    \n",
    " l=2    16    1269   \n",
    "Accuracy: 0.912\n",
    "Precision: 0.918\n",
    "Recall: 0.845\n",
    "F1: 0.880\n",
    "        y=1    y=2   \n",
    " l=1    169    15    \n",
    " l=2    31     306   \n",
    "Accuracy: 0.976\n",
    "Precision: 0.861\n",
    "Recall: 0.968\n",
    "F1: 0.911\n",
    "        y=1    y=2   \n",
    " l=1    334    54    \n",
    " l=2    11    2268   \n",
    "Accuracy: 0.914\n",
    "Precision: 0.707\n",
    "Recall: 0.906\n",
    "F1: 0.794\n",
    "        y=1    y=2   \n",
    " l=1    183    76    \n",
    " l=2    19     827   \n",
    "Accuracy: 0.957\n",
    "Precision: 0.874\n",
    "Recall: 0.905\n",
    "F1: 0.889\n",
    "        y=1    y=2   \n",
    " l=1    249    36    \n",
    " l=2    26    1116   \n",
    "\n",
    "Average F1: .866\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Train LabelModel on frames that we have GT for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_gt_only = windows_with_weak_labels.filter_against(\n",
    "    clips, predicate=overlaps(), working_window=1\n",
    ")\n",
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    L_train = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in train_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    label_model = LabelModel(k=2, seed=123)\n",
    "    label_model.train_model(L_train, class_balance=(0.15, 0.85), n_epochs=500, log_train_every=50)\n",
    "    label_model.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_gt_only = windows_with_weak_labels.filter_against(\n",
    "    clips, predicate=overlaps(), working_window=1\n",
    ")\n",
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    Y_train = np.array([\n",
    "        intrvl.payload\n",
    "        for video_id in train_videos\n",
    "        for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    L_train = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in train_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    label_model = LabelModel(k=2, seed=123)\n",
    "    label_model.train_model(L_train, Y_dev=Y_train, n_epochs=500, log_train_every=50)\n",
    "    label_model.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.927\n",
    "Precision: 0.709\n",
    "Recall: 0.882\n",
    "F1: 0.786\n",
    "        y=1    y=2   \n",
    " l=1    217    89    \n",
    " l=2    29    1271 \n",
    " \n",
    "Accuracy: 0.893\n",
    "Precision: 0.911\n",
    "Recall: 0.789\n",
    "F1: 0.845\n",
    "        y=1    y=2   \n",
    " l=1    153    15    \n",
    " l=2    41     312  \n",
    "\n",
    "Accuracy: 0.969\n",
    "Precision: 0.868\n",
    "Recall: 0.903\n",
    "F1: 0.885\n",
    "        y=1    y=2   \n",
    " l=1    316    48    \n",
    " l=2    34    2269\n",
    "\n",
    "Accuracy: 0.886\n",
    "Precision: 0.657\n",
    "Recall: 0.763\n",
    "F1: 0.706\n",
    "        y=1    y=2   \n",
    " l=1    151    79    \n",
    " l=2    47     828\n",
    "\n",
    "Accuracy: 0.941\n",
    "Precision: 0.805\n",
    "Recall: 0.881\n",
    "F1: 0.842\n",
    "        y=1    y=2   \n",
    " l=1    223    54    \n",
    " l=2    30    1120 \n",
    "\n",
    "Average F1: .813\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Train LabelModel on entire videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_gt_only = windows_with_weak_labels.filter_against(\n",
    "    clips, predicate=overlaps(), working_window=1\n",
    ")\n",
    "prediction_probabilities_windows = []\n",
    "for i in range(5):\n",
    "    test_fold = shot_detection_folds[i]\n",
    "    train_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id not in test_fold\n",
    "    ]\n",
    "    test_videos = [\n",
    "        video_id\n",
    "        for video_id in video_ids if video_id in test_fold\n",
    "    ]\n",
    "    \n",
    "    L_train = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in train_videos\n",
    "        for intrvl in windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    Y_test = np.array([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    L_test = csr_matrix([\n",
    "        intrvl.payload\n",
    "        for video_id in test_videos\n",
    "        for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "    ])\n",
    "    \n",
    "    label_model = LabelModel(k=2, seed=123)\n",
    "    label_model.train_model(L_train, class_balance=(0.15, 0.85), n_epochs=500, log_train_every=50)\n",
    "    label_model.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])\n",
    "    \n",
    "    predictions = label_model.predict(L_test)\n",
    "    prediction_probs = label_model.predict_proba(L_test)\n",
    "    prediction_probabilities_windows.append([p[0] for p in prediction_probs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.934\n",
    "Precision: 0.765\n",
    "Recall: 0.873\n",
    "F1: 0.815\n",
    "        y=1    y=2   \n",
    " l=1    234    72    \n",
    " l=2    34    1266   \n",
    "\n",
    "Accuracy: 0.910\n",
    "Precision: 0.932\n",
    "Recall: 0.825\n",
    "F1: 0.875\n",
    "        y=1    y=2   \n",
    " l=1    165    12    \n",
    " l=2    35     309   \n",
    "\n",
    "Accuracy: 0.979\n",
    "Precision: 0.877\n",
    "Recall: 0.971\n",
    "F1: 0.922\n",
    "        y=1    y=2   \n",
    " l=1    335    47    \n",
    " l=2    10    2275   \n",
    "\n",
    "Accuracy: 0.898\n",
    "Precision: 0.682\n",
    "Recall: 0.827\n",
    "F1: 0.747\n",
    "        y=1    y=2   \n",
    " l=1    167    78    \n",
    " l=2    35     825   \n",
    "\n",
    "Accuracy: 0.955\n",
    "Precision: 0.881\n",
    "Recall: 0.887\n",
    "F1: 0.884\n",
    "        y=1    y=2   \n",
    " l=1    244    33    \n",
    " l=2    31    1119   \n",
    "\n",
    "Average F1: .849\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, problist in enumerate(prediction_probabilities_windows):\n",
    "    plt.hist(\n",
    "        problist,\n",
    "        log=True)\n",
    "    plt.title('Probability histogram for fold {}'.format(i + 1))\n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Training on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load noisy labels from the entire dataset\n",
    "video_ids_all = sorted(list(frame_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weak_labels_all_movies = []\n",
    "for folder in labeling_function_folders:\n",
    "    labels_for_function_all = {}\n",
    "    for video_id in tqdm(video_ids):\n",
    "        all_frames = IntervalList([\n",
    "            (f+1, f+1, 0)\n",
    "            for f in range(frame_counts[video_id])\n",
    "        ])\n",
    "        with open(os.path.join(folder, '{}.pkl'.format(video_id)), 'rb') as f:\n",
    "            positive_boundaries, negative_boundaries = pickle.load(f)\n",
    "            positive_frames = IntervalList([\n",
    "                (f, f, 1)\n",
    "                for f in positive_boundaries if f <= frame_counts[video_id]\n",
    "            ])\n",
    "            negative_frames = IntervalList([\n",
    "                (f, f, 2)\n",
    "                for f in negative_boundaries if f <= frame_counts[video_id]\n",
    "            ])\n",
    "            frames_w_labels = all_frames.set_union(\n",
    "                positive_frames\n",
    "            ).set_union(\n",
    "                negative_frames\n",
    "            ).coalesce(payload_merge_op = lambda p1, p2: max(p1, p2))\n",
    "            \n",
    "            labels_for_function_all[video_id] = [\n",
    "                intrvl.payload\n",
    "                for intrvl in frames_w_labels.get_intervals()\n",
    "            ]\n",
    "            \n",
    "    weak_labels_all_movies.append(labels_for_function_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weak labels\n",
    "with open('../../data/shot_detection_weak_labels/all_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(weak_labels_all_movies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load weak labels\n",
    "with open('../../data/shot_detection_weak_labels/all_labels.pkl', 'rb') as f:\n",
    "    weak_labels_all_movies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_labels_gt_only = [\n",
    "    {\n",
    "        video_id: [\n",
    "            lf[video_id][f-1]\n",
    "            for f in frames_per_video[video_id]\n",
    "        ]\n",
    "        for video_id in sorted(list(clips.get_allintervals().keys()))\n",
    "    }\n",
    "    for lf in weak_labels_all_movies\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose 100 movies to train on; do not choose any movies that we have GT for\n",
    "vid_candidates = sorted(list(set(video_ids_all).difference(set(clips.get_allintervals().keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(vid_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = sorted(vid_candidates[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train split\n",
    "with open('../../data/shot_detection_weak_labels/train_split_100.pkl', 'wb') as f:\n",
    "    pickle.dump(train_split, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load train split\n",
    "with open('../../data/shot_detection_weak_labels/train_split_100.pkl', 'rb') as f:\n",
    "    train_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame-Based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos = sorted(list(clips.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_100_frames = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in train_split\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_all_movies\n",
    "]).transpose()\n",
    "\n",
    "Y_test = np.array([\n",
    "    label\n",
    "    for video_id in test_videos\n",
    "    for label in ground_truth[video_id]\n",
    "])\n",
    "L_test = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in test_videos\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_gt_only\n",
    "]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MajorityLabelVoter(seed=123).score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_100_frames = LabelModel(k=2, seed=123)\n",
    "label_model_100_frames.train_model(L_train_100_frames, Y_dev = Y_test, n_epochs=5000, log_train_every=50)\n",
    "label_model_100_frames.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct windows of 16 frames for each video\n",
    "windows_train = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 8)\n",
    "    ]\n",
    "    for video_id in train_split\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_test = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 8)\n",
    "    ]\n",
    "    for video_id in test_videos\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label windows with the weak labels in our labeling functions\n",
    "def label_window(per_frame_weak_labels):\n",
    "    if 1 in per_frame_weak_labels:\n",
    "        return 1\n",
    "    if len([l for l in per_frame_weak_labels if l == 2]) >= len(per_frame_weak_labels) / 2:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "windows_with_weak_labels_train = windows_train.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_test = windows_test.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_train_100_windows = csr_matrix([\n",
    "#     intrvl.payload\n",
    "#     for video_id in train_split\n",
    "#     for intrvl in windows_with_weak_labels_train.get_intervallist(video_id).get_intervals()\n",
    "# ])\n",
    "\n",
    "Y_test_windows = np.array([\n",
    "    intrvl.payload\n",
    "    for video_id in test_videos\n",
    "    for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "])\n",
    "L_test_windows = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in test_videos\n",
    "    for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MajorityLabelVoter(seed=123).score((L_test_windows, Y_test_windows), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_100_windows = LabelModel(k=2, seed=123)\n",
    "label_model_100_windows.train_model(L_train_100_windows, class_balance=(0.15, 0.85), n_epochs=10000, log_train_every=50)\n",
    "label_model_100_windows.score((L_test_windows, Y_test_windows), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies_all = sorted(list(set(video_ids_all).difference(set(clips.get_allintervals().keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_everything = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in train_movies_all\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_all_movies\n",
    "]).transpose()\n",
    "\n",
    "Y_test = np.array([\n",
    "    label\n",
    "    for video_id in test_videos\n",
    "    for label in ground_truth[video_id]\n",
    "])\n",
    "L_test = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in test_videos\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_gt_only\n",
    "]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_everything = LabelModel(k=2, seed=123)\n",
    "label_model_everything.train_model(L_train_everything, class_balance=(0.01, 0.99), n_epochs=5000, log_train_every=50)\n",
    "label_model_everything.score((L_test, Y_test), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_everything_frame = csr_matrix([\n",
    "    [\n",
    "        label\n",
    "        for video_id in sorted(list(video_ids_all))\n",
    "        for label in lf[video_id]\n",
    "    ]\n",
    "    for lf in weak_labels_all_movies\n",
    "]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weak_labels_all_movies[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_everything_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_predictions_everything = label_model_everything.predict_proba(L_everything_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frame_nums = [\n",
    "    (video_id, f+1)\n",
    "    for video_id in sorted(list(video_ids_all))\n",
    "    for f in range(frame_counts[video_id])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_predictions_everything.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frame_nums[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_frame_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_save = [\n",
    "    (frame_info, prediction.tolist())\n",
    "    for frame_info, prediction in zip(video_frame_nums, frame_predictions_everything)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_save[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np = np.array(predictions_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to disk\n",
    "with open('../../data/shot_detection_weak_labels/noisy_labels_all_frame.npy', 'wb') as f:\n",
    "    np.save(f, preds_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct windows of 16 frames for each video\n",
    "windows_train_all = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 8)\n",
    "    ]\n",
    "    for video_id in train_movies_all\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label windows with the weak labels in our labeling functions\n",
    "def label_window(per_frame_weak_labels):\n",
    "    if 1 in per_frame_weak_labels:\n",
    "        return 1\n",
    "    if len([l for l in per_frame_weak_labels if l == 2]) >= len(per_frame_weak_labels) / 2:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "windows_with_weak_labels_train_all = windows_train_all.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_test_all = windows.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_gt_only = windows_with_weak_labels_test_all.filter_against(\n",
    "    clips, predicate=overlaps(), working_window=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_with_weak_labels_all = windows_with_weak_labels_train_all.set_union(\n",
    "    windows_with_weak_labels_test_all\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_windows = np.array([\n",
    "    intrvl.payload\n",
    "    for video_id in test_videos\n",
    "    for intrvl in windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "])\n",
    "L_test_windows = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in test_videos\n",
    "    for intrvl in windows_with_weak_labels_gt_only.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_windows_all = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in train_split\n",
    "    for intrvl in windows_with_weak_labels_train_all.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_everything_windows = LabelModel(k=2, seed=123)\n",
    "label_model_everything_windows.train_model(L_train_windows_all, class_balance=(0.15, 0.85), n_epochs=20000, log_train_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model_everything_windows.score((L_test_windows, Y_test_windows), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_everything_windows = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in sorted(list(video_ids_all))\n",
    "    for intrvl in windows_with_weak_labels_all.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_predictions_everything = label_model_everything_windows.predict_proba(L_everything_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_nums = [\n",
    "    (video_id, intrvl.start, intrvl.end)\n",
    "    for video_id in sorted(list(video_ids_all))\n",
    "    for intrvl in windows_with_weak_labels_all.get_intervallist(video_id).get_intervals()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_save_windows = [\n",
    "    (window_info, prediction)\n",
    "    for window_info, prediction in zip(window_nums, window_predictions_everything)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np_windows = np.array(predictions_to_save_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to disk\n",
    "with open('../../data/shot_detection_weak_labels/noisy_labels_all_windows.npy', 'wb') as f:\n",
    "    np.save(f, preds_np_windows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
