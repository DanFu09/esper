{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:05:35.615306Z",
     "start_time": "2019-02-21T08:05:34.795111Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from query.models import Shot\n",
    "from django.db.models import Value\n",
    "from django.db.models.fields import IntegerField\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "\n",
    "def convert_to_1d_collection(collection):\n",
    "    from rekall.interval_list import Interval\n",
    "    video_map = collection.get_allintervals()\n",
    "    return VideoIntervalCollection({vid: [Interval(\n",
    "        i.t[0], i.t[1], i.payload) for i in video_map[vid].get_intervals()] for vid in video_map})\n",
    "\n",
    "\n",
    "def display_result(collection_1d, display_payload=False):\n",
    "    from esper.rekall import intrvllists_to_result_bbox\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    if display_payload:\n",
    "        results = intrvllists_to_result_with_objects(collection_1d.get_allintervals(), \n",
    "            lambda p, v: p, limit=1000, stride=1)\n",
    "    else:\n",
    "        results = intrvllists_to_result_with_objects(collection_1d.get_allintervals(), \n",
    "            lambda p, v:[], limit=1000, stride=1)\n",
    "    return esper_widget(results,\n",
    "            crop_bboxes=False, show_middle_frame=False, disable_captions=True,\n",
    "            results_per_page=25, jupyter_keybindings=True)\n",
    "\n",
    "def get_set(vid, collection):\n",
    "    from rekall.interval_set_3d import IntervalSet3D\n",
    "    return collection.get_allintervals().get(vid, IntervalSet3D([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermione in the Middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T07:26:12.237840Z",
     "start_time": "2019-02-21T07:25:56.477347Z"
    }
   },
   "outputs": [],
   "source": [
    "def hermione_in_the_middle():\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X\n",
    "    from rekall.temporal_predicates import before, overlaps_before\n",
    "    from rekall.bbox_predicates import height_at_least, same_value, same_height, left_of\n",
    "    from query.models import FaceCharacterActor\n",
    "    \n",
    "    MIN_FACE_HEIGHT = 0.25\n",
    "    EPSILON = 0.15\n",
    "    NAMES = [ 'ron weasley', 'hermione granger', 'harry potter' ]\n",
    "    \n",
    "    faces_with_character_actor_qs = FaceCharacterActor.objects.annotate(\n",
    "        min_frame=F('face__frame__number'),\n",
    "        max_frame=F('face__frame__number'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        bbox_x1=F('face__bbox_x1'),\n",
    "        bbox_y1=F('face__bbox_y1'),\n",
    "        bbox_x2=F('face__bbox_x2'),\n",
    "        bbox_y2=F('face__bbox_y2'),\n",
    "        character_name=F('characteractor__character__name')\n",
    "    ).filter(face__frame__video__name__contains=\"harry potter\")\n",
    "    \n",
    "    total = faces_with_character_actor_qs.count()\n",
    "    \n",
    "    schema = VideoIntervalCollection3D.django_bbox_default_schema()\n",
    "    schema['payload'] = 'character_name'    \n",
    "    all_faces = VideoIntervalCollection3D.from_django_qs(faces_with_character_actor_qs, schema, progress=True,\n",
    "                                                    total=total)\n",
    "    frames_with_faces = all_faces.group_by_time()\n",
    "    \n",
    "    def name_is(name):\n",
    "        return lambda f: f.payload == name\n",
    "    def start_before():\n",
    "        return or_preds(overlaps_before(), before())\n",
    "    def in_order():\n",
    "        return lambda a,b,c: start_before()(a,b) and start_before()(b,c)\n",
    "    def rev_order():\n",
    "        return lambda *args: in_order()(*args[::-1])\n",
    "    \n",
    "    pattern = [\n",
    "        ([\"harry\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[2])]),\n",
    "        ([\"ron\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[0])]),\n",
    "        ([\"hermione\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[1])]),\n",
    "        ([\"harry\", \"ron\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"ron\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\",\"hermione\", \"ron\"], [X(or_preds(in_order(), rev_order()))])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<character>>\n",
    "    final = frames_with_faces.filter(P(matches_pattern(pattern, exact=True)))\n",
    "    return final\n",
    "\n",
    "def payload_to_vgrid_objects(faces):\n",
    "    from query.models import Character\n",
    "    def intrvl_to_obj(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1],\n",
    "            'character_id': Character.objects.get(name=face.payload).id\n",
    "        }\n",
    "    def update(acc, face):\n",
    "        acc.append(intrvl_to_obj(face))\n",
    "        return acc\n",
    "    return faces.fold(update, [])\n",
    "    \n",
    "answer = hermione_in_the_middle()\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T07:08:47.894529Z",
     "start_time": "2019-02-14T07:08:02.922162Z"
    }
   },
   "outputs": [],
   "source": [
    "def kissing():\n",
    "    from query.models import Face\n",
    "    from rekall.interval_set_3d import Interval3D, IntervalSet3D\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps, overlaps_before, before\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.captions import get_all_segments\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.4\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.7\n",
    "    MIN_FACE_ANGLE = 0.2\n",
    "    \n",
    "    # Cannot be parallelized??\n",
    "    def get_landmarks(faces):\n",
    "        ids = [face.payload for face in faces.get_intervals()]\n",
    "        landmarks = flw.get_from_face_ids(ids)\n",
    "        id_to_lm = {idx: lm for idx, lm in zip(ids, landmarks)}\n",
    "        return faces.map_payload(lambda idx : {\n",
    "            'id': idx,\n",
    "            'landmarks': id_to_lm[idx]\n",
    "        })\n",
    "    \n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "    \n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    \n",
    "    # Returns (a,b,c) which defines ax+by+c=0\n",
    "    def find_best_line_fit(xs, ys):\n",
    "        fit1 = np.polyfit(xs, ys, 1)\n",
    "        error1 = np.sum((np.poly1d(fit1)(xs)-ys)**2)\n",
    "        fit2 = np.polyfit(ys, xs, 1)\n",
    "        error2 = np.sum((np.poly1d(fit2)(ys)-xs)**2)\n",
    "        if error1 < error2:\n",
    "            # fit1[0]x+fit1[1]=y\n",
    "            return fit1[0], -1, fit1[1]\n",
    "        # fit2[0]y+fit2[1]=x\n",
    "        return -1, fit2[0], fit2[1]\n",
    "    \n",
    "    # Positive if facing left\n",
    "    def signed_face_angle(lm):\n",
    "        center_line_indices = [27,28, 32, 33,34, 51,62,66,57]\n",
    "        data = lm.landmarks[center_line_indices]\n",
    "        a, b, c = find_best_line_fit(data[:,0], data[:,1])\n",
    "        A = project_point_to_line(lm.landmarks[center_line_indices[0]], a, b, c)\n",
    "        B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a, b, c)\n",
    "        AB = B-A\n",
    "        AB = AB / np.linalg.norm(AB)\n",
    "        C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "        AC = C-A\n",
    "        AC = AC / np.linalg.norm(AC)\n",
    "        return np.cross(AB, AC)\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(\n",
    "        frame__regularly_sampled=True,\n",
    "        probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT, video_id__lte=25)\n",
    "    \n",
    "    total = faces_qs.count()\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_faces = VideoIntervalCollection3D.from_django_qs(\n",
    "        faces_qs, VideoIntervalCollection3D.django_bbox_default_schema(),\n",
    "        progress=True, total=total\n",
    "    ).group_by_time(profile=True)\n",
    "    \n",
    "    overlap_faces_pattern = [\n",
    "        ([\"left\",\"right\"], [\n",
    "            X(or_preds(before(), overlaps_before())), # Left face on the left\n",
    "            X(lambda f1,f2: f1.end - f2.start > MIN_FACE_OVERLAP_X), # Faces overlap\n",
    "            Y(lambda f1,f2: min(f1.end, f2.end)-max(f1.start, f2.start) > MIN_FACE_OVERLAP_Y), # No face is entirely above another\n",
    "            XY(same_height(MAX_FACE_HEIGHT_DIFF)),\n",
    "            X(lambda f1, f2: (f1.end-f2.start)/max(f1.length(), f2.length()) < MAX_FACE_OVERLAP_X_FRACTION),\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_overlapped_faces = frames_with_faces.filter(P(matches_pattern(overlap_faces_pattern, exact=True)), profile=True)\n",
    "    \n",
    "#     def get_landmark_map(frames_with_faces):\n",
    "#         def update(fids, frame):\n",
    "#             faces = frame.payload\n",
    "#             return fids + [face.payload for face in faces.get_intervals()]\n",
    "#         vid_to_fids = frames_with_faces.fold(update, [])\n",
    "#         fids = [fid for fids in vid_to_fids.values() for fid in fids]\n",
    "#         print(\"Getting landmarks for {0} faces\".format(len(fids)))\n",
    "#         landmarks = flw.get_from_face_ids(fids)\n",
    "#         print(\"Landmarks loaded\".format(len(fids)))\n",
    "#         return {idx: lm for idx, lm in zip(fids, landmarks)}\n",
    "    \n",
    "#     landmark_map = get_landmark_map(frames_with_overlapped_faces)\n",
    "    \n",
    "#     def fid_to_face_meta(lm_map):\n",
    "#         def map_fn(fid):\n",
    "#             return {\n",
    "#                 'id': fid,\n",
    "#                 'landmarks': lm_map[fid]\n",
    "#             }\n",
    "#         return map_fn       \n",
    "    \n",
    "#     # Frame_IS<Face_IS<FaceMeta>>\n",
    "#     frames_with_landmarks = frames_with_overlapped_faces.map_payload(\n",
    "#         lambda faces: faces.map_payload(fid_to_face_meta(landmark_map)))\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_landmarks = frames_with_overlapped_faces.map_payload(get_landmarks, profile=True, parallel=True)\n",
    "    opposing_face_pattern = [\n",
    "        (['left'], [P(lambda f: signed_face_angle(f['landmarks']) < -MIN_FACE_ANGLE)]),\n",
    "        (['right'], [P(lambda f: signed_face_angle(f['landmarks']) > MIN_FACE_ANGLE)]),\n",
    "        (['left','right'], [P(lambda l, r: mouths_are_close(l['landmarks'], r['landmarks']))])\n",
    "    ]\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_faces = frames_with_landmarks.filter(P(matches_pattern(opposing_face_pattern, exact=True)), profile=True)\n",
    "    \n",
    "    vids = frames_with_opposing_faces.get_allintervals().keys()\n",
    "    \n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        cinematic = True,\n",
    "    )\n",
    "    total = shots_qs.count()\n",
    "    # Shot_IS<>\n",
    "    shots = VideoIntervalCollection3D.from_django_qs(\n",
    "        shots_qs,\n",
    "        progress=True, total=total\n",
    "    )\n",
    "    # Shot_IS<Frame_IS<Face_IS<FaceMeta>>>\n",
    "    kissing_shots = shots.collect_by_interval(\n",
    "        frames_with_opposing_faces,\n",
    "        T(overlaps()),\n",
    "        time_window=1, profile=True\n",
    "    ).map_payload(lambda p:p[1]).map(\n",
    "        # Take the start of the kissing as the start of the shot\n",
    "        lambda shot: Interval3D((shot.payload.get_intervals()[0].t[0], shot.t[1]), payload=shot.payload))\n",
    "    \n",
    "    # Get faces in shots\n",
    "    faces_qs2 = Face.objects.filter(\n",
    "         frame__regularly_sampled=True,\n",
    "         frame__video_id__in=vids,probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "             min_frame=F('frame__number'),\n",
    "             max_frame=F('frame__number'),\n",
    "             video_id=F('frame__video_id')       \n",
    "    )\n",
    "    total = faces_qs2.count()\n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_faces2 = VideoIntervalCollection3D.from_django_qs(\n",
    "        faces_qs2, VideoIntervalCollection3D.django_bbox_default_schema(),\n",
    "        progress=True, total=total\n",
    "    ).group_by_time(profile=True)\n",
    "    \n",
    "    def both_faces_are_high(faces):\n",
    "        def update(result, face):\n",
    "            if face.height() < MIN_FACE_HEIGHT:\n",
    "                return False\n",
    "            return result\n",
    "        return faces.fold(update, True)\n",
    "    \n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_two_faces = frames_with_faces2.filter(\n",
    "        P(lambda faces: faces.size()==2)).filter(P(both_faces_are_high), profile=True)\n",
    "    \n",
    "    # Collect frames with two faces into kissing shots, and clips the shot to the last frame with two faces\n",
    "    def clip_to_last_frame(intrvl):\n",
    "        frames = intrvl.payload[1]\n",
    "        if frames.empty():\n",
    "            return intrvl.copy()\n",
    "        return Interval3D((intrvl.t[0], frames.get_intervals()[-1].t[1]), payload=intrvl.payload)\n",
    "    \n",
    "    # Shot_IS<(Frame_IS<Face_IS>, Frame_IS<Face_IS>)>\n",
    "    clipped_kissing_shots = kissing_shots.collect_by_interval(\n",
    "        frames_with_two_faces, T(overlaps()), time_window=1, filter_empty=False, profile=True\n",
    "    ).map(clip_to_last_frame).filter_size(min_size=12)\n",
    "    \n",
    "    \n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    # Word_IS<>\n",
    "    caption_results = VideoIntervalCollection3D({\n",
    "        video_id: IntervalSet3D([Interval3D((\n",
    "            word[0] * fps_map[video_id], # start frame\n",
    "            word[1] * fps_map[video_id]))\n",
    "            for word in words])\n",
    "        for video_id, words in tqdm(results)\n",
    "    })\n",
    "    \n",
    "    kissing_without_words = clipped_kissing_shots.minus(caption_results, profile=True)\n",
    "    kissing_final = kissing_without_words.temporal_coalesce(epsilon=0.5, profile=True).map(\n",
    "        lambda i: Interval3D((int(i.t[0]), int(i.t[1])), payload=i.payload)\n",
    "    ).filter_size(min_size=12)\n",
    "    \n",
    "    return kissing_final\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_overlapped_faces, _ = payload\n",
    "    def face_to_objects(face):\n",
    "        from esper.stdlib import face_landmarks_to_dict\n",
    "        return [{\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }, face_landmarks_to_dict(face.payload['landmarks'])]\n",
    "    def update(acc, frame):\n",
    "        def accumulate_faces(a, face):\n",
    "            return a+face_to_objects(face)\n",
    "        return acc + frame.payload.fold(accumulate_faces, [])\n",
    "    return frames_with_opposing_overlapped_faces.fold(update, [])\n",
    "\n",
    "answer = kissing()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:06:01.786277Z",
     "start_time": "2019-02-08T09:06:01.756131Z"
    }
   },
   "source": [
    "# Action Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T01:11:02.451099Z",
     "start_time": "2019-02-20T01:10:06.121906Z"
    }
   },
   "outputs": [],
   "source": [
    "def action_shots():\n",
    "    from query.models import Shot\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import meets_before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from django.db.models import ExpressionWrapper, FloatField\n",
    "    from esper.captions import get_all_segments\n",
    "    from rekall.merge_ops import payload_first, payload_plus, merge_named_payload\n",
    "    import numpy as np\n",
    "\n",
    "    NUM_SHOTS=5\n",
    "    MAX_SHOT_DURATION=0.8\n",
    "    BRIGHTNESS_THRESHOLD = 20.0\n",
    "    MAX_NUM_WORDS_PER_SECOND = 1.0\n",
    "    \n",
    "    shots_qs = Shot.objects.annotate(\n",
    "        duration = ExpressionWrapper((F('max_frame') - F('min_frame')) / F('video__fps'), output_field=FloatField())\n",
    "    ).filter(\n",
    "        duration__lt=MAX_SHOT_DURATION,\n",
    "        duration__gt=0.,\n",
    "        cinematic=True,\n",
    "        video__ignore_film=False\n",
    "    )\n",
    "    total=shots_qs.count()\n",
    "    \n",
    "    # Shot_IS<>\n",
    "    short_shots = VideoIntervalCollection3D.from_django_qs(shots_qs, progress=True, total=total)\n",
    "    \n",
    "    def get_all_frames(short_shots):\n",
    "        def update(frames, shot):\n",
    "            return frames + list(range(shot.t[0], shot.t[1]+1))\n",
    "        return short_shots.fold(update, [])\n",
    "    \n",
    "    video_to_frame_numbers = get_all_frames(short_shots)\n",
    "    all_frames = VideoIntervalCollection3D({})\n",
    "    for video, frames in tqdm(video_to_frame_numbers.items()):\n",
    "        # Getting brightness\n",
    "        qs = Frame.objects.filter(video_id=video, number__in=frames, regularly_sampled=True).order_by('number')\n",
    "        all_frames = all_frames.union(VideoIntervalCollection3D.from_django_qs(\n",
    "            qs, schema={'t1':'number', 't2': 'number', 'payload': 'brightness'}), profile=False)\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Shot_IS<Frame_IS>\n",
    "    shots_with_brightness = short_shots.collect_by_interval(\n",
    "        all_frames, T(overlaps()), time_window=0, filter_empty=False\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    # Sequence_IS<Shot_IS<Frame_IS>>\n",
    "    one_shots = shots_with_brightness.collect_by_interval(\n",
    "        shots_with_brightness, T(equal()), time_window=0).map_payload(select_second)\n",
    "    n_shots = one_shots\n",
    "    for n in range(2, NUM_SHOTS+1):\n",
    "        print(\"Constructing {} consecutive short shots\".format(n))\n",
    "        n_shots = n_shots.merge(\n",
    "            one_shots,\n",
    "            T(meets_before(epsilon=1)),\n",
    "            payload_merge_op = IntervalSet3D.union,            \n",
    "            time_window=1, profile=False)\n",
    "        print('There are {} videos with {} consecutive short shots'.format(\n",
    "                 len(n_shots.get_allintervals()), n))\n",
    "        \n",
    "    def merge_shots(seq1, seq2):\n",
    "        return seq1.union(seq2.minus(seq1))\n",
    "    coalesced_n_shots = n_shots.temporal_coalesce(payload_merge_op=merge_shots)\n",
    "    \n",
    "    def bright_enough(shots):\n",
    "        # Check if any shots is above mean brightness threshold\n",
    "        def compute_avg_brightness(frames):\n",
    "            ret = frames.fold(lambda acc, f: acc+f.payload, 0)\n",
    "            if not frames.empty():\n",
    "                ret = ret / frames.size()\n",
    "            return ret\n",
    "        return shots.map_payload(compute_avg_brightness).fold(\n",
    "            lambda acc, shot: acc or shot.payload > BRIGHTNESS_THRESHOLD)\n",
    "            \n",
    "    n_bright_shots = n_shots.filter(P(bright_enough))\n",
    "    \n",
    "    vids = n_bright_shots.get_allintervals().keys()\n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    \n",
    "    # Word_IS<fps>\n",
    "    caption_results = VideoIntervalCollection3D({\n",
    "        video_id: IntervalSet3D([Interval3D(\n",
    "            (word[0] * fps_map[video_id], word[1] * fps_map[video_id]),\n",
    "            payload = fps_map[video_id])\n",
    "            for word in words])\n",
    "        for video_id, words in results\n",
    "    })\n",
    "    \n",
    "    def has_few_words(seq):\n",
    "        _, words = seq.payload\n",
    "        n_words = words.size()\n",
    "        if n_words == 0:\n",
    "            return True\n",
    "        time = seq.length() / words.get_intervals()[0].payload\n",
    "        return n_words / time <= MAX_NUM_WORDS_PER_SECOND\n",
    "    \n",
    "    # Seq_IS<(Shot_IS<Frame_IS>, Word_IS)>\n",
    "    n_bright_shots_with_few_words = n_bright_shots.collect_by_interval(\n",
    "        caption_results,\n",
    "        T(overlaps()),\n",
    "        time_window=0,\n",
    "        filter_empty=False).filter(has_few_words)\n",
    "    \n",
    "    # Seq_IS<Shot_IS<Frame_IS>>\n",
    "    action_shots = coalesced_n_shots.filter_against(\n",
    "        n_bright_shots_with_few_words,\n",
    "        T(overlaps()),\n",
    "        time_window=0)\n",
    "    \n",
    "    return action_shots\n",
    "\n",
    "answer = action_shots()\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T09:25:48.264643Z",
     "start_time": "2019-02-09T09:25:48.229274Z"
    }
   },
   "source": [
    "# Conversations with Identity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:16:38.738208Z",
     "start_time": "2019-02-21T08:16:38.690270Z"
    }
   },
   "outputs": [],
   "source": [
    "def coalesce(self, predicate, payload_merge_op):\n",
    "    from rekall.interval_set_3d import IntervalSet3D\n",
    "    # State is (new, current)\n",
    "    def update(state, interval):\n",
    "        new, current = state\n",
    "        updated_current = []\n",
    "        size = len(new)+len(current)\n",
    "        for cur in current:\n",
    "            # No more intervals will overlap with cur\n",
    "            if cur.t[1] < interval.t[0]:\n",
    "                new.append(cur)\n",
    "            else:\n",
    "                updated_current.append(cur)\n",
    "        matched = None\n",
    "        for i, cur in enumerate(updated_current):\n",
    "            if predicate(cur, interval):\n",
    "                matched = i\n",
    "                break\n",
    "        if matched is None:\n",
    "            updated_current.append(interval)\n",
    "        else:\n",
    "            updated_current[matched] = updated_current[matched].merge(interval, payload_merge_op)\n",
    "        return new, updated_current\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        old = self.size(profile=False)\n",
    "        self = self.fold_to_set(update, ([],[]), acc_to_set=lambda state: IntervalSet3D(state[0]+state[1]),\n",
    "                                profile=False)\n",
    "        converged = old == self.size(profile=False)\n",
    "        # print(old, self.size(profile=False))\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:16:41.532381Z",
     "start_time": "2019-02-21T08:16:41.391251Z"
    }
   },
   "outputs": [],
   "source": [
    "def conversationsq(vids, progress=True):\n",
    "    from query.models import FaceCharacterActor, Shot\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    \n",
    "    faces_with_character_actor_qs = FaceCharacterActor.objects.annotate(\n",
    "        min_frame=F('face__frame__number'),\n",
    "        max_frame=F('face__frame__number'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        bbox_x1=F('face__bbox_x1'),\n",
    "        bbox_y1=F('face__bbox_y1'),\n",
    "        bbox_x2=F('face__bbox_x2'),\n",
    "        bbox_y2=F('face__bbox_y2'),\n",
    "        character_name=F('characteractor__character__name')\n",
    "    ).filter(face__frame__video_id__in=vids)\n",
    "    \n",
    "    total = faces_with_character_actor_qs.count()\n",
    "    \n",
    "    schema = VideoIntervalCollection3D.django_bbox_default_schema()\n",
    "    schema['payload'] = 'character_name'    \n",
    "    all_faces = VideoIntervalCollection3D.from_django_qs(faces_with_character_actor_qs, schema, progress=progress,\n",
    "                                                    total=total)\n",
    "    \n",
    "    vids = all_faces.get_allintervals().keys()\n",
    "    if len(vids) == 0:\n",
    "        return VideoIntervalCollection3D({})\n",
    "    \n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        cinematic = True,\n",
    "    )\n",
    "    total = shots_qs.count()\n",
    "    shots = VideoIntervalCollection3D.from_django_qs(\n",
    "        shots_qs,\n",
    "        progress=progress, total=total\n",
    "    )\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Shot_IS<Face_IS>\n",
    "    shots_with_frames = shots.collect_by_interval(\n",
    "        all_faces, T(overlaps()), time_window=0, filter_empty=True).map_payload(select_second)\n",
    "    \n",
    "    def group_characters(faces):\n",
    "        def get_char(face):\n",
    "            return face.payload\n",
    "        def merge(char, faces):\n",
    "            merged_interval = faces.fold(Interval3D.merge)\n",
    "            merged_interval.payload = (char, faces)\n",
    "            return merged_interval\n",
    "        return faces.group_by(get_char, merge)\n",
    "    \n",
    "    # Shot_IS<Char_IS<(char, Face_IS)>>\n",
    "    shots_with_chars = shots_with_frames.map_payload(group_characters)\n",
    "    \n",
    "    def cross_product_chars(chars1, chars2):\n",
    "        def get_chars(chars):\n",
    "            def update(acc, char):\n",
    "                acc.append(char.payload[0])\n",
    "                return acc\n",
    "            return chars.fold(update, [])\n",
    "        chars_in_1 = get_chars(chars1)\n",
    "        chars_in_2 = get_chars(chars2)\n",
    "        result = []\n",
    "        for charA in chars_in_1:\n",
    "            for charB in chars_in_2:\n",
    "                if charA != charB:\n",
    "                    result.append((charA, charB))\n",
    "        return result\n",
    "            \n",
    "    # Seq_IS<[(char, char)]>\n",
    "    two_shots = shots_with_chars.merge(\n",
    "        shots_with_chars,\n",
    "        T(before(max_dist=1)),\n",
    "        payload_merge_op=cross_product_chars,\n",
    "        time_window=1\n",
    "    )\n",
    "    \n",
    "    def sequences_share_face_pair(list1, list2):\n",
    "        for A1, B1 in list1:\n",
    "            for A2, B2 in list2:\n",
    "                if ((A1==A2 and B1==B2) or\n",
    "                    (A1==B2 and B1==A2)):\n",
    "                    return True\n",
    "        return False\n",
    "    def merge_face_pairs(list1, list2):\n",
    "        return list1+list2\n",
    "    \n",
    "    conv_candidates = coalesce(two_shots, P(sequences_share_face_pair), merge_face_pairs)\n",
    "    \n",
    "    def num_shots_at_least(n):\n",
    "        def pred(shots):\n",
    "            return shots.size() >= n\n",
    "        return pred\n",
    "    \n",
    "    # Conv_IS<Shot_IS<Char_IS<(char, Face_IS)>>>\n",
    "    convs = conv_candidates.collect_by_interval(\n",
    "        shots_with_chars, T(overlaps()), time_window=0, filter_empty=True\n",
    "    ).map_payload(select_second\n",
    "    ).filter(P(num_shots_at_least(3)))\n",
    "    \n",
    "    \n",
    "    return convs\n",
    "\n",
    "#answer = conversationsq([380])\n",
    "#display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShotScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:26:26.483155Z",
     "start_time": "2019-02-21T08:26:26.183547Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_scale_q(vids, progress=True):\n",
    "    from query.models import Face, Pose, Shot\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from esper import pose_wrapper as pw\n",
    "    from esper import shot_scale\n",
    "    \n",
    "    shots_qs = Shot.objects.filter(video_id__in=vids, cinematic=True)\n",
    "    total = shots_qs.count()\n",
    "    # Shot_IS\n",
    "    shots = VideoIntervalCollection3D.from_django_qs(shots_qs, progress=progress, total=total)\n",
    "    \n",
    "    faces_qs= Face.objects.filter(frame__video_id__in=vids, frame__regularly_sampled=True\n",
    "                                 ).annotate(video_id=F('frame__video__id'),\n",
    "                                            number=F('frame__number'))\n",
    "    poses_qs = PoseMeta.objects.filter(frame__video_id__in=vids, frame__regularly_sampled=True\n",
    "                                 ).annotate(video_id=F('frame__video__id'),\n",
    "                                            number=F('frame__number'))\n",
    "    \n",
    "    total = faces_qs.count()\n",
    "    all_faces = VideoIntervalCollection3D.from_django_qs(faces_qs, schema={\n",
    "        't1':'number', 't2':'number', 'x1':'bbox_x1', 'x2':'bbox_x2', 'y1':'bbox_y1', 'y2':'bbox_y2'\n",
    "    }, progress=progress, total=total)\n",
    "    \n",
    "    total = poses_qs.count()\n",
    "    all_poses = VideoIntervalCollection3D.from_django_qs(poses_qs, schema={\n",
    "        't1':'number', 't2':'number', 'payload':'id'\n",
    "    }, progress=progress, total=total)\n",
    "    \n",
    "    # print(\"Loading {0} Poses\".format(total))\n",
    "    \n",
    "    def get_pose_map(poses_qs):\n",
    "        poses = pw.get(poses_qs)\n",
    "        # print(\"Poses loaded\")\n",
    "        return {pose.id: pose for pose in poses}\n",
    "    \n",
    "    def get_pose(pose_map):\n",
    "        def map_fn(payload):\n",
    "            return pose_map[payload]\n",
    "        return map_fn\n",
    "    \n",
    "    all_poses = all_poses.map_payload(get_pose(get_pose_map(poses_qs)), profile=progress)\n",
    "    \n",
    "    def add_scale_to_face(face):\n",
    "        face.payload = shot_scale.face_height_to_shot_scale(face.height())\n",
    "        return face\n",
    "    \n",
    "    # Face_IS<Scale>\n",
    "    all_faces_with_scale = all_faces.map(add_scale_to_face, profile=progress)\n",
    "    \n",
    "    def add_scale_to_pose(pose):\n",
    "        return {\n",
    "            'pose': pose,\n",
    "            'scale': shot_scale.pose_keypoints_to_shot_scale(pose.pose_keypoints())\n",
    "        }\n",
    "    # Pose_IS<{'pose','scale'}>\n",
    "    all_poses_with_scale = all_poses.map_payload(add_scale_to_pose, profile=progress)\n",
    "    \n",
    "    # Frame_IS\n",
    "    all_frames_with_signal = all_faces.union(all_poses).group_by_time(profile=progress)\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Frame_IS<(Face_IS, Pose_IS)>\n",
    "    frames_with_faces_and_poses = all_frames_with_signal.collect_by_interval(\n",
    "        all_faces_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress,\n",
    "    ).map_payload(select_second).collect_by_interval(\n",
    "        all_poses_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress\n",
    "    )\n",
    "    \n",
    "    def add_scale_to_frame(payload):\n",
    "        faces, poses = payload\n",
    "        def take_max_face(acc, face):\n",
    "            return max(acc, face.payload)\n",
    "        def take_max_pose(acc, pose):\n",
    "            return max(acc, pose.payload['scale'])\n",
    "        max_face_scale = faces.fold(take_max_face, shot_scale.ShotScale.UNKNOWN)\n",
    "        max_pose_scale = poses.fold(take_max_pose, shot_scale.ShotScale.UNKNOWN)\n",
    "        return (max(max_face_scale, max_pose_scale), faces, poses)\n",
    "    \n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    frames_with_scale = frames_with_faces_and_poses.map_payload(add_scale_to_frame, profile=progress)\n",
    "    \n",
    "    # Shot_IS<Frame_IS<(Scale, Face_IS, Pose_IS)>>\n",
    "    shots_with_frames = shots.collect_by_interval(\n",
    "        frames_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress,\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    def get_mode(scales):\n",
    "        count = {}\n",
    "        for s in shot_scale.ShotScale:\n",
    "            count[s] = 0\n",
    "        for s in scales:\n",
    "            count[s]+=1\n",
    "        best_count = 0\n",
    "        best_scale=shot_scale.ShotScale.UNKNOWN\n",
    "        for s in shot_scale.ShotScale:\n",
    "            if count[s]>=best_count:\n",
    "                best_count = count[s]\n",
    "                best_scale = s\n",
    "        return best_scale\n",
    "    \n",
    "    def add_scale_to_shot(frames):\n",
    "        def update(acc, frame):\n",
    "            acc.append(frame.payload[0])\n",
    "            return acc\n",
    "        scales = frames.fold(update, [])\n",
    "        mode = get_mode(scales)\n",
    "        return mode, frames\n",
    "    \n",
    "    # Shot_IS<(Scale, Frame_IS<(Scale, Face_IS<Scale>, Pose_IS<(Scale, PoseKeypoints)>)>)>\n",
    "    shots_with_scale = shots_with_frames.map_payload(add_scale_to_shot, profile=progress)\n",
    "    return shots_with_scale\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    scale, frames = payload\n",
    "    def face_to_object(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }\n",
    "    \n",
    "    def pose_to_object(pose):\n",
    "        from esper.stdlib import pose_to_dict\n",
    "        return pose_to_dict(pose.payload['pose'])\n",
    "    \n",
    "    def face_objects_at_scale(faces, scale):\n",
    "        faces = faces.filter(P(lambda p:p==scale))\n",
    "        def update(acc, face):\n",
    "            acc.append(face_to_object(face))\n",
    "            return acc\n",
    "        return faces.fold(update, [])\n",
    "    \n",
    "    def pose_objects_at_scale(poses, scale):\n",
    "        poses = poses.filter(P(lambda p:p['scale']==scale))\n",
    "        def update(acc, pose):\n",
    "            acc.append(pose_to_object(pose))\n",
    "            return acc\n",
    "        return poses.fold(update, [])\n",
    "    \n",
    "    frames = frames.filter(P(lambda p:p[0]==scale))\n",
    "    def update(acc, frame):\n",
    "        _, faces, poses = frame.payload\n",
    "        return acc + face_objects_at_scale(faces, scale) + pose_objects_at_scale(poses, scale)\n",
    "    return frames.fold(update, [])\n",
    "\n",
    "#answer = shot_scale_q([1])\n",
    "#display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T23:23:29.485059Z",
     "start_time": "2019-02-19T23:23:27.493922Z"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_func(vid):\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from query.models import Video\n",
    "    \n",
    "    print(\"Processing\", vid)\n",
    "    v = Video.objects.get(id=vid)\n",
    "    return IntervalSet3D([Interval3D((0, v.num_frames-1))])\n",
    "\n",
    "def run_dummy():\n",
    "    from esper.rekall_parallel import par_do\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    return par_do(dummy_func, vids, profile=True, parallel=True, fork=True)\n",
    "\n",
    "display_result(convert_to_1d_collection(run_dummy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hermione in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:05:51.124241Z",
     "start_time": "2019-02-21T08:05:38.804718Z"
    }
   },
   "outputs": [],
   "source": [
    "def hermione_in_the_middle_for_vid(vid):\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X\n",
    "    from rekall.temporal_predicates import before, overlaps_before\n",
    "    from rekall.bbox_predicates import height_at_least, same_value, same_height, left_of\n",
    "    from query.models import FaceCharacterActor\n",
    "    \n",
    "    MIN_FACE_HEIGHT = 0.25\n",
    "    EPSILON = 0.15\n",
    "    NAMES = [ 'ron weasley', 'hermione granger', 'harry potter' ]\n",
    "    \n",
    "    faces_with_character_actor_qs = FaceCharacterActor.objects.annotate(\n",
    "        min_frame=F('face__frame__number'),\n",
    "        max_frame=F('face__frame__number'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        bbox_x1=F('face__bbox_x1'),\n",
    "        bbox_y1=F('face__bbox_y1'),\n",
    "        bbox_x2=F('face__bbox_x2'),\n",
    "        bbox_y2=F('face__bbox_y2'),\n",
    "        character_name=F('characteractor__character__name')\n",
    "    ).filter(face__frame__video_id=vid)\n",
    "    \n",
    "    schema = VideoIntervalCollection3D.django_bbox_default_schema()\n",
    "    schema['payload'] = 'character_name'    \n",
    "    all_faces = VideoIntervalCollection3D.from_django_qs(faces_with_character_actor_qs, schema).get_allintervals()[vid]\n",
    "    frames_with_faces = all_faces.group_by_time()\n",
    "    \n",
    "    def name_is(name):\n",
    "        return lambda f: f.payload == name\n",
    "    def start_before():\n",
    "        return or_preds(overlaps_before(), before())\n",
    "    def in_order():\n",
    "        return lambda a,b,c: start_before()(a,b) and start_before()(b,c)\n",
    "    def rev_order():\n",
    "        return lambda *args: in_order()(*args[::-1])\n",
    "    \n",
    "    pattern = [\n",
    "        ([\"harry\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[2])]),\n",
    "        ([\"ron\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[0])]),\n",
    "        ([\"hermione\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[1])]),\n",
    "        ([\"harry\", \"ron\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"ron\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\",\"hermione\", \"ron\"], [X(or_preds(in_order(), rev_order()))])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<character>>\n",
    "    final = frames_with_faces.filter(P(matches_pattern(pattern, exact=True)))\n",
    "    return final\n",
    "\n",
    "def run_hp():\n",
    "    from esper.rekall_parallel import get_runtime_for_jupyter\n",
    "    from rekall.runtime import wrap_interval_set\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.filter(name__contains=\"harry potter\")]\n",
    "    rt = get_runtime_for_jupyter(num_workers=8)\n",
    "    return rt.run(wrap_interval_set(hermione_in_the_middle_for_vid), vids, profile=True, progress=True)\n",
    "\n",
    "def payload_to_vgrid_objects(faces):\n",
    "    from query.models import Character\n",
    "    def intrvl_to_obj(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1],\n",
    "            'character_id': Character.objects.get(name=face.payload).id\n",
    "        }\n",
    "    def update(acc, face):\n",
    "        acc.append(intrvl_to_obj(face))\n",
    "        return acc\n",
    "    return faces.fold(update, [])\n",
    "    \n",
    "answer = run_hp()\n",
    "print(\"Answer computed. Preparing for VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:13:33.268056Z",
     "start_time": "2019-02-21T08:09:01.421386Z"
    }
   },
   "outputs": [],
   "source": [
    "def kissing_for_vid(vid):\n",
    "    from query.models import Face\n",
    "    from rekall.interval_set_3d import Interval3D, IntervalSet3D\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps, overlaps_before, before\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.captions import get_all_segments\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.4\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.7\n",
    "    MIN_FACE_ANGLE = 0.2\n",
    "    \n",
    "    def get_landmarks(faces):\n",
    "        ids = [face.payload for face in faces.get_intervals()]\n",
    "        landmarks = flw.get_from_face_ids(ids)\n",
    "        id_to_lm = {idx: lm for idx, lm in zip(ids, landmarks)}\n",
    "        return faces.map_payload(lambda idx : {\n",
    "            'id': idx,\n",
    "            'landmarks': id_to_lm[idx]\n",
    "        })\n",
    "    \n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "    \n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    \n",
    "    # Returns (a,b,c) which defines ax+by+c=0\n",
    "    def find_best_line_fit(xs, ys):\n",
    "        fit1 = np.polyfit(xs, ys, 1)\n",
    "        error1 = np.sum((np.poly1d(fit1)(xs)-ys)**2)\n",
    "        fit2 = np.polyfit(ys, xs, 1)\n",
    "        error2 = np.sum((np.poly1d(fit2)(ys)-xs)**2)\n",
    "        if error1 < error2:\n",
    "            # fit1[0]x+fit1[1]=y\n",
    "            return fit1[0], -1, fit1[1]\n",
    "        # fit2[0]y+fit2[1]=x\n",
    "        return -1, fit2[0], fit2[1]\n",
    "    \n",
    "    # Positive if facing left\n",
    "    def signed_face_angle(lm):\n",
    "        center_line_indices = [27,28, 32, 33,34, 51,62,66,57]\n",
    "        data = lm.landmarks[center_line_indices]\n",
    "        a, b, c = find_best_line_fit(data[:,0], data[:,1])\n",
    "        A = project_point_to_line(lm.landmarks[center_line_indices[0]], a, b, c)\n",
    "        B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a, b, c)\n",
    "        AB = B-A\n",
    "        AB = AB / np.linalg.norm(AB)\n",
    "        C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "        AC = C-A\n",
    "        AC = AC / np.linalg.norm(AC)\n",
    "        return np.cross(AB, AC)\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(\n",
    "        frame__regularly_sampled=True,\n",
    "        probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT, video_id=vid)\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_faces = get_set(vid, VideoIntervalCollection3D.from_django_qs(\n",
    "        faces_qs, VideoIntervalCollection3D.django_bbox_default_schema(),\n",
    "    )).group_by_time()\n",
    "    \n",
    "    overlap_faces_pattern = [\n",
    "        ([\"left\",\"right\"], [\n",
    "            X(or_preds(before(), overlaps_before())), # Left face on the left\n",
    "            X(lambda f1,f2: f1.end - f2.start > MIN_FACE_OVERLAP_X), # Faces overlap\n",
    "            Y(lambda f1,f2: min(f1.end, f2.end)-max(f1.start, f2.start) > MIN_FACE_OVERLAP_Y), # No face is entirely above another\n",
    "            XY(same_height(MAX_FACE_HEIGHT_DIFF)),\n",
    "            X(lambda f1, f2: (f1.end-f2.start)/max(f1.length(), f2.length()) < MAX_FACE_OVERLAP_X_FRACTION),\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_overlapped_faces = frames_with_faces.filter(P(matches_pattern(overlap_faces_pattern, exact=True)))\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_landmarks = frames_with_overlapped_faces.map_payload(get_landmarks)\n",
    "    opposing_face_pattern = [\n",
    "        (['left'], [P(lambda f: signed_face_angle(f['landmarks']) < -MIN_FACE_ANGLE)]),\n",
    "        (['right'], [P(lambda f: signed_face_angle(f['landmarks']) > MIN_FACE_ANGLE)]),\n",
    "        (['left','right'], [P(lambda l, r: mouths_are_close(l['landmarks'], r['landmarks']))])\n",
    "    ]\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_faces = frames_with_landmarks.filter(P(matches_pattern(opposing_face_pattern, exact=True)))\n",
    "    \n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id = vid,\n",
    "        cinematic = True,\n",
    "    )\n",
    "    # Shot_IS<>\n",
    "    shots = get_set(vid, VideoIntervalCollection3D.from_django_qs(\n",
    "        shots_qs,\n",
    "    ))\n",
    "    # Shot_IS<Frame_IS<Face_IS<FaceMeta>>>\n",
    "    kissing_shots = shots.collect_by_interval(\n",
    "        frames_with_opposing_faces,\n",
    "        T(overlaps()),\n",
    "        time_window=1,\n",
    "    ).map_payload(lambda p:p[1]).map(\n",
    "        # Take the start of the kissing as the start of the shot\n",
    "        lambda shot: Interval3D((shot.payload.get_intervals()[0].t[0], shot.t[1]), payload=shot.payload))\n",
    "    \n",
    "    # Get faces in shots\n",
    "    faces_qs2 = Face.objects.filter(\n",
    "         frame__regularly_sampled=True,\n",
    "         frame__video_id=vid,\n",
    "         probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "             min_frame=F('frame__number'),\n",
    "             max_frame=F('frame__number'),\n",
    "             video_id=F('frame__video_id')       \n",
    "    )\n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_faces2 = get_set(vid, VideoIntervalCollection3D.from_django_qs(\n",
    "        faces_qs2, VideoIntervalCollection3D.django_bbox_default_schema(),\n",
    "    )).group_by_time()\n",
    "    \n",
    "    def both_faces_are_high(faces):\n",
    "        def update(result, face):\n",
    "            if face.height() < MIN_FACE_HEIGHT:\n",
    "                return False\n",
    "            return result\n",
    "        return faces.fold(update, True)\n",
    "    \n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_two_faces = frames_with_faces2.filter(\n",
    "        P(lambda faces: faces.size()==2)).filter(P(both_faces_are_high))\n",
    "    \n",
    "    # Collect frames with two faces into kissing shots, and clips the shot to the last frame with two faces\n",
    "    def clip_to_last_frame(intrvl):\n",
    "        frames = intrvl.payload[1]\n",
    "        if frames.empty():\n",
    "            return intrvl.copy()\n",
    "        return Interval3D((intrvl.t[0], frames.get_intervals()[-1].t[1]), payload=intrvl.payload)\n",
    "    \n",
    "    # Shot_IS<(Frame_IS<Face_IS>, Frame_IS<Face_IS>)>\n",
    "    clipped_kissing_shots = kissing_shots.collect_by_interval(\n",
    "        frames_with_two_faces, T(overlaps()), time_window=1, filter_empty=False\n",
    "    ).map(clip_to_last_frame).filter_size(min_size=12)\n",
    "    \n",
    "    \n",
    "    _, words = next(get_all_segments([vid]))\n",
    "    fps = Video.objects.get(id=vid).fps\n",
    "    # Word_IS<>\n",
    "    caption_results = IntervalSet3D([Interval3D((\n",
    "            word[0] * fps, # start frame\n",
    "            word[1] * fps))\n",
    "            for word in words])\n",
    "    \n",
    "    kissing_without_words = clipped_kissing_shots.minus(caption_results)\n",
    "    kissing_final = kissing_without_words.temporal_coalesce(epsilon=0.5).map(\n",
    "        lambda i: Interval3D((int(i.t[0]), int(i.t[1])), payload=i.payload)\n",
    "    ).filter_size(min_size=12)\n",
    "    \n",
    "    return kissing_final\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_overlapped_faces, _ = payload\n",
    "    def face_to_objects(face):\n",
    "        from esper.stdlib import face_landmarks_to_dict\n",
    "        return [{\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }, face_landmarks_to_dict(face.payload['landmarks'])]\n",
    "    def update(acc, frame):\n",
    "        def accumulate_faces(a, face):\n",
    "            return a+face_to_objects(face)\n",
    "        return acc + frame.payload.fold(accumulate_faces, [])\n",
    "    return frames_with_opposing_overlapped_faces.fold(update, [])\n",
    "\n",
    "def run_kissing():\n",
    "    from esper.rekall_parallel import get_worker_pool_factory_for_jupyter, WorkerPoolWithStorageFactory\n",
    "    from rekall.runtime import Runtime, wrap_interval_set\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    output_dir = \"/app/data/kissing\"\n",
    "    rt = Runtime(WorkerPoolWithStorageFactory(output_dir, get_worker_pool_factory_for_jupyter(num_workers=10)))\n",
    "    return rt.run(wrap_interval_set(kissing_for_vid), vids, profile=True, progress=True, chunksize=5)\n",
    "\n",
    "answer = run_kissing()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:15:27.592628Z",
     "start_time": "2019-02-21T08:15:11.592198Z"
    }
   },
   "outputs": [],
   "source": [
    "def action_shots_for_vid(vid):\n",
    "    from query.models import Shot\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import meets_before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from django.db.models import ExpressionWrapper, FloatField\n",
    "    from esper.captions import get_all_segments\n",
    "    from rekall.merge_ops import payload_first, payload_plus, merge_named_payload\n",
    "    import numpy as np\n",
    "\n",
    "    NUM_SHOTS=5\n",
    "    MAX_SHOT_DURATION=0.8\n",
    "    BRIGHTNESS_THRESHOLD = 20.0\n",
    "    MAX_NUM_WORDS_PER_SECOND = 1.0\n",
    "    \n",
    "    shots_qs = Shot.objects.annotate(\n",
    "        duration = ExpressionWrapper((F('max_frame') - F('min_frame')) / F('video__fps'), output_field=FloatField())\n",
    "    ).filter(\n",
    "        duration__lt=MAX_SHOT_DURATION,\n",
    "        duration__gt=0.,\n",
    "        cinematic=True,\n",
    "        video_id=vid,\n",
    "    )\n",
    "    \n",
    "    # Shot_IS<>\n",
    "    short_shots = get_set(vid, VideoIntervalCollection3D.from_django_qs(shots_qs))\n",
    "    \n",
    "    def get_all_frames(short_shots):\n",
    "        def update(frames, shot):\n",
    "            return frames + list(range(shot.t[0], shot.t[1]+1))\n",
    "        return short_shots.fold(update, [])\n",
    "    \n",
    "    frame_numbers = get_all_frames(short_shots)\n",
    "    frames_qs = Frame.objects.filter(video_id=vid, number__in=frame_numbers, regularly_sampled=True).order_by('number')\n",
    "    all_frames = get_set(vid, VideoIntervalCollection3D.from_django_qs(\n",
    "            frames_qs, schema={'t1':'number', 't2': 'number', 'payload': 'brightness'}))\n",
    "\n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Shot_IS<Frame_IS>\n",
    "    shots_with_brightness = short_shots.collect_by_interval(\n",
    "        all_frames, T(overlaps()), time_window=0, filter_empty=False\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    # Sequence_IS<Shot_IS<Frame_IS>>\n",
    "    one_shots = shots_with_brightness.collect_by_interval(\n",
    "        shots_with_brightness, T(equal()), time_window=0).map_payload(select_second)\n",
    "    n_shots = one_shots\n",
    "    for n in range(2, NUM_SHOTS+1):\n",
    "        n_shots = n_shots.merge(\n",
    "            one_shots,\n",
    "            T(meets_before(epsilon=1)),\n",
    "            payload_merge_op = IntervalSet3D.union,            \n",
    "            time_window=1)\n",
    "        \n",
    "    def merge_shots(seq1, seq2):\n",
    "        return seq1.union(seq2.minus(seq1))\n",
    "    coalesced_n_shots = n_shots.temporal_coalesce(payload_merge_op=merge_shots)\n",
    "    \n",
    "    def bright_enough(shots):\n",
    "        # Check if any shots is above mean brightness threshold\n",
    "        def compute_avg_brightness(frames):\n",
    "            ret = frames.fold(lambda acc, f: acc+f.payload, 0)\n",
    "            if not frames.empty():\n",
    "                ret = ret / frames.size()\n",
    "            return ret\n",
    "        return shots.map_payload(compute_avg_brightness).fold(\n",
    "            lambda acc, shot: acc or shot.payload > BRIGHTNESS_THRESHOLD)\n",
    "            \n",
    "    n_bright_shots = n_shots.filter(P(bright_enough))\n",
    "    \n",
    "    _, words = next(get_all_segments([vid]))\n",
    "    fps = Video.objects.get(id=vid).fps\n",
    "    \n",
    "    # Word_IS<>\n",
    "    caption_results = IntervalSet3D([Interval3D(\n",
    "            (word[0] * fps, word[1] * fps))\n",
    "            for word in words])\n",
    "    \n",
    "    def has_few_words(seq):\n",
    "        _, words = seq.payload\n",
    "        n_words = words.size()\n",
    "        if n_words == 0:\n",
    "            return True\n",
    "        time = seq.length() / fps\n",
    "        return n_words / time <= MAX_NUM_WORDS_PER_SECOND\n",
    "    \n",
    "    # Seq_IS<(Shot_IS<Frame_IS>, Word_IS)>\n",
    "    n_bright_shots_with_few_words = n_bright_shots.collect_by_interval(\n",
    "        caption_results,\n",
    "        T(overlaps()),\n",
    "        time_window=0,\n",
    "        filter_empty=False).filter(has_few_words)\n",
    "    \n",
    "    # Seq_IS<Shot_IS<Frame_IS>>\n",
    "    action_shots = coalesced_n_shots.filter_against(\n",
    "        n_bright_shots_with_few_words,\n",
    "        T(overlaps()),\n",
    "        time_window=0)\n",
    "    \n",
    "    return action_shots\n",
    "\n",
    "def run_action_shots():\n",
    "    from esper.rekall_parallel import get_runtime_for_jupyter\n",
    "    from rekall.runtime import wrap_interval_set\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_jupyter(num_workers=8)\n",
    "    return rt.run(wrap_interval_set(action_shots_for_vid), vids, profile=True, progress=True)\n",
    "\n",
    "answer = run_action_shots()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversations with Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:24:18.396125Z",
     "start_time": "2019-02-21T08:17:47.973577Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_conversations():\n",
    "    from esper.rekall_parallel import get_runtime_for_jupyter\n",
    "    from query.models import Video, FaceCharacterActor\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_jupyter()\n",
    "    def query(vids):\n",
    "        return conversationsq(vids, progress=False)\n",
    "    return rt.run(query, vids, profile=True, progress=True, chunksize=10)\n",
    "\n",
    "answer = run_conversations()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShotScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:37:03.868385Z",
     "start_time": "2019-02-21T08:26:46.738097Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_shot_scale():\n",
    "    from esper.rekall_parallel import get_runtime_for_jupyter\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.filter(id__gte=600)]\n",
    "    rt = get_runtime_for_jupyter()\n",
    "    def query(vids):\n",
    "        return shot_scale_q(vids, progress=False)\n",
    "    return rt.run(query, vids, profile=True, progress=True, chunksize=1)\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    scale, frames = payload\n",
    "    def face_to_object(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }\n",
    "    \n",
    "    def pose_to_object(pose):\n",
    "        from esper.stdlib import pose_to_dict\n",
    "        return pose_to_dict(pose.payload['pose'])\n",
    "    \n",
    "    def face_objects_at_scale(faces, scale):\n",
    "        faces = faces.filter(P(lambda p:p==scale))\n",
    "        def update(acc, face):\n",
    "            acc.append(face_to_object(face))\n",
    "            return acc\n",
    "        return faces.fold(update, [])\n",
    "    \n",
    "    def pose_objects_at_scale(poses, scale):\n",
    "        poses = poses.filter(P(lambda p:p['scale']==scale))\n",
    "        def update(acc, pose):\n",
    "            acc.append(pose_to_object(pose))\n",
    "            return acc\n",
    "        return poses.fold(update, [])\n",
    "    \n",
    "    frames = frames.filter(P(lambda p:p[0]==scale))\n",
    "    def update(acc, frame):\n",
    "        _, faces, poses = frame.payload\n",
    "        return acc + face_objects_at_scale(faces, scale) + pose_objects_at_scale(poses, scale)\n",
    "    return frames.fold(update, [])\n",
    "\n",
    "answer = run_shot_scale()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T00:24:01.993498Z",
     "start_time": "2019-02-10T00:24:01.953664Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.filter(lambda i:i.t[0]==120401).get_allintervals()[380].get_intervals()[0].payload.map_payload(lambda char: char.fold(lambda acc, c: acc+[c.payload[0]], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T19:39:36.083555Z",
     "start_time": "2019-02-11T19:39:36.051577Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()[32].get_intervals()[0].payload[0].get_intervals()[0].payload.get_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T22:33:45.964208Z",
     "start_time": "2019-02-11T22:33:19.090364Z"
    }
   },
   "outputs": [],
   "source": [
    "def payload_to_vgrid_objects(payload):\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    scale, frames = payload\n",
    "    def face_to_object(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }\n",
    "    \n",
    "    def pose_to_object(pose):\n",
    "        from esper.stdlib import pose_to_dict\n",
    "        return pose_to_dict(pose.payload['pose'])\n",
    "    \n",
    "    def face_objects_at_scale(faces, scale):\n",
    "        faces = faces.filter(P(lambda p:p==scale))\n",
    "        def update(acc, face):\n",
    "            acc.append(face_to_object(face))\n",
    "            return acc\n",
    "        return faces.fold(update, [])\n",
    "    \n",
    "    def pose_objects_at_scale(poses, scale):\n",
    "        poses = poses.filter(P(lambda p:p['scale']==scale))\n",
    "        def update(acc, pose):\n",
    "            acc.append(pose_to_object(pose))\n",
    "            return acc\n",
    "        return poses.fold(update, [])\n",
    "    \n",
    "    frames = frames.filter(P(lambda p:p[0]==scale))\n",
    "    def update(acc, frame):\n",
    "        _, faces, poses = frame.payload\n",
    "        return acc + face_objects_at_scale(faces, scale) + pose_objects_at_scale(poses, scale)\n",
    "    return frames.fold(update, [])\n",
    "\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:42:15.510233Z",
     "start_time": "2019-02-14T05:42:15.436150Z"
    }
   },
   "outputs": [],
   "source": [
    "qs=Face.objects.all()[:3]\n",
    "[q.id for q in qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:33:35.694562Z",
     "start_time": "2019-02-14T05:33:35.497049Z"
    }
   },
   "outputs": [],
   "source": [
    "import esper.face_landmarks_wrapper as flw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:33:55.830761Z",
     "start_time": "2019-02-14T05:33:55.797716Z"
    }
   },
   "outputs": [],
   "source": [
    "flw.get_from_face_ids([3,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T07:36:54.585992Z",
     "start_time": "2019-02-14T07:36:39.400298Z"
    }
   },
   "outputs": [],
   "source": [
    "from django.db.models import Count\n",
    "from query.models import Face\n",
    "Face.objects.values(\"frame__video_id\").annotate(num_faces=Count('id')).order_by('num_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T21:50:08.195355Z",
     "start_time": "2019-02-19T21:50:08.155611Z"
    }
   },
   "outputs": [],
   "source": [
    "from query.models import Frame, Video\n",
    "v = Video.objects.get(id=1)\n",
    "Frame.objects.filter(video=v, number=v.num_frames-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T01:46:42.160154Z",
     "start_time": "2019-02-20T01:46:41.064610Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.shot_scale import ShotScale as ShotScaleEnum\n",
    "from rekall.interval_set_3d_utils import P\n",
    "display_result(convert_to_1d_collection(answer.filter(P(lambda p: p==ShotScaleEnum.EXTREME_LONG))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:42:24.161519Z",
     "start_time": "2019-02-21T08:37:46.756154Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects, profile=True, parallel=True)), display_payload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1219px",
    "left": "0px",
    "right": "2348px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
