{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "from query.datasets.tvnews.shot_detect import shot_detect, shot_stitch\n",
    "from query.datasets.tvnews.face_detect import face_detect\n",
    "from query.datasets.tvnews.face_embed import face_embed\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "from query.datasets.tvnews.identity_detect import identity_detect\n",
    "from query.datasets.tvnews.animatedness import shot_frame_to_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_update_copy(self, objects):\n",
    "    with connection.cursor() as cursor:\n",
    "        table = self.model._meta.db_table\n",
    "        cursor.execute('BEGIN')\n",
    "        cursor.execute('TRUNCATE TABLE {}'.format(table))\n",
    "        bulk_create_copy(self, objects, table=table)\n",
    "        cursor.execute('END')\n",
    "        \n",
    "with Timer('updating'):\n",
    "    bulk_update_copy(Shot.objects, sorted(flatten(all_shots.values()), key=itemgetter('id')))\n",
    "#Shot.objects.bulk_update([Shot(**d) for d in flatten(all_shots.values())], batch_size=50000, update_fields=['in_commercial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.debug('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_commercials(all_commercials):\n",
    "    to_save = []\n",
    "    labeler, _ = Labeler.objects.get_or_create(name='haotian-commercials')\n",
    "    for path, commercials in tqdm(all_commercials.iteritems()):\n",
    "        v = all_videos['tvnews/videos/{}.mp4'.format(path)]\n",
    "        for (min_frame, _), (max_frame, _) in commercials:\n",
    "            to_save.append({\n",
    "                'min_frame': min_frame,\n",
    "                'max_frame': max_frame,\n",
    "                'video_id': v.id,\n",
    "                'labeler_id': labeler.id\n",
    "            })\n",
    "    Commercial.objects.bulk_create_copy(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commercials = pickle.load(open('/app/commercial_dict_2.pkl'))\n",
    "load_commercials(all_commercials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query.datasets.tvnews.models import ThingType \n",
    "def load_segments(all_topics):\n",
    "    all_videos = {v.path: v for v in tqdm(Video.objects.all().order_by('id'))}\n",
    "\n",
    "    types = {\n",
    "        'subject': ThingType.TOPIC,\n",
    "        'phrase': ThingType.PHRASE,\n",
    "        'people': ThingType.PERSON,\n",
    "        'location': ThingType.LOCATION,\n",
    "        'organization': ThingType.ORGANIZATION\n",
    "    }\n",
    "\n",
    "    seen = {\n",
    "        t: set()\n",
    "        for t in types.values()\n",
    "    }\n",
    "\n",
    "    things_to_save = []\n",
    "    segments_to_save = []\n",
    "    for path, segments in tqdm(all_topics.iteritems()):\n",
    "        for (start, end), things in segments.iteritems():\n",
    "            for k, l in things.iteritems():\n",
    "                if k == 'sentiment':\n",
    "                    pass\n",
    "                else:\n",
    "                    ty = types[k]\n",
    "                    for obj in l:\n",
    "                        if obj is None: continue\n",
    "                        if ty == ThingType.PERSON:\n",
    "                            obj = ' '.join(obj.split(', ')[::-1]).strip()\n",
    "                        obj = obj.lower()\n",
    "                        if obj not in seen[ty]:                        \n",
    "                            things_to_save.append({\n",
    "                                'name': obj,\n",
    "                                'type': ty\n",
    "                            })\n",
    "                            seen[ty].add(obj)\n",
    "    Thing.objects.bulk_create_copy(things_to_save)\n",
    "    \n",
    "    log.debug('Creating segments')\n",
    "    segments_to_save = []\n",
    "    labeler, _ = Labeler.objects.get_or_create(name='haotian-segments')\n",
    "    for path, segments in tqdm(all_topics.iteritems()):\n",
    "        v = all_videos['tvnews/videos/{}.mp4'.format(path)]\n",
    "        for (start, end), things in segments.iteritems():\n",
    "            (polarity, subjectivity) = things['sentiment']\n",
    "            s = {\n",
    "                'min_frame': int(start * v.fps),\n",
    "                'max_frame': int(end * v.fps),\n",
    "                'video_id': v.id,\n",
    "                'labeler_id': labeler.id\n",
    "            }\n",
    "            if polarity is not None and subjectivity is not None:\n",
    "                s['polarity'] = polarity\n",
    "                s['subjectivity'] = subjectivity\n",
    "            segments_to_save.append(s)\n",
    "    Segment.objects.bulk_create_copy(segments_to_save)\n",
    "    \n",
    "    log.debug('Creating links')\n",
    "    cur_segments = {(s['video_id'], s['min_frame'], s['max_frame']): s for s in tqdm(Segment.objects.all().values())}\n",
    "    cur_things = {(t['name'], t['type']): t for t in tqdm(Thing.objects.all().values())}\n",
    "    links_to_save = []\n",
    "    for path, segments in tqdm(all_topics.iteritems()):\n",
    "        v = all_videos['tvnews/videos/{}.mp4'.format(path)]\n",
    "        for (start, end), things in segments.iteritems():\n",
    "            s = cur_segments[(v.id, int(start*v.fps), int(end*v.fps))]        \n",
    "            for k, l in things.iteritems():\n",
    "                if k == 'sentiment':\n",
    "                    pass\n",
    "                else:\n",
    "                    ty = types[k]\n",
    "                    for obj in l:\n",
    "                        if obj is None: continue\n",
    "                        if ty == ThingType.PERSON:\n",
    "                            obj = ' '.join(obj.split(', ')[::-1]).strip()\n",
    "                        obj = obj.lower()\n",
    "                        links_to_save.append({\n",
    "                            'tvnews_segment_id': s['id'],\n",
    "                            'tvnews_thing_id': cur_things[(obj, ty)]['id']\n",
    "                        })\n",
    "                        \n",
    "\n",
    "    bulk_create_copy(Segment.things.through.objects, links_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = pickle.load(open('/app/topic_dict_res_2.pkl'))\n",
    "load_segments(all_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = list(tqdm(Video.objects.all().order_by('id')))\n",
    "vids = all_videos[:100]\n",
    "make_montage_video(vids, 0, 1000, '/app/montage.mkv', num_cols=10, width=1600, target_height=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Detecting shots'):\n",
    "    import query.datasets.tvnews.shot_detect\n",
    "    reload(query.datasets.tvnews.shot_detect)\n",
    "    from query.datasets.tvnews.shot_detect import shot_detect\n",
    "    log.debug('Loading videos')\n",
    "    all_videos = list(tqdm(Video.objects.all().order_by('id')))\n",
    "    shot_indices, all_shots, all_blackframes = shot_detect(all_videos)\n",
    "    shot_videos = gather(all_videos, shot_indices)\n",
    "    log.debug('Computing face frames to detect')\n",
    "    face_frame_per_shot = [[shot_frame_to_detect(shot) for shot in vid_shots]\n",
    "                           for vid_shots in tqdm(all_shots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Detecting sparse face'):\n",
    "    import query.datasets.tvnews.face_detect\n",
    "    reload(query.datasets.tvnews.face_detect)\n",
    "    from query.datasets.tvnews.face_detect import face_detect\n",
    "    \n",
    "    all_faces, indices = face_detect(shot_videos, face_frame_per_shot)\n",
    "    face_videos = gather(shot_videos, indices)\n",
    "    face_shots = gather(all_shots, indices)\n",
    "    face_frames = gather(face_frame_per_shot, indices)\n",
    "    print(len(all_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "with Timer('Saving faces'):\n",
    "    frames_to_save = [\n",
    "        [{\n",
    "            'video_id': video.id,\n",
    "            'number': f\n",
    "        } for f in frames]\n",
    "        for (video, frames) in zip(face_videos, face_frames)\n",
    "    ]\n",
    "    Frame.objects.bulk_create_copy(flatten(frames_to_save))\n",
    "    \n",
    "    labeler, _ = Labeler.objects.get_or_create(name='mtcnn')\n",
    "    for (frames, vid_faces) in zip(frames_to_save, all_faces):\n",
    "        for (frame, faces) in zip(frames, vid_faces):\n",
    "            for face in faces:\n",
    "                face['frame_id'] = frame['id']\n",
    "                face['labeler_id'] = labeler.id\n",
    "    Face.objects.bulk_create_copy(flatten(all_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_montage(face_videos[0], face_frames[0], '/app/montage.jpg', bboxes=all_faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_name(video, frames):\n",
    "    return video.path + '_faces_' + str(hash(tuple(frames)))\n",
    "\n",
    "face_tables = [output_name(video, frames) for video, frames in tqdm(zip(face_videos, face_frames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer('Gender faces'):\n",
    "    import query.datasets.tvnews.gender_detect\n",
    "    reload(query.datasets.tvnews.gender_detect)\n",
    "    from query.datasets.tvnews.gender_detect import gender_detect\n",
    "    \n",
    "    gender_detect(face_videos, face_frames, face_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Embedding faces\"):\n",
    "    import query.datasets.tvnews.face_embed\n",
    "    reload(query.datasets.tvnews.face_embed)\n",
    "    from query.datasets.tvnews.face_embed import face_embed\n",
    "\n",
    "    face_embed(face_videos, face_frames, face_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_name(video, frames):\n",
    "    return video.path + '_embeddings_' + str(hash(tuple(frames)))\n",
    "\n",
    "with make_scanner_db() as db:\n",
    "    db._load_db_metadata()\n",
    "    \n",
    "indices, embed_tables = unzip([\n",
    "    (i, db.table(output_name(video, frames)))\n",
    "    for i, (video, frames) in tqdm(enumerate(zip(face_videos, face_frames)))\n",
    "    if db.has_table(output_name(video, frames)) and db.table(output_name(video, frames)).committed()\n",
    "])\n",
    "print(len(indices))\n",
    "\n",
    "embed_videos, embed_frames, embed_faces, embed_shots = map(lambda l: gather(l, indices),\n",
    "                                                          (face_videos, face_frames, all_faces, face_shots))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Embedding faces\"):\n",
    "    def load_embs():\n",
    "        log.debug('Loading embs')\n",
    "        EMBEDDING_SIZE = 128\n",
    "        def load(t):\n",
    "            embs = list(t.column('embeddings').load())\n",
    "            arrays = [np.frombuffer(emb, dtype=np.float32) if emb is not None else [] for _, emb in embs]\n",
    "            return [np.split(a, len(a) / 128) if len(a) > 0 else [] for a in arrays]\n",
    "        return par_for(load, embed_tables, workers=32)\n",
    "\n",
    "    all_embs = pcache.get('all_embs', load_embs, method='pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flat_embs():\n",
    "    with Timer(\"Embedding faces\"):\n",
    "        def load_embs():\n",
    "            log.debug('Loading embs')\n",
    "            EMBEDDING_SIZE = 128\n",
    "            def load(t):\n",
    "                embs = list(t.column('embeddings').load())\n",
    "                arrays = [np.frombuffer(emb, dtype=np.float32) if emb is not None else [] for _, emb in embs]\n",
    "                return [np.split(a, len(a) / 128) if len(a) > 0 else [] for a in arrays]\n",
    "            return par_for(load, embed_tables, workers=32)\n",
    "\n",
    "        all_embs = pcache.get('all_embs', load_embs, method='pickle')\n",
    "        \n",
    "    with Timer('Pinging db'):\n",
    "        db_faces = list(Face.objects.all().values('id', 'person__frame__video__id', 'person__frame__number', 'bbox_x1'))\n",
    "    d1 = {k: collect(f, itemgetter('person__frame__number')) for k, f in collect(db_faces, itemgetter('person__frame__video__id')).iteritems()}\n",
    "\n",
    "    EPSILON = 0.0001\n",
    "    for (video, vid_faces, vid_frames) in tqdm(zip(embed_videos, embed_faces, embed_frames)):\n",
    "        for (frame_faces, frame) in zip(vid_faces, vid_frames):\n",
    "            for face in frame_faces:\n",
    "                for face2 in d1[video.id][frame]:\n",
    "                    if abs(face['bbox_x1'] - face2['bbox_x1']) < EPSILON:\n",
    "                        face['id'] = face2['id']\n",
    "                        face_id = face2['id']\n",
    "                        break\n",
    "        \n",
    "    return unzip([\n",
    "        (face['id'], emb)\n",
    "        for (vid_faces, vid_embs) in tqdm(zip(embed_faces, all_embs))\n",
    "        for (frame_faces, frame_embs) in zip(vid_faces, vid_embs)\n",
    "        for (face, emb) in zip(frame_faces, frame_embs)\n",
    "    ])\n",
    "    \n",
    "face_ids, all_embs_flat = pcache.get(\n",
    "    ('face_ids', 'all_embs_flat'), load_flat_embs, method=('pickle', 'numpy'), dtype=np.float32, length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/app/anchor_test_txt.txt') as f:\n",
    "#     paths = ['tvnews/videos/{}.mp4'.format(s.strip()) for s in f.readlines()]\n",
    "    \n",
    "vid_map = {v.path: i for i, v in enumerate(embed_videos)}\n",
    "#indices = [vid_map[p] for p in paths]\n",
    "indices = list(range(len(embed_videos)))\n",
    "from itertools import izip\n",
    "        \n",
    "for_haotian = [\n",
    "    {\n",
    "        'video': video.path,\n",
    "        'shots': [{\n",
    "            'min_frame': s['min_frame'],\n",
    "            'max_frame': s['max_frame'],\n",
    "            'face_frame': frame,\n",
    "            'faces': zip(fr_faces, fr_embs)\n",
    "        } for s, frame, fr_faces, fr_embs in zip(shots, frames, faces, embs)\n",
    "        if len(fr_faces) >= 1 and len(fr_faces) <= 3]\n",
    "    }\n",
    "    for (video, shots, frames, faces, embs) in\n",
    "    tqdm(izip(gather(embed_videos, indices), \n",
    "              gather(embed_shots, indices), \n",
    "              gather(embed_frames, indices), \n",
    "              gather(embed_faces, indices), \n",
    "              gather(all_embs, indices)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(for_haotian, open('/app/for_haotian.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_facefeatures():\n",
    "    return spark.dicts_to_df([\n",
    "        {'face_id': face['id'], 'embedding': emb}\n",
    "        for (vid_faces, vid_embs) in tqdm(zip(embed_faces, all_embs))\n",
    "        for (frame_faces, frame_embs) in zip(vid_faces, vid_embs)\n",
    "        for (face, emb) in zip(frame_faces, frame_embs)\n",
    "    ])\n",
    "\n",
    "featues_df = spark.load('facefeatures', load_facefeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.rdd.map(lambda d: distance.euclidean(d['embedding'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "for_sahaj = [\n",
    "    {\n",
    "        'video': video.path,\n",
    "        'shots': [{\n",
    "            'min_frame': s['min_frame'],\n",
    "            'max_frame': s['max_frame'],\n",
    "            'face_frame': frame,\n",
    "            'faces': zip(fr_faces, fr_embs)\n",
    "        } for s, frame, fr_faces, fr_embs in zip(shots, frames, faces, embs)]\n",
    "    }\n",
    "    for (video, shots, frames, faces, embs) in\n",
    "    tqdm(izip(embed_videos[:1000], embed_shots, embed_frames, embed_faces, all_embs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(for_sahaj, open('sahaj-data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Stitching shots\"):    \n",
    "    def load_stitches():\n",
    "        log.debug('Computing stitches')\n",
    "        import query.datasets.tvnews.shot_detect\n",
    "        reload(query.datasets.tvnews.shot_detect)\n",
    "        return query.datasets.tvnews.shot_detect.shot_stitch(embed_videos, embed_shots, embed_frames, embed_faces, all_embs)\n",
    "    (stitched_shots, stitched_indices) = pcache.get('stitched_shots', load_stitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = embed_faces\n",
    "stitched_videos = embed_videos\n",
    "stitched_frames, stitched_faces, stitched_embs = map(\n",
    "    lambda t: [gather(l, idx) for l, idx in zip(t, stitched_indices)],\n",
    "    (embed_frames, embed_faces, all_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = Show.objects.get(name='The Rachel Maddow Show').id\n",
    "indices = [i for i, video in enumerate(stitched_videos) if video.show_id == show]\n",
    "\n",
    "with Timer('Detecting identities'):\n",
    "    def load_identities():\n",
    "        log.debug('Computing identities')\n",
    "        import query.datasets.tvnews.identity_detect\n",
    "        reload(query.datasets.tvnews.identity_detect)\n",
    "\n",
    "        return query.datasets.tvnews.identity_detect.identity_detect(\n",
    "           gather(stitched_videos, indices), \"/app/rachel-maddow.jpg\", gather(stitched_embs, indices))\n",
    "    \n",
    "    matching_indices = pcache.get('matching_indices', load_identities)\n",
    "    \n",
    "print(len(matching_indices), sum([len(l) for l in matching_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "flat_indices = [(i, j, k) for i, idx in enumerate(matching_indices) for (j, k) in idx]\n",
    "random_indices = random.sample(flat_indices, 16)\n",
    "identity_videos = gather(stitched_videos, indices)\n",
    "identity_frames = gather(stitched_frames, indices)\n",
    "make_montage(\n",
    "    [identity_videos[i] for i, _1, _2 in random_indices],\n",
    "    [identity_frames[i][j] for i, j, _ in random_indices],\n",
    "    'montage.jpg',\n",
    "    num_cols=4,\n",
    "    target_height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_indices_onelevel = [[j for j, k in l] for l in matching_indices]\n",
    "matching_videos, matching_shots, matching_frames, matching_faces = \\\n",
    "    (gather(filter3_videos, indices),      \n",
    "    [gather(shots, idxs) for (shots, idxs) in zip(gather(stitched_shots, indices), matching_indices_onelevel)],\n",
    "    [gather(frames, idxs) for (frames, idxs) in zip(gather(filter3_frames, indices), matching_indices_onelevel)],\n",
    "    [gather2(faces, idxs) for (faces, idxs) in zip(gather(filter3_faces, indices), matching_indices)])\n",
    "    \n",
    "#pose_blacklist = ['tvnews/videos/MSNBCW_20170708_010000_The_Rachel_Maddow_Show.mp4']    \n",
    "#pose_blacklist = ['tvnews/videos/MSNBCW_20170506_040000_The_Rachel_Maddow_Show.mp4']\n",
    "pose_blacklist = []\n",
    "    \n",
    "matching2_videos, matching2_shots, matching2_frames, matching2_faces = unzip([\n",
    "    (video, shots, frames, faces)\n",
    "    for video, shots, frames, faces in zip(matching_videos, matching_shots, matching_frames, matching_faces)\n",
    "    if len(shots) > 0 and video.path not in pose_blacklist\n",
    "])\n",
    "    \n",
    "TARGET_FPS = 10\n",
    "pose_frames = [\n",
    "    sum([list(range(s['min_frame'], s['max_frame'], int(round(video.fps / TARGET_FPS)))) for s in shots], [])\n",
    "    for (video, shots) in zip(matching2_videos, matching2_shots)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_detect\n",
    "\n",
    "all_poses = pose_detect(matching2_videos, pose_frames, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.tvnews.pose_detect\n",
    "reload(query.datasets.tvnews.pose_detect)\n",
    "from query.datasets.tvnews.pose_detect import pose_track\n",
    "\n",
    "\n",
    "#pose_track(matching2_videos, matching2_shots, matching2_frames, matching2_faces, all_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    if len(matches) == 0:\n",
    "        print(video.path)\n",
    "        return\n",
    "    make_montage(\n",
    "        video,\n",
    "        [frames[j] for j, _ in matches],\n",
    "        '/tmp/montage{}.jpg'.format(i),\n",
    "        bboxes=[[faces[j][k]] for j, k in matches],\n",
    "        progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query.datasets.prelude\n",
    "reload(query.datasets.prelude)\n",
    "from query.datasets.prelude import *\n",
    "\n",
    "# make_montage(filter3_videos[indices[i]], filter3_frames[indices[i]],\n",
    "#              '/app/montage.jpg', filter3_faces[indices[i]], workers=96, progress=True)\n",
    "\n",
    "def bbox_montage((i, (video, frames, faces, matches))):\n",
    "    try:\n",
    "        if len(matches) == 0:\n",
    "            print(video.path)\n",
    "            return\n",
    "        bbox_map = defaultdict(list, {j: [faces[j][k]] for j, k in matches})\n",
    "        make_montage(\n",
    "            video,\n",
    "            #[frames[j] for j, _ in matches],\n",
    "            frames,\n",
    "            '/tmp/montage{}.jpg'.format(i),\n",
    "            bboxes=[bbox_map[i] for i in range(len(frames))],\n",
    "            #bboxes=[[faces[j][k]] for j, k in matches],\n",
    "            progress=False)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        print(video.path)\n",
    "    \n",
    "_ = par_for(bbox_montage,\n",
    "        list(enumerate(zip(gather(filter3_videos, indices)[:100], gather(filter3_frames, indices), \n",
    "            gather(filter3_faces, indices), matching_indices))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "\n",
    "par_for(make_montage,\n",
    "        list(enumerate(zip(filter2_videos, [[s['min_frame'] for s in l] for l in stitched_shots][:100]))),\n",
    "        process=True,\n",
    "        workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shot.objects.bulk_create_copy({\n",
    "    'min_frame': shot['min_frame'], \n",
    "    'max_frame': shot['max_frame'], \n",
    "    'labeler_id': shot['labeler'],\n",
    "    'video_id': shot['video__id']\n",
    "} for shot_list in tqdm(stitched_shots) for shot in shot_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
