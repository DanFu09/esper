{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Supercuts\" data-toc-modified-id=\"Supercuts-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Supercuts</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-all-intervals-of-person-P\" data-toc-modified-id=\"Get-all-intervals-of-person-P-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get all intervals of person P</a></span></li><li><span><a href=\"#For-each-word-W-in-sentence,-create-list-of-intervals-for-W\" data-toc-modified-id=\"For-each-word-W-in-sentence,-create-list-of-intervals-for-W-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>For each word W in sentence, create list of intervals for W</a></span></li><li><span><a href=\"#For-each-word-W,-intersect-its-interval-list-with-person-P-intervals-to-get-P-+-W-intervals\" data-toc-modified-id=\"For-each-word-W,-intersect-its-interval-list-with-person-P-intervals-to-get-P-+-W-intervals-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>For each word W, intersect its interval list with person P intervals to get P + W intervals</a></span></li><li><span><a href=\"#Get-all-intervals-where-there-is-exactly-one-face-on-screen\" data-toc-modified-id=\"Get-all-intervals-where-there-is-exactly-one-face-on-screen-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Get all intervals where there is exactly one face on screen</a></span></li><li><span><a href=\"#For-each-word-W-in-sentence,-intersect-P-with-word-intervals-with-one-face-intervals\" data-toc-modified-id=\"For-each-word-W-in-sentence,-intersect-P-with-word-intervals-with-one-face-intervals-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>For each word W in sentence, intersect P with word intervals with one face intervals</a></span></li><li><span><a href=\"#Random-sample-one-element-from-each-P-+-W-alone-interval-list\" data-toc-modified-id=\"Random-sample-one-element-from-each-P-+-W-alone-interval-list-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Random sample one element from each P + W alone interval list</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercuts\n",
    "\n",
    "Our goal is to get intervals for a short supercut video of a certain person (e.g, Anderson Cooper) saying a funny sentence, like:\n",
    "\n",
    "```\n",
    "P = a person in the dataset\n",
    "sentence = \"Intel is great because they fund Stanford.\"\n",
    "```\n",
    "\n",
    "We'll use `rekall` to get the candidate intervals and the caption index to get caption intervals. Make sure the caption index and `rekall` are installed in your Esper instance before running this notebook. If they aren't, the imports will fail.\n",
    "\n",
    "Strategy:\n",
    "1. Get all intervals where person P is on screen\n",
    "2. For each word W in sentence, create list of intervals for W \n",
    "3. For each word W, intersect its interval list with person P intervals to get P + W intervals\n",
    "4. Get all intervals where there is exactly one face on screen\n",
    "5. For each word W, intersect P + W intervals with one face intervals to get P + W alone intervals\n",
    "6. Random sample one element from each P + W alone interval list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T22:10:08.077905Z",
     "start_time": "2018-12-11T22:10:06.761825Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import rekall\n",
    "from esper.rekall import *\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import Interval, IntervalList\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.spatial_predicates import *\n",
    "from esper.utility import *\n",
    "# import caption search\n",
    "from esper.captions import *\n",
    "\n",
    "# import face identities for person search\n",
    "from query.models import Video, Face, FaceIdentity\n",
    "\n",
    "# import esper widget for debugging\n",
    "from esper.prelude import esper_widget\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import tempfile\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:33:38.285266Z",
     "start_time": "2018-12-08T00:33:38.235794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set these parameters for the notebook.\n",
    "person_name = \"Anderson Cooper\"\n",
    "sentence = \"Make america great again\"\n",
    "# video_list = pickle.load(open('/app/data/tvnews_std_sample.pkl', 'rb'))['sample_100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:48:39.654233Z",
     "start_time": "2018-12-08T00:48:36.758634Z"
    }
   },
   "outputs": [],
   "source": [
    "videos = [Video.objects.filter(path__contains=video_name)[0] for video_name in video_list]\n",
    "video_ids = [video.id for video in videos if video.threeyears_dataset]\n",
    "print(len(video_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all intervals of person P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T23:44:09.277704Z",
     "start_time": "2018-12-07T23:44:05.926685Z"
    }
   },
   "outputs": [],
   "source": [
    "person_intrvllists = qs_to_intrvllists(\n",
    "    FaceIdentity.objects\n",
    "#         .filter(face__shot__video_id__in=video_ids)\n",
    "        .filter(identity__name=person_name.lower())\n",
    "        .filter(probability__gt=0.99)\n",
    "        .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "        .annotate(shot_id=F(\"face__shot_id\"))\n",
    "        .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "        .annotate(max_frame=F(\"face__shot__max_frame\")),\n",
    "    schema={\n",
    "        'start': 'min_frame',\n",
    "        'end': 'max_frame',\n",
    "        'payload': 'shot_id'\n",
    "    })\n",
    "person_intrvlcol = VideoIntervalCollection(person_intrvllists)\n",
    "print(\"Got all occurrences of {}\".format(person_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each word W in sentence, create list of intervals for W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:58:26.634438Z",
     "start_time": "2018-12-08T00:58:26.454480Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for 2. to convert caption search to dict mapping from video ID to IntervalList\n",
    "def caption_to_intrvllists(search_term, dilation=0, video_ids=None):\n",
    "    results = topic_search([search_term], dilation)\n",
    "    if video_ids == None:\n",
    "        videos = {v.id: v for v in Video.objects.all()}\n",
    "    else:\n",
    "        videos = {v.id: v for v in Video.objects.filter(id__in=video_ids).all()}\n",
    "    \n",
    "    def convert_time(k, t):\n",
    "        return int(t * videos[k].fps)\n",
    "    \n",
    "    segments_by_video = {}\n",
    "    flattened = [\n",
    "        (v.id, convert_time(v.id, l.start), convert_time(v.id, l.end)) \n",
    "        for v in results.documents if v.id in videos\n",
    "        for l in v.locations\n",
    "    ]\n",
    "    \n",
    "    for video_id, t1, t2 in flattened:\n",
    "        if video_id in segments_by_video:\n",
    "            segments_by_video[video_id].append((t1, t2, 0))\n",
    "        else:\n",
    "            segments_by_video[video_id] = [(t1, t2, 0)]\n",
    "    \n",
    "    for video in segments_by_video:\n",
    "        segments_by_video[video] = IntervalList(segments_by_video[video])\n",
    "        \n",
    "    print(\"Got all occurrences of the word {} by searching\".format(search_term))\n",
    "    \n",
    "    return segments_by_video\n",
    "\n",
    "# scans for search terms across videos in parallel\n",
    "def scan_for_search_terms_intrvllist(search_terms, video_ids, dilation=0):\n",
    "    results = scan_for_ngrams_in_parallel(search_terms, video_ids)\n",
    "    \n",
    "    search_terms_intrvllists = [{} for term in search_terms]\n",
    "    videos = {v.id: v for v in Video.objects.filter(id__in=video_ids).all()}\n",
    "    def convert_time(k, t):\n",
    "        return int(t * videos[k].fps)\n",
    "    \n",
    "    for video_id, result in results:\n",
    "        if result == []:\n",
    "            continue\n",
    "        for i, term in enumerate(search_terms):\n",
    "            term_result = result[i]\n",
    "            interval_list = IntervalList([\n",
    "                (convert_time(video_id, start - dilation),\n",
    "                convert_time(video_id, end + dilation),\n",
    "                0)\n",
    "                for start, end in term_result\n",
    "            ])\n",
    "            if interval_list.size() > 0:\n",
    "                search_terms_intrvllists[i][video_id] = interval_list\n",
    "        \n",
    "    print(\"Got all occurrences of the words {} by scanning\".format(search_terms))\n",
    "    \n",
    "    return search_terms_intrvllists\n",
    "\n",
    "import pysrt\n",
    "def scan_aligned_transcript_intrvllist(search_terms, video_ids):\n",
    "    word_intrvllists = {term: {} for term in search_terms}\n",
    "    for video_id in video_ids:\n",
    "        video = Video.objects.filter(id=video_id)[0]\n",
    "        video_name = os.path.basename(video.path)[:-4]\n",
    "        print(video_name)\n",
    "        word_lists = {term: [] for term in search_terms}\n",
    "        transcript_path = os.path.join('/app/result/aligned_transcript_100/', video_name+'.word.srt')\n",
    "        if not os.path.exists(transcript_path):\n",
    "            continue\n",
    "        subs = pysrt.open(transcript_path)\n",
    "        for sub in subs:\n",
    "            for term in search_terms:\n",
    "                if term in sub.text:\n",
    "                    word_lists[term].append((time2second(tuple(sub.start)[:4])*video.fps, time2second(tuple(sub.end)[:4])*video.fps, 0))\n",
    "#         print(word_lists)\n",
    "        for term, value in word_lists.items():\n",
    "            if len(value) > 0:\n",
    "                word_intrvllists[term][video_id] = IntervalList(value)\n",
    "    \n",
    "    return  [ VideoIntervalCollection(intrvllist) for intrvllist in word_intrvllists.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T22:17:35.861285Z",
     "start_time": "2018-12-07T22:16:57.228129Z"
    }
   },
   "outputs": [],
   "source": [
    "# search words from caption index\n",
    "\n",
    "# Get extremely frequent words\n",
    "EXTREMELY_FREQUENT_WORDS = {\n",
    "    w.token for w in caption_util.frequent_words(LEXICON, 99.997)\n",
    "}\n",
    "\n",
    "# Split words into words to search by index and words to scan through documents for\n",
    "words = [word.upper() for word in sentence.split()]\n",
    "words_to_scan = set()\n",
    "words_to_search_by_index = set()\n",
    "for word in words:\n",
    "    if word in EXTREMELY_FREQUENT_WORDS:\n",
    "        words_to_scan.add(word)\n",
    "    else:\n",
    "        words_to_search_by_index.add(word)\n",
    "words_to_scan = list(words_to_scan)\n",
    "words_to_search_by_index = list(words_to_search_by_index)\n",
    "\n",
    "video_ids = list(person_intrvllists.keys())\n",
    "\n",
    "scanned_words = caption_scan_to_intrvllists(\n",
    "    scan_for_ngrams_in_parallel(words_to_scan, video_ids),\n",
    "    words_to_scan,\n",
    "    video_ids)\n",
    "searched_words = [\n",
    "    topic_search_to_intrvllists(topic_search([word], 0), video_ids)\n",
    "    for word in words_to_search_by_index \n",
    "]\n",
    "\n",
    "sentence_intrvllists = [\n",
    "    scanned_words[words_to_scan.index(word)]\n",
    "    if word in words_to_scan else\n",
    "    searched_words[words_to_search_by_index.index(word)]\n",
    "    for word in words\n",
    "]\n",
    "sentence_intrvlcol = [VideoIntervalCollection(intrvllist) for intrvllist in sentence_intrvllists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:58:58.564346Z",
     "start_time": "2018-12-08T00:58:33.189879Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search words from aligned transcript\n",
    "\n",
    "words = [word.upper() for word in sentence.split()]\n",
    "\n",
    "sentence_intrvlcol = scan_aligned_transcript_intrvllist(words, video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each word W, intersect its interval list with person P intervals to get P + W intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:52:27.254116Z",
     "start_time": "2018-12-08T00:52:27.203840Z"
    }
   },
   "outputs": [],
   "source": [
    "# person_with_sentence_intrvlcol = []\n",
    "# for i, word_intrvlcol in enumerate(sentence_intrvlcol):\n",
    "#     person_with_word_intrvlcol = person_intrvlcol.overlaps(word_intrvlcol)\n",
    "#     print(len(person_with_word_intrvlcol.get_allintervals()))\n",
    "#     if len(person_with_word_intrvlcol.get_allintervals()) == 0:\n",
    "#         print(\"Could not find instance of person {} with word {}\".format(person_name, words[i]))\n",
    "#     else:\n",
    "#         person_with_sentence_intrvlcol.append(person_with_word_intrvlcol)\n",
    "\n",
    "person_with_sentence_intrvlcol = sentence_intrvlcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all intervals where there is exactly one face on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:52:29.452916Z",
     "start_time": "2018-12-08T00:52:29.377261Z"
    }
   },
   "outputs": [],
   "source": [
    "from rekall.parsers import in_array, bbox_payload_parser\n",
    "from rekall.merge_ops import payload_plus\n",
    "from rekall.payload_predicates import payload_satisfies\n",
    "from rekall.list_predicates import length_exactly\n",
    "\n",
    "relevant_shots = set()\n",
    "for person_with_word_intrvlcol in person_with_sentence_intrvlcol:\n",
    "     for intrvllist in list(person_with_word_intrvlcol.get_allintervals().values()):\n",
    "        for interval in intrvllist.get_intervals():\n",
    "            relevant_shots.add(interval.get_payload())\n",
    "print(len(relevant_shots))\n",
    "            \n",
    "faces = Face.objects.filter(shot__in=list(relevant_shots)) \\\n",
    "        .annotate(video_id=F('shot__video_id')) \\\n",
    "        .annotate(min_frame=F('shot__min_frame')) \\\n",
    "        .annotate(max_frame=F('shot__max_frame'))\n",
    "\n",
    "# Materialize all the faces and load them into rekall with bounding box payloads\n",
    "# Then coalesce them so that all faces in the same frame are in the same interval\n",
    "# NOTE that this is slow right now since we're loading all faces!\n",
    "oneface_intrvlcol = VideoIntervalCollection.from_django_qs(\n",
    "    faces,\n",
    "    with_payload=in_array(\n",
    "        bbox_payload_parser(VideoIntervalCollection.django_accessor))\n",
    "    ).coalesce(payload_merge_op=payload_plus).filter(payload_satisfies(length_exactly(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T22:34:40.836520Z",
     "start_time": "2018-12-07T22:34:40.769415Z"
    }
   },
   "outputs": [],
   "source": [
    "len(oneface_intrvlcol.get_allintervals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each word W in sentence, intersect P with word intervals with one face intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T22:34:43.172745Z",
     "start_time": "2018-12-07T22:34:43.097026Z"
    }
   },
   "outputs": [],
   "source": [
    "person_with_sentence_alone_intrvlcol = []\n",
    "for i, person_with_word_intrvlcol in enumerate(person_with_sentence_intrvlcol):\n",
    "    person_alone_intrvlcol = person_with_word_intrvlcol.overlaps(oneface_intrvlcol)\n",
    "    print(len(person_alone_intrvlcol.get_allintervals()))\n",
    "    if len(person_alone_intrvlcol.get_allintervals()) == 0:\n",
    "        print(\"Could not find instance of person {} along with word {}\".format(person_name, words[i]))\n",
    "    else:\n",
    "        person_with_sentence_alone_intrvlcol.append(person_alone_intrvlcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T00:59:03.797473Z",
     "start_time": "2018-12-08T00:59:03.725928Z"
    }
   },
   "outputs": [],
   "source": [
    "supercut_intervals_all = []\n",
    "for i, person_with_word_alone_intrvlcol in enumerate(sentence_intrvlcol):\n",
    "    supercut_intervals = []\n",
    "    for video, intrvllist in person_with_word_alone_intrvlcol.intervals.items():\n",
    "        for interval in intrvllist.get_intervals():\n",
    "            supercut_intervals.append((video, interval.get_start(), interval.get_end()))\n",
    "    supercut_intervals_all.append(supercut_intervals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sample one element from each P + W alone interval list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T04:25:34.863972Z",
     "start_time": "2018-12-08T04:25:34.758474Z"
    }
   },
   "outputs": [],
   "source": [
    "supercut_intervals = [random.choice(intervals) for intervals in supercut_intervals_all]\n",
    "print(\"Supercut intervals: \", supercut_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the supercut intervals in Esper widget for debugging\n",
    "supercut_intrvllists = {}\n",
    "for video, start, end in supercut_intervals:\n",
    "    supercut_intrvllists[video] = IntervalList([(start, end, 0)])\n",
    "esper_widget(intrvllists_to_result(supercut_intrvllists,\n",
    "                                   video_order = [video for video, start, end in supercut_intervals]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T01:02:48.270448Z",
     "start_time": "2018-12-08T00:59:23.771532Z"
    }
   },
   "outputs": [],
   "source": [
    "# make supercut video \n",
    "supercut_path = '/app/result/supercut.mp4'\n",
    "local_cut_list = []\n",
    "local_cut_list_path = tempfile.NamedTemporaryFile(suffix='.txt').name.replace('tmp/', 'app/result/')\n",
    "flist = open(local_cut_list_path, 'w')\n",
    "for video_id, sfid, efid in supercut_intervals:\n",
    "    video = Video.objects.filter(id=video_id)[0]\n",
    "    filename = tempfile.NamedTemporaryFile(suffix='.mp4').name.replace('tmp/', 'app/result/')\n",
    "   \n",
    "    cmd = 'ffmpeg -y -i ' + '\\\"' + video.url() + '\\\"' + ' -async 1 '\n",
    "    cmd += '-ss {:s} -t {:s} '.format(second2time(sfid/video.fps, '.'), second2time((efid-sfid)/video.fps, '.'))\n",
    "    cmd += filename\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "    \n",
    "    local_cut_list.append(filename)\n",
    "    flist.write('file ' + filename + '\\n')\n",
    "flist.close()\n",
    "\n",
    "os.system('ffmpeg -y -f concat -safe 0 -i ' + local_cut_list_path + ' -c copy ' + supercut_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
