{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-Detector\" data-toc-modified-id=\"Introduction-Detector-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction Detector</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T20:53:19.819155Z",
     "start_time": "2018-11-13T20:52:52.579116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports. Run this first!\n",
    "\n",
    "from query.models import LabeledInterview, Video, FaceIdentity\n",
    "from esper.rekall import *\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.spatial_predicates import *\n",
    "from rekall.interval_list import IntervalList, Interval\n",
    "from esper.prelude import esper_widget\n",
    "from esper.captions import scan_for_ngrams_in_parallel\n",
    "\n",
    "sandbox_videos = [529, 763, 2648, 3459, 3730, 3769, 3952, 4143, 4611, 5281, 6185, 7262, 8220,\n",
    "    8697, 8859, 9215, 9480, 9499, 9901, 10323, 10335, 11003, 11555, 11579, 11792,\n",
    "    12837, 13058, 13141, 13247, 13556, 13827, 13927, 13993, 14482, 15916, 16215,\n",
    "    16542, 16693, 16879, 17458, 17983, 19882, 19959, 20380, 20450, 23181, 23184,\n",
    "    24193, 24847, 24992, 25463, 26386, 27188, 27410, 29001, 31378, 32472, 32996,\n",
    "    33004, 33387, 33541, 33800, 34359, 34642, 36755, 37107, 37113, 37170, 38275,\n",
    "    38420, 40203, 40856, 41480, 41725, 42756, 45472, 45645, 45655, 45698, 48140,\n",
    "    49225, 49931, 50164, 50561, 51175, 52075, 52749, 52945, 53355, 53684, 54377,\n",
    "    55711, 57384, 57592, 57708, 57804, 57990, 59122, 59398, 60186]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Detector\n",
    "\n",
    "We're going to write a query to look for introductions of guests and compare it to our labeled interviews from our sandbox. We'll look for the text \"JOINING US NOW\" and join that with intervals of a host on screen by themselves followed by a non-host on screen by themselves, or a non-host followed by a host, or a host on screen with a non-host at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T20:53:19.873972Z",
     "start_time": "2018-11-13T20:53:19.823017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ground-truth interviews\n",
    "\n",
    "interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(original=True)\n",
    "interviews_intrvllists = qs_to_intrvllists(interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T20:53:19.935092Z",
     "start_time": "2018-11-13T20:53:19.877303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns precision, recall, precision_per_item, recall_per_item\n",
    "def compute_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    total_query_time = 0\n",
    "    total_query_segments = 0\n",
    "    total_ground_truth_time = 0\n",
    "    total_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        total_query_time += query_intrvllists[video].coalesce().get_total_time()\n",
    "        total_query_segments += query_intrvllists[video].size()\n",
    "    for video in ground_truth_intrvllists:\n",
    "        total_ground_truth_time += ground_truth_intrvllists[video].coalesce().get_total_time()\n",
    "        total_ground_truth_segments += ground_truth_intrvllists[video].size()\n",
    "        \n",
    "    total_overlap_time = 0\n",
    "    overlapping_query_segments = 0\n",
    "    overlapping_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        if video in ground_truth_intrvllists:\n",
    "            query_list = query_intrvllists[video]\n",
    "            gt_list = ground_truth_intrvllists[video]\n",
    "            \n",
    "            total_overlap_time += query_list.overlaps(gt_list).coalesce().get_total_time()\n",
    "            overlapping_query_segments += query_list.filter_against(gt_list, predicate=overlaps()).size()\n",
    "            overlapping_ground_truth_segments += gt_list.filter_against(query_list, predicate=overlaps()).size()\n",
    "    \n",
    "    if total_query_time == 0:\n",
    "        precision = 1.0\n",
    "        precision_per_item = 1.0\n",
    "    else:\n",
    "        precision = total_overlap_time / total_query_time\n",
    "        precision_per_item = overlapping_query_segments / total_query_segments\n",
    "    \n",
    "    if total_ground_truth_time == 0:\n",
    "        recall = 1.0\n",
    "        recall_per_item = 1.0\n",
    "    else:\n",
    "        recall = total_overlap_time / total_ground_truth_time\n",
    "        recall_per_item = overlapping_ground_truth_segments / total_ground_truth_segments\n",
    "    \n",
    "    return precision_per_item, recall_per_item\n",
    "\n",
    "def print_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    precision_per_item, recall_per_item = compute_statistics(\n",
    "        query_intrvllists, ground_truth_intrvllists)\n",
    "\n",
    "    print(\"Precision Per Item: \", precision_per_item)\n",
    "    print(\"Recall Per Item: \", recall_per_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T20:55:47.319448Z",
     "start_time": "2018-11-13T20:53:19.940200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Host face bboxes\n",
    "\n",
    "identities = FaceIdentity.objects.filter(face__shot__video_id__in=sandbox_videos)\n",
    "hosts = identities.filter(face__is_host=True) \\\n",
    "    .annotate(video_id=F(\"face__shot__video_id\")) \\\n",
    "    .annotate(shot_id=F(\"face__shot_id\")) \\\n",
    "    .annotate(min_frame=F(\"face__shot__min_frame\")) \\\n",
    "    .annotate(max_frame=F(\"face__shot__max_frame\")) \\\n",
    "    .annotate(bbox_x1=F(\"face__bbox_x1\")) \\\n",
    "    .annotate(bbox_y1=F(\"face__bbox_y1\")) \\\n",
    "    .annotate(bbox_x2=F(\"face__bbox_x2\")) \\\n",
    "    .annotate(bbox_y2=F(\"face__bbox_y2\"))\n",
    "\n",
    "vids = {}\n",
    "for face in hosts:\n",
    "    video_id = face.video_id\n",
    "    shot_id = face.shot_id\n",
    "    if video_id not in vids:\n",
    "        vids[video_id] = {}\n",
    "    if shot_id not in vids[video_id]:\n",
    "        vids[video_id][shot_id] = {'min_frame': face.min_frame, 'max_frame': face.max_frame, 'objects': []}\n",
    "    new_face = {'x1': face.bbox_x1, 'y1': face.bbox_y1, 'x2': face.bbox_x2, 'y2': face.bbox_y2}\n",
    "    if new_face not in vids[video_id][shot_id]['objects']:\n",
    "        vids[video_id][shot_id]['objects'].append(\n",
    "            {'x1': face.bbox_x1, 'y1': face.bbox_y1, 'x2': face.bbox_x2, 'y2': face.bbox_y2})\n",
    "\n",
    "host_intrvllists = {}\n",
    "for video in vids:\n",
    "    host_intrvllists[video] = IntervalList([(\n",
    "        shot['min_frame'], \n",
    "        shot['max_frame'],\n",
    "        {\n",
    "            'type': 'bbox_list',\n",
    "            'objects': shot['objects']\n",
    "        }) for shot in list(vids[video].values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T20:59:09.366299Z",
     "start_time": "2018-11-13T20:55:47.323059Z"
    }
   },
   "outputs": [],
   "source": [
    "# All faces, in IntervalList form\n",
    "\n",
    "# Let's test out some of the spatial predicates by reproducing the panels query\n",
    "from query.models import Face\n",
    "faces = Face.objects.annotate(video_id=F('shot__video_id')) \\\n",
    "        .filter(video_id__in=sandbox_videos) \\\n",
    "        .annotate(min_frame=F('shot__min_frame')) \\\n",
    "        .annotate(max_frame=F('shot__max_frame'))\n",
    "vids = {}\n",
    "for face in faces:\n",
    "    video_id = face.video_id\n",
    "    shot_id = face.shot_id\n",
    "    if video_id not in vids:\n",
    "        vids[video_id] = {}\n",
    "    if shot_id not in vids[video_id]:\n",
    "        vids[video_id][shot_id] = {'min_frame': face.min_frame, 'max_frame': face.max_frame, 'objects': []}\n",
    "    new_face = {'x1': face.bbox_x1, 'y1': face.bbox_y1, 'x2': face.bbox_x2, 'y2': face.bbox_y2}\n",
    "    if new_face not in vids[video_id][shot_id]['objects']:\n",
    "        vids[video_id][shot_id]['objects'].append(\n",
    "            {'x1': face.bbox_x1, 'y1': face.bbox_y1, 'x2': face.bbox_x2, 'y2': face.bbox_y2})\n",
    "\n",
    "faces_intrvllists = {}\n",
    "for video in vids:\n",
    "    faces_intrvllists[video] = IntervalList([(\n",
    "        shot['min_frame'], \n",
    "        shot['max_frame'],\n",
    "        {\n",
    "            'type': 'bbox_list',\n",
    "            'objects': shot['objects']\n",
    "        }) for shot in list(vids[video].values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:20:25.728724Z",
     "start_time": "2018-11-13T23:20:24.225981Z"
    }
   },
   "outputs": [],
   "source": [
    "# All intervals with \"JOINING US NOW\"\n",
    "terms = [\n",
    "    'JOINING US', \n",
    "    'JOINING ME', \n",
    "    'HERE WITH ME', \n",
    "    'JOINS US',\n",
    "    'JOINS ME',\n",
    "    'FOR BEING HERE',\n",
    "    'SITTING TWO FEET AWAY',\n",
    "    'BRING IN',\n",
    "    'JOINED NOW'\n",
    "]\n",
    "captions = {}\n",
    "scan_results = caption_scan_to_intrvllists(\n",
    "    scan_for_ngrams_in_parallel(terms, video_ids=sandbox_videos),\n",
    "    terms, video_ids=sandbox_videos, dilation=10\n",
    ")\n",
    "for result in scan_results:\n",
    "    for video in result:\n",
    "        if video in captions:\n",
    "            captions[video] = captions[video].set_union(result[video]).coalesce()\n",
    "        else:\n",
    "            captions[video] = result[video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:42:14.359122Z",
     "start_time": "2018-11-13T23:42:14.312674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statistics for just captions\n",
    "print_statistics(captions, interviews_intrvllists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:30:15.013380Z",
     "start_time": "2018-11-13T23:30:13.639020Z"
    }
   },
   "outputs": [],
   "source": [
    "anti_terms = [\n",
    "    'PANEL',\n",
    "    'CORRESPONDENT',\n",
    "    'ANALYST'\n",
    "]\n",
    "anti_captions = {}\n",
    "for result in caption_scan_to_intrvllists(\n",
    "    scan_for_ngrams_in_parallel(anti_terms, video_ids=sandbox_videos),\n",
    "    anti_terms, video_ids=sandbox_videos, dilation=30):\n",
    "    for video in result:\n",
    "        if video in anti_captions:\n",
    "            anti_captions[video] = anti_captions[video].set_union(result[video]).coalesce()\n",
    "        else:\n",
    "            anti_captions[video] = result[video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:43:42.970941Z",
     "start_time": "2018-11-13T23:43:42.917999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statistics for captions minus anti-captions\n",
    "captions_without_anti_captions = {}\n",
    "for video in captions:\n",
    "    if video not in anti_captions:\n",
    "        captions_without_anti_captions[video] = captions[video]\n",
    "    else:\n",
    "        captions_without_anti_captions[video] = captions[video].minus(\n",
    "            captions[video].filter_against(anti_captions[video], predicate=overlaps())\n",
    "        )\n",
    "print_statistics(captions_without_anti_captions, interviews_intrvllists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:43:56.988413Z",
     "start_time": "2018-11-13T23:43:51.995535Z"
    }
   },
   "outputs": [],
   "source": [
    "# for debugging later\n",
    "one_host_lists = {}\n",
    "non_host_alone_lists = {}\n",
    "host_with_guest_lists = {}\n",
    "host_alone_lists = {}\n",
    "\n",
    "# Introductions\n",
    "introductions = {}\n",
    "for video in captions:\n",
    "    if (video not in list(host_intrvllists.keys()) or\n",
    "        video not in list(faces_intrvllists.keys())):\n",
    "        continue\n",
    "    caption = captions[video]\n",
    "    hosts = host_intrvllists[video]\n",
    "    faces = faces_intrvllists[video]\n",
    "\n",
    "    one_host = hosts.filter(exactly(1)).coalesce()\n",
    "    non_host_alone = faces.filter(exactly(1)).minus(one_host).dilate(30).coalesce().dilate(-30)\n",
    "    host_with_guest = faces.filter(exactly(2)).overlaps(one_host)\n",
    "    host_alone = one_host.overlaps(faces.filter(exactly(1)))\n",
    "    \n",
    "    one_host_lists[video] = one_host\n",
    "    non_host_alone_lists[video] = non_host_alone\n",
    "    host_with_guest_lists[video] = host_with_guest\n",
    "    host_alone_lists[video] = host_alone\n",
    "    \n",
    "    intros = caption.merge(\n",
    "        host_with_guest.set_union(\n",
    "            host_alone.merge(\n",
    "                non_host_alone,\n",
    "                predicate=or_pred(before(max_dist=30), after(max_dist=30)))\n",
    "        ).dilate(30),\n",
    "        predicate=overlaps()\n",
    "    ).coalesce().map(\n",
    "        lambda intrvl: Interval(intrvl.start, intrvl.end + 6000, intrvl.payload)\n",
    "    )\n",
    "    \n",
    "    if video in anti_captions:\n",
    "        intros = intros.minus(intros.filter_against(anti_captions[video], predicate=overlaps()))\n",
    "    \n",
    "    if intros.size() > 0:\n",
    "        introductions[video] = intros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:44:04.997020Z",
     "start_time": "2018-11-13T23:44:04.954413Z"
    }
   },
   "outputs": [],
   "source": [
    "# add visual filters\n",
    "print_statistics(introductions, interviews_intrvllists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of these results in depth. You can use the following code to comment or uncomment various different intermediate results used throughout our query. By default, we have our query results in black, ground truth in red, and the caption results in orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:39:28.274175Z",
     "start_time": "2018-11-13T23:39:26.995690Z"
    }
   },
   "outputs": [],
   "source": [
    "result = intrvllists_to_result(introductions, color='black')\n",
    "add_intrvllists_to_result(result, interviews_intrvllists, color='red')\n",
    "# add_intrvllists_to_result(result, host_intrvllists, color='blue')\n",
    "# add_intrvllists_to_result(result, one_host_lists, color='purple')\n",
    "# add_intrvllists_to_result(result, non_host_alone_lists, color='green')\n",
    "add_intrvllists_to_result(result, captions, color='orange')\n",
    "# add_intrvllists_to_result(result, anti_captions, color='yellow')\n",
    "esper_widget(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our visual filtering removes some cases with multiple interviewers, which lowers our recall. But it also removes some other false positives, particularly of pa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
