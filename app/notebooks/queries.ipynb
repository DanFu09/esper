{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internet Archive TV news analysis <a class=\"tocSkip\">\n",
    "This document contains the code and corresponding visualizations/statistics for answering various questions about the TV news dataset.\n",
    "\n",
    "All times shown are H*:MM:SS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from query.datasets.prelude import *\n",
    "import query.datasets.tvnews.queries as queries\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import IPython\n",
    "import shutil\n",
    "\n",
    "rudecarnie = Labeler.objects.get(name='rudecarnie')\n",
    "mtcnn = Labeler.objects.get(name='mtcnn')\n",
    "\n",
    "def format_time(seconds):\n",
    "    return '{}:{:02d}:{:02d}'.format(seconds/3600, seconds/60 % 60, seconds % 60)\n",
    "\n",
    "def show_df(table, ordering, clear=True):\n",
    "    if clear:\n",
    "        IPython.display.clear_output()\n",
    "    return pd.DataFrame(table)[ordering]\n",
    "\n",
    "spark = SparkSession.builder.master(\"spark://spark:7077\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "def qs_to_df(qs):\n",
    "    qs.save_to_csv('tmp')\n",
    "    return spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/app/pg/tmp.csv\")\n",
    "    \n",
    "def dicts_to_df(ds):\n",
    "    return spark.createDataFrame(sc.parallelize(data).map(lambda d: Row(**d)))\n",
    "    \n",
    "PREFIX = 'data'\n",
    "def spark_load(key, fn, force=False):\n",
    "    key = '{}/{}'.format(PREFIX, key)\n",
    "    has_dir = os.path.isdir(key)\n",
    "    if not has_dir or force:\n",
    "        if force and has_dir:\n",
    "            shutil.rmtree(key)\n",
    "        df = fn()\n",
    "        df.write.save(key)\n",
    "        return df\n",
    "    else:\n",
    "        with Timer('Reading data'):\n",
    "            return spark.read.load(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#All-videos\" data-toc-modified-id=\"All-videos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>All videos</a></span></li><li><span><a href=\"#Videos-by-channel\" data-toc-modified-id=\"Videos-by-channel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Videos by channel</a></span></li><li><span><a href=\"#Videos-by-show\" data-toc-modified-id=\"Videos-by-show-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Videos by show</a></span></li><li><span><a href=\"#Videos-by-time-of-day\" data-toc-modified-id=\"Videos-by-time-of-day-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Videos by time of day</a></span></li></ul></li><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gender</a></span><ul class=\"toc-item\"><li><span><a href=\"#Detector-accuracy\" data-toc-modified-id=\"Detector-accuracy-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Detector accuracy</a></span></li><li><span><a href=\"#Male-vs.-female-faces\" data-toc-modified-id=\"Male-vs.-female-faces-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Male vs. female faces</a></span></li><li><span><a href=\"#Male-vs.-female-faces-across-channels\" data-toc-modified-id=\"Male-vs.-female-faces-across-channels-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Male vs. female faces across channels</a></span></li><li><span><a href=\"#Male-vs.-female-faces-across-shows\" data-toc-modified-id=\"Male-vs.-female-faces-across-shows-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Male vs. female faces across shows</a></span></li><li><span><a href=\"#Male-vs.-female-faces-across-time-of-day\" data-toc-modified-id=\"Male-vs.-female-faces-across-time-of-day-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Male vs. female faces across time of day</a></span></li><li><span><a href=\"#Male-vs.-female-faces-across-topics\" data-toc-modified-id=\"Male-vs.-female-faces-across-topics-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Male vs. female faces across topics</a></span></li><li><span><a href=\"#Male-vs.-female-faces-in-panels\" data-toc-modified-id=\"Male-vs.-female-faces-in-panels-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Male vs. female faces in panels</a></span></li></ul></li><li><span><a href=\"#Pose\" data-toc-modified-id=\"Pose-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pose</a></span></li><li><span><a href=\"#Misc\" data-toc-modified-id=\"Misc-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Misc</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-people-in-frame\" data-toc-modified-id=\"Number-of-people-in-frame-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Number of people in frame</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def load_videos():\n",
    "    return qs_to_df(\n",
    "        Video.objects.all().annotate(hour=Extract('time', 'hour')) \\\n",
    "        .values('num_frames', 'fps', 'show_id', 'channel_id', 'hour'))\n",
    "videos = spark_load('videos', load_videos)\n",
    "\n",
    "def video_stats(key, labels):\n",
    "    times = videos.select(\"*\").rdd.map(lambda v: (v[key] if key is not None else 0, v['num_frames'] / v['fps']))\n",
    "    counts = times.countByKey()\n",
    "    durations = {k: v for k, v in times.aggregateByKey(0, (lambda a, b: a + b), (lambda a, b: a + b), 8).collect()}\n",
    "    return [{\n",
    "        'label': label['name'],\n",
    "        'count': counts[label['id']],\n",
    "        'duration': format_time(int(durations[label['id']])),\n",
    "        'avg_duration': format_time(int(durations[label['id']] / counts[label['id']]))\n",
    "    } for label in labels]\n",
    "\n",
    "ds_ordering = ['label', 'count', 'duration', 'avg_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## All videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats(None, [{'id': 0, 'name': 'whole dataset'}]),\n",
    "    ds_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats('channel_id', list(Channel.objects.all().values('id', 'name'))),\n",
    "    ds_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by show\n",
    "\"Situation Room with Wolf Blitzer\" and \"Special Report with Bret Baier\" were ingested as 60 10-minute segments each, whereas the other shows have 10 â‰¥1 hour segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats('show_id', list(Show.objects.all().values('id', 'name'))),\n",
    "    ds_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by time of day\n",
    "Initial selection of videos was only prime-time, so between 4pm-11pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [r['hour'] for r in \n",
    "         Video.objects.annotate(hour=Extract('time', 'hour')).distinct('hour').order_by('hour').values('hour')]\n",
    "\n",
    "def format_hour(h):\n",
    "    if h <= 12:\n",
    "        return '{} AM'.format(h)\n",
    "    else:\n",
    "        return '{} PM'.format(h-12)\n",
    "    \n",
    "show_df(\n",
    "    video_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours]),\n",
    "    ds_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Gender\n",
    "These queries analyze the distribution of men vs. women across a number of axes. We use faces detected by [MTCNN](https://github.com/kpzhang93/MTCNN_face_detection_alignment/) and gender detected by [rude-carnie](https://github.com/dpressel/rude-carnie). We only consider faces with a height > 20% of the frame to eliminate people in the background. Face detection was run at 2 frames per second on all videos. If a person's face is detected, we count that as 0.5 seconds of screen time. Total screen times reported double-count frames depending on the number of people in them, e.g. 2 women in one frame is 1 second of screen time.\n",
    "\n",
    "Remaining questions:\n",
    "* No. of unique women vs. unique men (identity-major)\n",
    "* No. of frames w/ men vs. women (frame-major)\n",
    "\n",
    "Add data:\n",
    "* Sunday morning news\n",
    "* General morning news shows (e.g. Today Show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def load_genders():\n",
    "    return qs_to_df(FaceGender.objects \\\n",
    "        .annotate(height=F('face__bbox_y2') - F('face__bbox_y1')) \\\n",
    "        .filter(labeler=rudecarnie, face__labeler=mtcnn, height__gte=0.2) \\\n",
    "        .annotate(duration=Cast(\n",
    "            (F('face__shot__max_frame') - F('face__shot__min_frame')) / F('face__shot__video__fps'),\n",
    "            models.FloatField())) \\\n",
    "        .values('gender', 'duration', 'face__person__frame__video__channel', 'face__person__frame__video__show'))\n",
    "genders = spark_load('genders', load_genders, force=True)\n",
    "\n",
    "def calc_derived_gender_fields(row):\n",
    "    total = float(row['M'] + row['F'])\n",
    "    if total > 0:\n",
    "        row['M_percent'] = '{:.0f}%'.format(row['M'] / total * 100)\n",
    "        row['M_screentime'] = format_time(row['M'] / 2)\n",
    "        row['F_percent'] = '{:.0f}%'.format(row['F'] / total * 100)\n",
    "        row['F_screentime'] = format_time(row['F'] / 2)\n",
    "    \n",
    "def filter_gender(key, labels):\n",
    "    times = genders.select(\"*\").rdd.map(lambda g: ((g[key] if key is not None else 0, g['gender']), g['duration']))\n",
    "    counts = times.countByKey()\n",
    "    durations = {k: v for k, v in times.aggregateByKey(0, (lambda a, b: a + b), (lambda a, b: a + b), 8).collect()}\n",
    "        \n",
    "    print(counts)\n",
    "    print(durations)\n",
    "    \n",
    "#     genders = list(Gender.objects \\\n",
    "#         .annotate(count=Subquery(\n",
    "#             face_filter(FaceGender.objects \\\n",
    "#             .filter(gender=OuterRef('pk'), labeler=rudecarnie, face__labeler=mtcnn) \\\n",
    "#             .annotate(height=F('face__bbox_y2') - F('face__bbox_y1')) \\\n",
    "#             .filter(height__gte=0.2)) \\\n",
    "#             .values('gender').annotate(count=Count('gender')) \\\n",
    "#             .values('count'), models.IntegerField())).values('name', 'count'))\n",
    "#     def zero_bad_val(n):\n",
    "#         if n is None or math.isnan(float(n)):\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return n\n",
    "#     df = pd.DataFrame(genders)\n",
    "#     row = {\n",
    "#         'M': int(zero_bad_val(df.loc[df['name'] == 'M']['count'].values[0])),\n",
    "#         'F': int(zero_bad_val(df.loc[df['name'] == 'F']['count'].values[0] or 0)),\n",
    "#     }\n",
    "#     calc_derived_gender_fields(row)\n",
    "\n",
    "#     total_length = int(sum([v['length'] for v in video_filter(Video.objects) \\\n",
    "#         .annotate(length=Sum(Cast(F('num_frames'), models.FloatField()) / F('fps'))) \\\n",
    "#         .values('length')]))\n",
    "#     row['length'] = format_time(total_length)\n",
    "    \n",
    "#     return row\n",
    "\n",
    "ordering = ['length', 'M', 'M_percent', 'M_screentime', 'F', 'F_percent', 'F_screentime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector accuracy\n",
    "* Handlabels are just for the \"main person in the frame\" (instruction to labelers), so precision is expected to be low.\n",
    "* Recall for face and gender detectors is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# TODO: add data table for handlabeled subset\n",
    "# TODO: deal with negative case\n",
    "# TODO: how many errors on women vs. men?\n",
    "\n",
    "face_labeler = Labeler.objects.get(name='mtcnn')\n",
    "hand_labeler = Labeler.objects.get(name='handlabeled')\n",
    "gender_labeler = Labeler.objects.get(name='rudecarnie')\n",
    "\n",
    "face_tp = 0\n",
    "face_fp = 0\n",
    "face_fn = 0\n",
    "\n",
    "gender_t = 0\n",
    "gender_f = 0\n",
    "\n",
    "handlabeled = [t['person__frame__video__id'] for t in Face.objects \\\n",
    "    .filter(labeler=hand_labeler) \\\n",
    "    .values('person__frame__video__id') \\\n",
    "    .distinct('person__frame__video__id') \\\n",
    "    .values('person__frame__video__id')]\n",
    "\n",
    "for i, video in enumerate(Video.objects.filter(id__in=handlabeled)):\n",
    "    frames_with_faces = Frame.objects \\\n",
    "        .filter(video=video) \\\n",
    "        .annotate(c=Subquery(\n",
    "            Face.objects.filter(person__frame=OuterRef('pk')) \\\n",
    "            .values('person__frame') \\\n",
    "            .annotate(c=Count('*')).values('c'))) \\\n",
    "        .filter(c__gt=0)\n",
    "    #print(i, video.path)\n",
    "    for frame in frames_with_faces:\n",
    "        handlabeled_faces = list(Face.objects.filter(person__frame=frame, labeler=hand_labeler))\n",
    "        autolabeled_faces = list(Face.objects.filter(person__frame=frame, labeler=face_labeler))\n",
    "        \n",
    "        for autoface in autolabeled_faces:\n",
    "            good = np.where(np.array([bbox_iou(autoface, handface) > 0.5 for handface in handlabeled_faces]))\n",
    "            index = good[0][0] if len(good[0]) > 0 else None\n",
    "            if index is not None:\n",
    "                face_tp += 1\n",
    "                auto_gender = FaceGender.objects.get(face=autoface)\n",
    "                hand_gender = FaceGender.objects.get(face=handlabeled_faces[index])\n",
    "                if auto_gender.gender == hand_gender.gender:\n",
    "                    gender_t += 1\n",
    "                else:\n",
    "                    gender_f += 1\n",
    "            else:\n",
    "                face_fp += 1\n",
    "            \n",
    "        for handface in handlabeled_faces:\n",
    "            good = any([bbox_iou(autoface, handface) > 0.5 for autoface in autolabeled_faces])\n",
    "            if not good:\n",
    "                face_fn += 1\n",
    "    \n",
    "print('Face precision: {:.2f}'.format(face_tp / float(face_tp + face_fp)))\n",
    "print('Face recall: {:.2f}'.format(face_tp / float(face_tp + face_fn)))\n",
    "print('Gender accuracy: {:.2f}'.format(gender_t / float(gender_t + gender_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces\n",
    "* Male:female ratio is 2:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: have frame-major instead of face-major, e.g. split into male-only, female-only, mixed\n",
    "\n",
    "show_df([filter_gender(lambda qs: qs, lambda qs: qs)], ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces across channels\n",
    "* No meaningful differnce in gender balance between CNN and FOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute t-test\n",
    "counts = []\n",
    "for channel in tqdm(Channel.objects.all()):\n",
    "    c = filter_gender(\n",
    "        lambda qs: qs.filter(face__person__frame__video__channel=channel), \n",
    "        lambda qs: qs.filter(channel=channel))\n",
    "    c['channel'] = channel.name\n",
    "    counts.append(c)\n",
    "    \n",
    "show_df(counts, ['channel'] + ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces across shows\n",
    "* Female-hosted shows (Poppy Harlow, Gretchen Carlson) have higher female percentages than any other show.\n",
    "* Farreed Zakaria and Bret Baier are most male-imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts = []\n",
    "for show in tqdm(Show.objects.all()):\n",
    "    c = filter_gender(\n",
    "        lambda qs: qs.filter(face__person__frame__video__show=show),\n",
    "        lambda qs: qs.filter(show=show))\n",
    "    c['show'] = show.name\n",
    "    counts.append(c)\n",
    "    \n",
    "show_df(counts, ['show'] + ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces across time of day\n",
    "* No meaningful trend in gender balance across time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours = Video.objects.annotate(hour=Extract('time', 'hour')).distinct('hour').order_by('hour').values('hour')\n",
    "\n",
    "counts = []\n",
    "for hour in hours:\n",
    "    hour = hour['hour']\n",
    "    c = filter_gender(\n",
    "        lambda qs: qs.filter(face__person__frame__video__time__hour=hour),\n",
    "        lambda qs: qs.filter(time__hour=hour))\n",
    "    c['hour'] = datetime.time(hour, 0).strftime('%I %p')\n",
    "    counts.append(c)\n",
    "\n",
    "show_df(counts, ['hour'] + ordering)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces across topics\n",
    "* Topic labeling is not robust enough to draw conclusions yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_labeler = Labeler.objects.get(name='word2vec')\n",
    "all_counts = []\n",
    "for topic in Topic.objects.all():\n",
    "    topic_counts = {'topic': topic.name, 'female': 0, 'male': 0, 'length': 0}\n",
    "    for track in TopicTrack.objects.filter(topic=topic, labeler=track_labeler).select_related('video'):\n",
    "        track_counts = filter_gender(\n",
    "            lambda qs: qs.filter(\n",
    "                face__person__frame__video=track.video, \n",
    "                face__person__frame__number__gte=track.min_frame, \n",
    "                face__person__frame__number__lte=track.max_frame),\n",
    "            lambda qs: qs.filter(id=track.video.id)\n",
    "        )\n",
    "        topic_counts['male'] += track_counts['male']\n",
    "        topic_counts['female'] += track_counts['female']\n",
    "        topic_counts['length'] += int((track.max_frame - track.min_frame) / track.video.fps)\n",
    "        \n",
    "    calc_derived_gender_fields(topic_counts)\n",
    "    topic_counts['length'] = format_time(topic_counts['length'])\n",
    "    all_counts.append(topic_counts)\n",
    "    \n",
    "show_df(all_counts, ['topic'] + ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces in panels\n",
    "* Smaller percentage of women in panels relative to overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: female-domainated situations?\n",
    "# TODO: slice this on # of people in the panel\n",
    "# TODO: small visualization that shows sample of segments\n",
    "# TODO: panels w/ majority male vs. majority female\n",
    "\n",
    "print('Computing panels')\n",
    "panels = queries.panels()\n",
    "print('Computing gender stats')\n",
    "frame_ids = [frame.id for (frame, _) in panels]\n",
    "counts = filter_gender(lambda qs: qs.filter(face__person__frame__id__in=frame_ids), lambda qs: qs)\n",
    "show_df([counts], ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Pose\n",
    "* Animatedness of people (specifically hosts)\n",
    "    * e.g. Rachel Maddow vs. others\n",
    "    * Pick 3-4 hours of a few specific hosts, compute dense poses and tracks\n",
    "    * Devise acceleration metric\n",
    "* More gesturing on heated exchanges?\n",
    "* Sitting vs. standing\n",
    "* Repeated gestures (debates vs. state of the union)\n",
    "* Head/eye orientation (are people looking at each other?)\n",
    "* Camera orientation (looking at someone from above/below)\n",
    "* How much are the hosts facing each other\n",
    "* Quantify aggressive body language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Number of people in frame\n",
    "* Surprisingly, a plurality of frames have no detected faces in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Func\n",
    "frames = Frame.objects.annotate(c=Subquery(\n",
    "    Face.objects.filter(person__frame=OuterRef('pk'), labeler=mtcnn) \\\n",
    "    .values('person__frame') \\\n",
    "    .annotate(c=Count('*')) \\\n",
    "    .values('c'), models.IntegerField())) \\\n",
    "    .annotate(mod=F('number') % Cast(Func(F('video__fps'), function='ROUND'), models.IntegerField())) \\\n",
    "    .filter(mod=0) \\\n",
    "    .values('c')\n",
    "\n",
    "all_counts = [f['c'] or 0 for f in frames]\n",
    "ax = plt.figure(figsize=(16, 6)).add_subplot(111)\n",
    "bins = range(10)\n",
    "arr = ax.hist(all_counts, bins=bins, align='left', rwidth=0.75)\n",
    "for i in bins:\n",
    "    if i == 9: continue\n",
    "    ax.text(arr[1][i]-0.15, arr[0][i], str(int(arr[0][i])))\n",
    "ax.set_xticks(bins)\n",
    "ax.set_xticklabels(bins)\n",
    "ax.set_xlabel(\"Number of people in frame\")\n",
    "_ = ax.set_ylabel(\"Number of frames\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
