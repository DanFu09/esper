{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:09:14.081370Z",
     "start_time": "2019-03-06T07:09:10.833780Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from query.models import Shot\n",
    "from django.db.models import Value\n",
    "from django.db.models.fields import IntegerField\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "\n",
    "def convert_to_1d_collection(collection):\n",
    "    from rekall.interval_list import Interval\n",
    "    video_map = collection.get_grouped_intervals()\n",
    "    return VideoIntervalCollection({vid: [Interval(\n",
    "        i.t[0], i.t[1], i.payload) for i in video_map[vid].get_intervals()] for vid in video_map})\n",
    "\n",
    "def display_result(collection_1d, display_payload=False):\n",
    "    from esper.rekall import intrvllists_to_result_bbox\n",
    "    from esper.rekall import intrvllists_to_result_with_objects\n",
    "    if display_payload:\n",
    "        results = intrvllists_to_result_with_objects(collection_1d.get_allintervals(), \n",
    "            lambda p, v: p, limit=1000, stride=1)\n",
    "    else:\n",
    "        results = intrvllists_to_result_with_objects(collection_1d.get_allintervals(), \n",
    "            lambda p, v:[], limit=1000, stride=1)\n",
    "    return esper_widget(results,\n",
    "            crop_bboxes=False, show_middle_frame=False, disable_captions=True,\n",
    "            results_per_page=25, jupyter_keybindings=True)\n",
    "\n",
    "# Takes a function from arg -> IntervalSet3D, returns a function that runs on batches:\n",
    "# [arg] -> DomainIntervalCollection where the domain key is arg.\n",
    "def in_sequence(func):\n",
    "    def fn(args):\n",
    "        return DomainIntervalCollection({\n",
    "            arg: func(arg) for arg in args\n",
    "        })\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermione in the Middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T01:32:44.377410Z",
     "start_time": "2019-03-06T01:32:28.918538Z"
    }
   },
   "outputs": [],
   "source": [
    "def hermione_in_the_middle(vids=None):\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X\n",
    "    from rekall.temporal_predicates import before, overlaps_before\n",
    "    from rekall.bbox_predicates import height_at_least, same_value, same_height, left_of\n",
    "    from query.models import FaceCharacterActor, Video\n",
    "    \n",
    "    MIN_FACE_HEIGHT = 0.25\n",
    "    EPSILON = 0.15\n",
    "    NAMES = [ 'ron weasley', 'hermione granger', 'harry potter' ]\n",
    "    \n",
    "    if vids is None:\n",
    "        vids = [v.id for v in Video.objects.filter(name__contains='harry potter')]\n",
    "    \n",
    "    faces_with_character_actor_qs = FaceCharacterActor.objects.annotate(\n",
    "        min_frame=F('face__frame__number'),\n",
    "        max_frame=F('face__frame__number'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        bbox_x1=F('face__bbox_x1'),\n",
    "        bbox_y1=F('face__bbox_y1'),\n",
    "        bbox_x2=F('face__bbox_x2'),\n",
    "        bbox_y2=F('face__bbox_y2'),\n",
    "        character_name=F('characteractor__character__name')\n",
    "    ).filter(face__frame__video_id__in=vids)\n",
    "    \n",
    "    total = faces_with_character_actor_qs.count()\n",
    "    \n",
    "    schema = DomainIntervalCollection.django_bbox_default_schema()\n",
    "    schema['payload'] = 'character_name'    \n",
    "    all_faces = DomainIntervalCollection.from_django_qs(faces_with_character_actor_qs, schema, progress=True,\n",
    "                                                    total=total)\n",
    "    frames_with_faces = all_faces.group_by_time()\n",
    "    \n",
    "    def name_is(name):\n",
    "        return lambda f: f.payload == name\n",
    "    def start_before():\n",
    "        return or_preds(overlaps_before(), before())\n",
    "    def in_order():\n",
    "        return lambda a,b,c: start_before()(a,b) and start_before()(b,c)\n",
    "    def rev_order():\n",
    "        return lambda *args: in_order()(*args[::-1])\n",
    "    \n",
    "    pattern = [\n",
    "        ([\"harry\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[2])]),\n",
    "        ([\"ron\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[0])]),\n",
    "        ([\"hermione\"], [XY(height_at_least(MIN_FACE_HEIGHT)), name_is(NAMES[1])]),\n",
    "        ([\"harry\", \"ron\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"ron\", \"hermione\"], [XY(same_value('y1', epsilon=EPSILON)), XY(same_height(epsilon=EPSILON))]),\n",
    "        ([\"harry\",\"hermione\", \"ron\"], [X(or_preds(in_order(), rev_order()))])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<character>>\n",
    "    final = frames_with_faces.filter(P(matches_pattern(pattern, exact=True)))\n",
    "    return final\n",
    "\n",
    "def payload_to_vgrid_objects(faces):\n",
    "    from query.models import Character\n",
    "    def intrvl_to_obj(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1],\n",
    "            'character_id': Character.objects.get(name=face.payload).id\n",
    "        }\n",
    "    def update(acc, face):\n",
    "        acc.append(intrvl_to_obj(face))\n",
    "        return acc\n",
    "    return faces.fold(update, [])\n",
    "    \n",
    "answer = hermione_in_the_middle()\n",
    "print(\"Query Done. Preparing for VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:31:58.771059Z",
     "start_time": "2019-03-06T07:31:39.135913Z"
    }
   },
   "outputs": [],
   "source": [
    "def kissing(vids):\n",
    "    from query.models import Face\n",
    "    from rekall.interval_set_3d import Interval3D, IntervalSet3D\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y,and_preds\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps, overlaps_before, before\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.captions import get_all_segments\n",
    "    from tqdm import tqdm as tqdm\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.4\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.7\n",
    "    MIN_FACE_ANGLE = 0.2\n",
    "    \n",
    "    def get_landmarks(faces):\n",
    "        ids = [face.payload for face in faces.get_intervals()]\n",
    "        landmarks = flw.get_from_face_ids(ids)\n",
    "        id_to_lm = {idx: lm for idx, lm in zip(ids, landmarks)}\n",
    "        return faces.map_payload(lambda idx : {\n",
    "            'id': idx,\n",
    "            'landmarks': id_to_lm[idx]\n",
    "        })\n",
    "    \n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "    \n",
    "    # Line is ax+by+c=0\n",
    "    def project_point_to_line(pt, a, b, c):\n",
    "        x0,y0=pt[0], pt[1]\n",
    "        d=a*a+b*b\n",
    "        x=(b*(b*x0-a*y0)-a*c)/d\n",
    "        y=(a*(-b*x0+a*y0)-b*c)/d\n",
    "        return np.array([x,y])\n",
    "    \n",
    "    # Returns (a,b,c) which defines ax+by+c=0\n",
    "    def find_best_line_fit(xs, ys):\n",
    "        fit1 = np.polyfit(xs, ys, 1)\n",
    "        error1 = np.sum((np.poly1d(fit1)(xs)-ys)**2)\n",
    "        fit2 = np.polyfit(ys, xs, 1)\n",
    "        error2 = np.sum((np.poly1d(fit2)(ys)-xs)**2)\n",
    "        if error1 < error2:\n",
    "            # fit1[0]x+fit1[1]=y\n",
    "            return fit1[0], -1, fit1[1]\n",
    "        # fit2[0]y+fit2[1]=x\n",
    "        return -1, fit2[0], fit2[1]\n",
    "    \n",
    "    # Positive if facing left\n",
    "    def signed_face_angle(lm):\n",
    "        center_line_indices = [27,28, 32, 33,34, 51,62,66,57]\n",
    "        data = lm.landmarks[center_line_indices]\n",
    "        a, b, c = find_best_line_fit(data[:,0], data[:,1])\n",
    "        A = project_point_to_line(lm.landmarks[center_line_indices[0]], a, b, c)\n",
    "        B = project_point_to_line(lm.landmarks[center_line_indices[-1]], a, b, c)\n",
    "        AB = B-A\n",
    "        AB = AB / np.linalg.norm(AB)\n",
    "        C = np.mean(lm.nose_bridge()[2:4], axis=0)\n",
    "        AC = C-A\n",
    "        AC = AC / np.linalg.norm(AC)\n",
    "        return np.cross(AB, AC)\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(\n",
    "        frame__regularly_sampled=True,\n",
    "        probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT, video_id__in=vids)\n",
    "    \n",
    "    total = faces_qs.count()\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_faces = DomainIntervalCollection.from_django_qs(\n",
    "        faces_qs, DomainIntervalCollection.django_bbox_default_schema(),\n",
    "        progress=True, total=total\n",
    "    ).group_by_time(profile=True)\n",
    "    \n",
    "    overlap_faces_pattern = [\n",
    "        ([\"left\",\"right\"], [\n",
    "            X(or_preds(before(), overlaps_before())), # Left face on the left\n",
    "            X(lambda f1,f2: f1.end - f2.start > MIN_FACE_OVERLAP_X), # Faces overlap\n",
    "            Y(lambda f1,f2: min(f1.end, f2.end)-max(f1.start, f2.start) > MIN_FACE_OVERLAP_Y), # No face is entirely above another\n",
    "            XY(same_height(MAX_FACE_HEIGHT_DIFF)),\n",
    "            X(lambda f1, f2: (f1.end-f2.start)/max(f1.length(), f2.length()) < MAX_FACE_OVERLAP_X_FRACTION),\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    def matches_pattern(pattern, exact):\n",
    "        def pred(intervals):\n",
    "            return len(intervals.match(pattern, exact))>0\n",
    "        return pred\n",
    "    \n",
    "    # Frame_IS<Face_IS<face_id>>\n",
    "    frames_with_overlapped_faces = frames_with_faces.filter(P(\n",
    "        matches_pattern(overlap_faces_pattern, exact=True)), profile=True)\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_landmarks = frames_with_overlapped_faces.map_payload(get_landmarks, profile=True)\n",
    "    opposing_face_pattern = [\n",
    "        (['left'], [P(lambda f: signed_face_angle(f['landmarks']) < -MIN_FACE_ANGLE)]),\n",
    "        (['right'], [P(lambda f: signed_face_angle(f['landmarks']) > MIN_FACE_ANGLE)]),\n",
    "        (['left','right'], [P(lambda l, r: mouths_are_close(l['landmarks'], r['landmarks']))])\n",
    "    ]\n",
    "    \n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_faces = frames_with_landmarks.filter(P(matches_pattern(opposing_face_pattern, exact=True)),\n",
    "                                                              profile=True)\n",
    "    \n",
    "    vids = frames_with_opposing_faces.get_grouped_intervals().keys()\n",
    "    \n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        cinematic = True,\n",
    "    )\n",
    "    total = shots_qs.count()\n",
    "    # Shot_IS<>\n",
    "    shots = DomainIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        progress=True, total=total\n",
    "    )\n",
    "    # Shot_IS<Frame_IS<Face_IS<FaceMeta>>>\n",
    "    kissing_shots = shots.collect_by_interval(\n",
    "        frames_with_opposing_faces,\n",
    "        T(overlaps()),\n",
    "        time_window=1, profile=True\n",
    "    ).map_payload(lambda p:p[1]).map(\n",
    "        # Take the start of the kissing as the start of the shot\n",
    "        lambda shot: Interval3D((shot.payload.get_intervals()[0].t[0], shot.t[1]), payload=shot.payload))\n",
    "    \n",
    "    # Get faces in shots\n",
    "    faces_qs2 = Face.objects.filter(\n",
    "         frame__regularly_sampled=True,\n",
    "         frame__video_id__in=vids,\n",
    "         probability__gte=MIN_FACE_CONFIDENCE\n",
    "    ).annotate(\n",
    "             min_frame=F('frame__number'),\n",
    "             max_frame=F('frame__number'),\n",
    "             video_id=F('frame__video_id')       \n",
    "    )\n",
    "    total = faces_qs2.count()\n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_faces2 = DomainIntervalCollection.from_django_qs(\n",
    "        faces_qs2, DomainIntervalCollection.django_bbox_default_schema(),\n",
    "        progress=True, total=total\n",
    "    ).group_by_time(profile=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def both_faces_are_high(faces):\n",
    "        f1, f2 = faces.get_intervals()\n",
    "        return f1.height() >= MIN_FACE_HEIGHT and f2.height() >= MIN_FACE_HEIGHT\n",
    "        \n",
    "    # Frame_IS<Face_IS>\n",
    "    frames_with_two_faces = frames_with_faces2.filter(\n",
    "        P(and_preds(lambda faces: faces.size()==2, both_faces_are_high)),\n",
    "        profile=True\n",
    "    )\n",
    "    \n",
    "    # Collect frames with two faces into kissing shots, and clips the shot to the last frame with two faces\n",
    "    def clip_to_last_frame(intrvl):\n",
    "        frames = intrvl.payload[1]\n",
    "        if frames.empty():\n",
    "            return intrvl.copy()\n",
    "        return Interval3D((intrvl.t[0], frames.get_intervals()[-1].t[1]), payload=intrvl.payload)\n",
    "    \n",
    "    # Shot_IS<(Frame_IS<Face_IS>, Frame_IS<Face_IS>)>\n",
    "    clipped_kissing_shots = kissing_shots.collect_by_interval(\n",
    "        frames_with_two_faces, T(overlaps()), time_window=1, filter_empty=False, profile=True\n",
    "    ).map(clip_to_last_frame).filter_size(min_size=12)\n",
    "    \n",
    "    \n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    # Word_IS<>\n",
    "    caption_results = DomainIntervalCollection({\n",
    "        video_id: IntervalSet3D([Interval3D((\n",
    "            word[0] * fps_map[video_id], # start frame\n",
    "            word[1] * fps_map[video_id]))\n",
    "            for word in words])\n",
    "        for video_id, words in tqdm(results)\n",
    "    })\n",
    "    \n",
    "    kissing_without_words = clipped_kissing_shots.minus(caption_results, profile=True)\n",
    "    kissing_final = kissing_without_words.temporal_coalesce(epsilon=0.5, profile=True).map(\n",
    "        lambda i: Interval3D((int(i.t[0]), int(i.t[1])), payload=i.payload)\n",
    "    ).filter_size(min_size=12)\n",
    "    \n",
    "    return kissing_final\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    # Frame_IS<Face_IS<FaceMeta>>\n",
    "    frames_with_opposing_overlapped_faces, _ = payload\n",
    "    def face_to_objects(face):\n",
    "        from esper.stdlib import face_landmarks_to_dict\n",
    "        return [{\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }, face_landmarks_to_dict(face.payload['landmarks'])]\n",
    "    def update(acc, frame):\n",
    "        def accumulate_faces(a, face):\n",
    "            return a+face_to_objects(face)\n",
    "        return acc + frame.payload.fold(accumulate_faces, [])\n",
    "    return frames_with_opposing_overlapped_faces.fold(update, [])\n",
    "\n",
    "answer = kissing(list(range(12)))\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:06:01.786277Z",
     "start_time": "2019-02-08T09:06:01.756131Z"
    }
   },
   "source": [
    "# Action Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:30:41.834332Z",
     "start_time": "2019-03-06T07:29:33.701780Z"
    }
   },
   "outputs": [],
   "source": [
    "def action_shots(vids=None):\n",
    "    from query.models import Shot\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import meets_before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from django.db.models import ExpressionWrapper, FloatField\n",
    "    from esper.captions import get_all_segments\n",
    "    from rekall.merge_ops import payload_first, payload_plus, merge_named_payload\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    NUM_SHOTS=5\n",
    "    MAX_SHOT_DURATION=0.8\n",
    "    BRIGHTNESS_THRESHOLD = 20.0\n",
    "    MAX_NUM_WORDS_PER_SECOND = 1.0\n",
    "    \n",
    "    if vids is None:\n",
    "        vids = [v.id for v in Video.objects.filter(ignore_film=False)]\n",
    "    \n",
    "    shots_qs = Shot.objects.annotate(\n",
    "        duration = ExpressionWrapper((F('max_frame') - F('min_frame')) / F('video__fps'), output_field=FloatField())\n",
    "    ).filter(\n",
    "        duration__lt=MAX_SHOT_DURATION,\n",
    "        duration__gt=0.,\n",
    "        cinematic=True,\n",
    "        video_id__in=vids,\n",
    "    )\n",
    "    total=shots_qs.count()\n",
    "    \n",
    "    # Shot_IS<>\n",
    "    short_shots = DomainIntervalCollection.from_django_qs(shots_qs, progress=True, total=total)\n",
    "    \n",
    "    def get_all_frames(short_shots):\n",
    "        def update(frames, shot):\n",
    "            return frames + list(range(shot.t[0], shot.t[1]+1))\n",
    "        return short_shots.fold(update, [])\n",
    "    \n",
    "    video_to_frame_numbers = get_all_frames(short_shots)\n",
    "    all_frames = DomainIntervalCollection({})\n",
    "    for video, frames in tqdm(video_to_frame_numbers.items()):\n",
    "        # Getting brightness\n",
    "        qs = Frame.objects.filter(video_id=video, number__in=frames, regularly_sampled=True).order_by('number')\n",
    "        all_frames = all_frames.union(DomainIntervalCollection.from_django_qs(\n",
    "            qs, schema={'t1':'number', 't2': 'number', 'payload': 'brightness'}), profile=False)\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Shot_IS<Frame_IS>\n",
    "    shots_with_brightness = short_shots.collect_by_interval(\n",
    "        all_frames, T(overlaps()), time_window=0, filter_empty=False\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    # Sequence_IS<Shot_IS<Frame_IS>>\n",
    "    one_shots = shots_with_brightness.collect_by_interval(\n",
    "        shots_with_brightness, T(equal()), time_window=0).map_payload(select_second)\n",
    "    n_shots = one_shots\n",
    "    for n in range(2, NUM_SHOTS+1):\n",
    "        print(\"Constructing {} consecutive short shots\".format(n))\n",
    "        n_shots = n_shots.merge(\n",
    "            one_shots,\n",
    "            T(meets_before(epsilon=1)),\n",
    "            payload_merge_op = IntervalSet3D.union,            \n",
    "            time_window=1, profile=False)\n",
    "        print('There are {} videos with {} consecutive short shots'.format(\n",
    "                 len(n_shots.get_grouped_intervals()), n))\n",
    "        \n",
    "    def merge_shots(seq1, seq2):\n",
    "        return seq1.union(seq2.minus(seq1))\n",
    "    coalesced_n_shots = n_shots.temporal_coalesce(payload_merge_op=merge_shots)\n",
    "    \n",
    "    def bright_enough(shots):\n",
    "        # Check if any shots is above mean brightness threshold\n",
    "        def compute_avg_brightness(frames):\n",
    "            ret = frames.fold(lambda acc, f: acc+f.payload, 0)\n",
    "            if not frames.empty():\n",
    "                ret = ret / frames.size()\n",
    "            return ret\n",
    "        return shots.map_payload(compute_avg_brightness).fold(\n",
    "            lambda acc, shot: acc or shot.payload > BRIGHTNESS_THRESHOLD)\n",
    "            \n",
    "    n_bright_shots = n_shots.filter(P(bright_enough))\n",
    "    \n",
    "    vids = n_bright_shots.get_grouped_intervals().keys()\n",
    "    results = get_all_segments(vids)\n",
    "    fps_map = dict((i, Video.objects.get(id=i).fps) for i in vids)\n",
    "    \n",
    "    # Word_IS<fps>\n",
    "    caption_results = DomainIntervalCollection({\n",
    "        video_id: IntervalSet3D([Interval3D(\n",
    "            (word[0] * fps_map[video_id], word[1] * fps_map[video_id]),\n",
    "            payload = fps_map[video_id])\n",
    "            for word in words])\n",
    "        for video_id, words in results\n",
    "    })\n",
    "    \n",
    "    def has_few_words(seq):\n",
    "        _, words = seq.payload\n",
    "        n_words = words.size()\n",
    "        if n_words == 0:\n",
    "            return True\n",
    "        time = seq.length() / words.get_intervals()[0].payload\n",
    "        return n_words / time <= MAX_NUM_WORDS_PER_SECOND\n",
    "    \n",
    "    # Seq_IS<(Shot_IS<Frame_IS>, Word_IS)>\n",
    "    n_bright_shots_with_few_words = n_bright_shots.collect_by_interval(\n",
    "        caption_results,\n",
    "        T(overlaps()),\n",
    "        time_window=0,\n",
    "        filter_empty=False).filter(has_few_words)\n",
    "    \n",
    "    # Seq_IS<Shot_IS<Frame_IS>>\n",
    "    action_shots = coalesced_n_shots.filter_against(\n",
    "        n_bright_shots_with_few_words,\n",
    "        T(overlaps()),\n",
    "        time_window=0)\n",
    "    \n",
    "    return action_shots\n",
    "\n",
    "answer = action_shots()\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T09:25:48.264643Z",
     "start_time": "2019-02-09T09:25:48.229274Z"
    }
   },
   "source": [
    "# Conversations with Identity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:17:09.954169Z",
     "start_time": "2019-03-06T02:17:03.672466Z"
    }
   },
   "outputs": [],
   "source": [
    "def conversationsq(vids, progress=True):\n",
    "    from query.models import FaceCharacterActor, Shot\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from django.db.models import F\n",
    "    \n",
    "    faces_with_character_actor_qs = FaceCharacterActor.objects.annotate(\n",
    "        min_frame=F('face__frame__number'),\n",
    "        max_frame=F('face__frame__number'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        bbox_x1=F('face__bbox_x1'),\n",
    "        bbox_y1=F('face__bbox_y1'),\n",
    "        bbox_x2=F('face__bbox_x2'),\n",
    "        bbox_y2=F('face__bbox_y2'),\n",
    "        character_name=F('characteractor__character__name')\n",
    "    ).filter(face__frame__video_id__in=vids)\n",
    "    \n",
    "    total = faces_with_character_actor_qs.count()\n",
    "    \n",
    "    schema = DomainIntervalCollection.django_bbox_default_schema()\n",
    "    schema['payload'] = 'character_name'    \n",
    "    all_faces = DomainIntervalCollection.from_django_qs(faces_with_character_actor_qs, schema, progress=progress,\n",
    "                                                    total=total)\n",
    "    \n",
    "    vids = all_faces.get_grouped_intervals().keys()\n",
    "    if len(vids) == 0:\n",
    "        return DomainIntervalCollection({})\n",
    "    \n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        cinematic = True,\n",
    "    )\n",
    "    total = shots_qs.count()\n",
    "    shots = DomainIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        progress=progress, total=total\n",
    "    )\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Shot_IS<Face_IS>\n",
    "    shots_with_frames = shots.collect_by_interval(\n",
    "        all_faces, T(overlaps()), time_window=0, filter_empty=True).map_payload(select_second)\n",
    "    \n",
    "    def group_characters(faces):\n",
    "        def get_char(face):\n",
    "            return face.payload\n",
    "        def merge(char, faces):\n",
    "            merged_interval = faces.fold(Interval3D.merge)\n",
    "            merged_interval.payload = (char, faces)\n",
    "            return merged_interval\n",
    "        return faces.group_by(get_char, merge)\n",
    "    \n",
    "    # Shot_IS<Char_IS<(char, Face_IS)>>\n",
    "    shots_with_chars = shots_with_frames.map_payload(group_characters)\n",
    "    \n",
    "    def cross_product_chars(chars1, chars2):\n",
    "        def get_chars(chars):\n",
    "            def update(acc, char):\n",
    "                acc.append(char.payload[0])\n",
    "                return acc\n",
    "            return chars.fold(update, [])\n",
    "        chars_in_1 = get_chars(chars1)\n",
    "        chars_in_2 = get_chars(chars2)\n",
    "        result = []\n",
    "        for charA in chars_in_1:\n",
    "            for charB in chars_in_2:\n",
    "                if charA != charB:\n",
    "                    result.append((charA, charB))\n",
    "        return result\n",
    "            \n",
    "    # Seq_IS<[(char, char)]>\n",
    "    two_shots = shots_with_chars.merge(\n",
    "        shots_with_chars,\n",
    "        T(before(max_dist=1)),\n",
    "        payload_merge_op=cross_product_chars,\n",
    "        time_window=1\n",
    "    )\n",
    "    \n",
    "    def sequences_share_face_pair(list1, list2):\n",
    "        for A1, B1 in list1:\n",
    "            for A2, B2 in list2:\n",
    "                if ((A1==A2 and B1==B2) or\n",
    "                    (A1==B2 and B1==A2)):\n",
    "                    return True\n",
    "        return False\n",
    "    def merge_face_pairs(list1, list2):\n",
    "        return list1+list2\n",
    "    \n",
    "    def coalesce(self, predicate, payload_merge_op):\n",
    "        from rekall.interval_set_3d import IntervalSet3D\n",
    "        # State is (new, current)\n",
    "        def update(state, interval):\n",
    "            new, current = state\n",
    "            updated_current = []\n",
    "            size = len(new)+len(current)\n",
    "            for cur in current:\n",
    "                # No more intervals will overlap with cur\n",
    "                if cur.t[1] < interval.t[0]:\n",
    "                    new.append(cur)\n",
    "                else:\n",
    "                    updated_current.append(cur)\n",
    "            matched = None\n",
    "            for i, cur in enumerate(updated_current):\n",
    "                if predicate(cur, interval):\n",
    "                    matched = i\n",
    "                    break\n",
    "            if matched is None:\n",
    "                updated_current.append(interval)\n",
    "            else:\n",
    "                updated_current[matched] = updated_current[matched].merge(interval, payload_merge_op)\n",
    "            return new, updated_current\n",
    "        converged = False\n",
    "        while not converged:\n",
    "            old = self.size(profile=False)\n",
    "            self = self.fold_to_set(update, ([],[]), acc_to_set=lambda state: IntervalSet3D(state[0]+state[1]),\n",
    "                                    profile=False)\n",
    "            converged = old == self.size(profile=False)\n",
    "            # print(old, self.size(profile=False))\n",
    "        return self\n",
    "    \n",
    "    conv_candidates = coalesce(two_shots, P(sequences_share_face_pair), merge_face_pairs)\n",
    "    \n",
    "    def num_shots_at_least(n):\n",
    "        def pred(shots):\n",
    "            return shots.size() >= n\n",
    "        return pred\n",
    "    \n",
    "    # Conv_IS<Shot_IS<Char_IS<(char, Face_IS)>>>\n",
    "    convs = conv_candidates.collect_by_interval(\n",
    "        shots_with_chars, T(overlaps()), time_window=0, filter_empty=True\n",
    "    ).map_payload(select_second\n",
    "    ).filter(P(num_shots_at_least(3)))\n",
    "    \n",
    "    \n",
    "    return convs\n",
    "\n",
    "answer = conversationsq([380])\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversations with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:09:33.441417Z",
     "start_time": "2019-03-06T07:09:18.493785Z"
    }
   },
   "outputs": [],
   "source": [
    "def conversations_emb(vids):\n",
    "    from query.models import Shot, Face\n",
    "    import esper.face_embeddings as fe\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.temporal_predicates import overlaps, before\n",
    "    from rekall.interval_set_3d_utils import T,P\n",
    "    from django.db.models import F\n",
    "    \n",
    "    EMBEDDING_EQUALITY_THRESHOLD = 1.\n",
    "    ONE_FRAME = 1\n",
    "    MAX_CLUSTER_RETRY = 10\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Use face closest to cluster centroid as center of cluster\n",
    "    def compute_center(fids):\n",
    "        mean = fe.mean(fids)\n",
    "        dists = fe.dist(fids, targets=[mean])\n",
    "        return min(zip(dists, fids))[1]\n",
    "    \n",
    "    # Kmeans on small data can hang\n",
    "    def run_kmeans(fids, num_cluster, num_attempt=0):\n",
    "        try:\n",
    "            return fe.kmeans(fids, num_cluster)\n",
    "        except RuntimeError:\n",
    "            if num_attempt > MAX_CLUSTER_RETRY:\n",
    "                raise RuntimeError(\"Failed to cluster fids {0} into {1} clusters\".format(fids, num_cluster))\n",
    "            print(\"Failed to cluster! Retrying\")\n",
    "            return run_kmeans(fids, num_cluster, num_attempt+1)\n",
    "    \n",
    "    # Frames<Faces<ID>>\n",
    "    # Returns a list of (ClusterCenter, FaceIDsInCluster)\n",
    "    def cluster_faces_and_compute_center(frames):\n",
    "        num_people_in_shot = max(frame.payload.size() for frame in frames.get_intervals())\n",
    "        all_faces = frames.split(lambda f: f.payload)\n",
    "        face_ids = [face.payload for face in all_faces.get_intervals()]\n",
    "        # cluster_assignment is list of (FaceID, ClusterID)\n",
    "        if num_people_in_shot == 1:\n",
    "            cluster_assignments = [(fid, 0) for fid in face_ids]\n",
    "        else:\n",
    "            cluster_assignments = run_kmeans(face_ids, num_people_in_shot)\n",
    "        clusters = []\n",
    "        for i in range(num_people_in_shot):\n",
    "            faces_in_cluster = [val[0] for val in cluster_assignments if val[1]==i]\n",
    "            center_face_id = compute_center(faces_in_cluster)\n",
    "            clusters.append((center_face_id, faces_in_cluster))\n",
    "        return clusters\n",
    "    \n",
    "    def same_face(face1, face2):\n",
    "        return fe.dist([face1], target_ids=[face2])[0] < EMBEDDING_EQUALITY_THRESHOLD\n",
    "    \n",
    "    def cross_product_faces(clusters1, clusters2):\n",
    "        pairs = []\n",
    "        for c1 in clusters1:\n",
    "            for c2 in clusters2:\n",
    "                if not same_face(c1[0], c2[0]):\n",
    "                    pairs.append((c1, c2))\n",
    "        return pairs\n",
    "    \n",
    "    def sequences_share_face_pair(pairs1, pairs2):\n",
    "        for c1, c2 in pairs1:\n",
    "            for d1, d2 in pairs2:\n",
    "                if (same_face(c1[0], d1[0]) and same_face(c2[0], d2[0])) or (\n",
    "                    same_face(c1[0], d2[0]) and same_face(c2[0], d1[0])):\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def merge_face_pairs(pairs1, pairs2):\n",
    "        return pairs1 + pairs2\n",
    "    \n",
    "    def coalesce(self, predicate, payload_merge_op):\n",
    "        from rekall.interval_set_3d import IntervalSet3D\n",
    "        # State is (new, current)\n",
    "        def update(state, interval):\n",
    "            new, current = state\n",
    "            updated_current = []\n",
    "            size = len(new)+len(current)\n",
    "            for cur in current:\n",
    "                # No more intervals will overlap with cur\n",
    "                if cur.t[1] < interval.t[0]:\n",
    "                    new.append(cur)\n",
    "                else:\n",
    "                    updated_current.append(cur)\n",
    "            matched = None\n",
    "            for i, cur in enumerate(updated_current):\n",
    "                if predicate(cur, interval):\n",
    "                    matched = i\n",
    "                    break\n",
    "            if matched is None:\n",
    "                updated_current.append(interval)\n",
    "            else:\n",
    "                updated_current[matched] = updated_current[matched].merge(interval, payload_merge_op)\n",
    "            return new, updated_current\n",
    "        converged = False\n",
    "        while not converged:\n",
    "            old = self.size(profile=False)\n",
    "            self = self.fold_to_set(update, ([],[]), acc_to_set=lambda state: IntervalSet3D(state[0]+state[1]),\n",
    "                                    profile=False)\n",
    "            converged = old == self.size(profile=False)\n",
    "            # print(old, self.size(profile=False))\n",
    "        return self\n",
    "    \n",
    "    def num_shots_at_least(n):\n",
    "        def pred(shots):\n",
    "            return shots.size() >= n\n",
    "        return pred\n",
    "    \n",
    "    faces_qs = Face.objects.annotate(\n",
    "        min_frame = F('frame__number'),\n",
    "        max_frame = F('frame__number'),\n",
    "        video_id = F('frame__video_id'),\n",
    "    ).filter(\n",
    "        video_id__in = vids,\n",
    "        frame__regularly_sampled=True\n",
    "    )\n",
    "    total = faces_qs.count()\n",
    "    # Faces<ID>\n",
    "    faces = DomainIntervalCollection.from_django_qs(\n",
    "        faces_qs,\n",
    "        DomainIntervalCollection.django_bbox_default_schema(),\n",
    "        progress=True, total=total)\n",
    "    \n",
    "    # Frames<Faces<ID>>\n",
    "    frames_with_faces = faces.group_by_time(profile=False)\n",
    "    \n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in=vids,\n",
    "        cinematic=True\n",
    "    )\n",
    "    total = shots_qs.count()\n",
    "    # Shots<Frames<Faces<ID>>>\n",
    "    shots = DomainIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        progress=True, total=total\n",
    "    ).collect_by_interval(\n",
    "        frames_with_faces,\n",
    "        T(overlaps()),\n",
    "        filter_empty=True,\n",
    "        time_window=0, profile=False,\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    # Shots<FaceClusters>\n",
    "    shots_with_face_clusters = shots.map_payload(cluster_faces_and_compute_center, profile=False)\n",
    "    \n",
    "    # Sequences<FacePairList>\n",
    "    two_shots = shots_with_face_clusters.merge(\n",
    "        shots_with_face_clusters,\n",
    "        T(before(max_dist=ONE_FRAME)),\n",
    "        payload_merge_op=cross_product_faces,\n",
    "        time_window=1,\n",
    "        profile=False,\n",
    "    )\n",
    "    \n",
    "    # Sequences<FacePairList>\n",
    "    conv_candidates = coalesce(two_shots, P(sequences_share_face_pair), merge_face_pairs)\n",
    "    \n",
    "    conv_with_shots = conv_candidates.collect_by_interval(\n",
    "        shots_with_face_clusters,\n",
    "        T(overlaps()),\n",
    "        filter_empty=True,\n",
    "        time_window=0, profile=False,\n",
    "    ).map_payload(select_second).filter(\n",
    "        P(num_shots_at_least(3))\n",
    "    )\n",
    "    \n",
    "    return conv_with_shots   \n",
    "\n",
    "answer = conversations_emb([14])\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShotScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:20:43.687408Z",
     "start_time": "2019-03-06T02:18:47.978080Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_scale_q(vids, progress=False):\n",
    "    from query.models import Face, PoseMeta, Shot\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.temporal_predicates import before, overlaps, equal\n",
    "    from rekall.interval_set_3d_utils import T,P,XY,or_preds,X,Y\n",
    "    from esper import pose_wrapper as pw\n",
    "    from esper import shot_scale\n",
    "    from django.db.models import F\n",
    "    \n",
    "    shots_qs = Shot.objects.filter(video_id__in=vids, cinematic=True)\n",
    "    total = shots_qs.count()\n",
    "    # Shot_IS\n",
    "    shots = DomainIntervalCollection.from_django_qs(shots_qs, progress=progress, total=total)\n",
    "    \n",
    "    faces_qs= Face.objects.filter(frame__video_id__in=vids, frame__regularly_sampled=True\n",
    "                                 ).annotate(video_id=F('frame__video__id'),\n",
    "                                            number=F('frame__number'))\n",
    "    poses_qs = PoseMeta.objects.filter(frame__video_id__in=vids, frame__regularly_sampled=True\n",
    "                                 ).annotate(video_id=F('frame__video__id'),\n",
    "                                            number=F('frame__number'))\n",
    "    \n",
    "    total = faces_qs.count()\n",
    "    all_faces = DomainIntervalCollection.from_django_qs(faces_qs, schema={\n",
    "        't1':'number', 't2':'number', 'x1':'bbox_x1', 'x2':'bbox_x2', 'y1':'bbox_y1', 'y2':'bbox_y2'\n",
    "    }, progress=progress, total=total)\n",
    "    \n",
    "    total = poses_qs.count()\n",
    "    all_poses = DomainIntervalCollection.from_django_qs(poses_qs, schema={\n",
    "        't1':'number', 't2':'number', 'payload':'id'\n",
    "    }, progress=progress, total=total)\n",
    "    \n",
    "    print(\"Loading {0} Poses\".format(total))\n",
    "    \n",
    "    def get_pose_map(poses_qs):\n",
    "        poses = pw.get(poses_qs)\n",
    "        print(\"Poses loaded\")\n",
    "        return {pose.id: pose for pose in poses}\n",
    "    \n",
    "    def get_pose(pose_map):\n",
    "        def map_fn(payload):\n",
    "            return pose_map[payload]\n",
    "        return map_fn\n",
    "    \n",
    "    all_poses = all_poses.map_payload(get_pose(get_pose_map(poses_qs)), profile=progress)\n",
    "    \n",
    "    def add_scale_to_face(face):\n",
    "        face.payload = shot_scale.face_height_to_shot_scale(face.height())\n",
    "        return face\n",
    "    \n",
    "    # Face_IS<Scale>\n",
    "    all_faces_with_scale = all_faces.map(add_scale_to_face, profile=progress)\n",
    "    \n",
    "    def add_scale_to_pose(pose):\n",
    "        return {\n",
    "            'pose': pose,\n",
    "            'scale': shot_scale.pose_keypoints_to_shot_scale(pose.pose_keypoints())\n",
    "        }\n",
    "    # Pose_IS<{'pose','scale'}>\n",
    "    all_poses_with_scale = all_poses.map_payload(add_scale_to_pose, profile=progress)\n",
    "    \n",
    "    # Frame_IS\n",
    "    all_frames_with_signal = all_faces.union(all_poses).group_by_time(profile=progress)\n",
    "    \n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Frame_IS<(Face_IS, Pose_IS)>\n",
    "    frames_with_faces_and_poses = all_frames_with_signal.collect_by_interval(\n",
    "        all_faces_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress,\n",
    "    ).map_payload(select_second).collect_by_interval(\n",
    "        all_poses_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress\n",
    "    )\n",
    "    \n",
    "    def add_scale_to_frame(payload):\n",
    "        faces, poses = payload\n",
    "        def take_max_face(acc, face):\n",
    "            return max(acc, face.payload)\n",
    "        def take_max_pose(acc, pose):\n",
    "            return max(acc, pose.payload['scale'])\n",
    "        max_face_scale = faces.fold(take_max_face, shot_scale.ShotScale.UNKNOWN)\n",
    "        max_pose_scale = poses.fold(take_max_pose, shot_scale.ShotScale.UNKNOWN)\n",
    "        return (max(max_face_scale, max_pose_scale), faces, poses)\n",
    "    \n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    frames_with_scale = frames_with_faces_and_poses.map_payload(add_scale_to_frame, profile=progress)\n",
    "    \n",
    "    # Shot_IS<Frame_IS<(Scale, Face_IS, Pose_IS)>>\n",
    "    shots_with_frames = shots.collect_by_interval(\n",
    "        frames_with_scale,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0, profile=progress,\n",
    "    ).map_payload(select_second)\n",
    "    \n",
    "    def get_mode(scales):\n",
    "        count = {}\n",
    "        for s in shot_scale.ShotScale:\n",
    "            count[s] = 0\n",
    "        for s in scales:\n",
    "            count[s]+=1\n",
    "        best_count = 0\n",
    "        best_scale=shot_scale.ShotScale.UNKNOWN\n",
    "        for s in shot_scale.ShotScale:\n",
    "            if count[s]>=best_count:\n",
    "                best_count = count[s]\n",
    "                best_scale = s\n",
    "        return best_scale\n",
    "    \n",
    "    def add_scale_to_shot(frames):\n",
    "        def update(acc, frame):\n",
    "            acc.append(frame.payload[0])\n",
    "            return acc\n",
    "        scales = frames.fold(update, [])\n",
    "        mode = get_mode(scales)\n",
    "        return mode, frames\n",
    "    \n",
    "    # Shot_IS<(Scale, Frame_IS<(Scale, Face_IS<Scale>, Pose_IS<(Scale, PoseKeypoints)>)>)>\n",
    "    shots_with_scale = shots_with_frames.map_payload(add_scale_to_shot, profile=progress)\n",
    "    return shots_with_scale\n",
    "\n",
    "def payload_to_vgrid_objects(payload):\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    scale, frames = payload\n",
    "    def face_to_object(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }\n",
    "    \n",
    "    def pose_to_object(pose):\n",
    "        from esper.stdlib import pose_to_dict\n",
    "        return pose_to_dict(pose.payload['pose'])\n",
    "    \n",
    "    def face_objects_at_scale(faces, scale):\n",
    "        faces = faces.filter(P(lambda p:p==scale))\n",
    "        def update(acc, face):\n",
    "            acc.append(face_to_object(face))\n",
    "            return acc\n",
    "        return faces.fold(update, [])\n",
    "    \n",
    "    def pose_objects_at_scale(poses, scale):\n",
    "        poses = poses.filter(P(lambda p:p['scale']==scale))\n",
    "        def update(acc, pose):\n",
    "            acc.append(pose_to_object(pose))\n",
    "            return acc\n",
    "        return poses.fold(update, [])\n",
    "    \n",
    "    frames = frames.filter(P(lambda p:p[0]==scale))\n",
    "    def update(acc, frame):\n",
    "        _, faces, poses = frame.payload\n",
    "        return acc + face_objects_at_scale(faces, scale) + pose_objects_at_scale(poses, scale)\n",
    "    return frames.fold(update, [])\n",
    "\n",
    "answer = shot_scale_q([1], True)\n",
    "print(\"Query Done. Preparing for VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:23:04.818594Z",
     "start_time": "2019-03-06T02:23:00.767773Z"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_func(vids):\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from query.models import Video\n",
    "    \n",
    "    vs = Video.objects.filter(id__in=vids)\n",
    "    return DomainIntervalCollection({\n",
    "        v.id: IntervalSet3D([Interval3D((0, v.num_frames-1))]) for v in vs})\n",
    "\n",
    "def run_dummy():\n",
    "    from rekall.runtime import Runtime\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = Runtime.inline()\n",
    "    results,_ = rt.run(dummy_func, vids, profile=True, progress=True)\n",
    "    return results\n",
    "\n",
    "display_result(convert_to_1d_collection(run_dummy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hermione in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:27:08.643723Z",
     "start_time": "2019-03-06T02:26:52.704424Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_hp():\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    from query.models import Video\n",
    "    import ipyparallel as ipp\n",
    "    \n",
    "    c = ipp.Client(profile='local')\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.filter(name__contains=\"harry potter\")]\n",
    "    rt = get_runtime_for_ipython_cluster(c)\n",
    "    return rt.run(hermione_in_the_middle, vids, profile=False, progress=True)[0]\n",
    "\n",
    "answer = run_hp()\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:41:19.605496Z",
     "start_time": "2019-03-06T07:33:10.023359Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_kissing():\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    import ipyparallel as ipp\n",
    "    from query.models import Video\n",
    "    \n",
    "    c = ipp.Client(profile='local')\n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_ipython_cluster(c)\n",
    "    return rt.run(kissing, vids, profile=False, progress=True, chunksize=5)[0]\n",
    "\n",
    "kissing_answer = run_kissing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:39:44.611639Z",
     "start_time": "2019-03-06T02:39:35.494165Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_action_shots():\n",
    "    import ipyparallel as ipp\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    from query.models import Video\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_ipython_cluster(ipp.Client(profile=\"local\"))\n",
    "    return rt.run(action_shots, vids, profile=False, progress=True, chunksize=2)[0]\n",
    "\n",
    "answer = run_action_shots()\n",
    "print(\"Query finished. Preparing VGrid.\")\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversations with Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:46:08.019796Z",
     "start_time": "2019-03-06T02:39:56.489513Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_conversations():\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    from query.models import Video, FaceCharacterActor\n",
    "    import ipyparallel as ipp\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_ipython_cluster(ipp.Client(profile=\"local\"))\n",
    "    return rt.run(conversationsq, vids, profile=False, progress=True, chunksize=10)[0]\n",
    "\n",
    "answer = run_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversations with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:26:10.831257Z",
     "start_time": "2019-03-06T07:22:00.571854Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_conversations_emb():\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    from query.models import Video\n",
    "    from rekall.runtime import Runtime\n",
    "    import ipyparallel as ipp\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_ipython_cluster(ipp.Client(profile=\"local\"))\n",
    "    return rt.run(conversations_emb, vids[::4], progress=True, chunksize=3)[0]\n",
    "\n",
    "answer = run_conversations_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShotScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T02:55:03.601799Z",
     "start_time": "2019-03-06T02:47:25.619317Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_scale_no_payload(vids):\n",
    "    return shot_scale_q(vids, progress=True).map_payload(lambda p:p[0])\n",
    "\n",
    "def run_shot_scale():\n",
    "    from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "    from query.models import Video\n",
    "    import ipyparallel as ipp\n",
    "    \n",
    "    vids = [v.id for v in Video.objects.all()]\n",
    "    rt = get_runtime_for_ipython_cluster(ipp.Client(profile='local'))\n",
    "    return rt.run(shot_scale_q, vids[::10], progress=True, chunksize=1)[0]\n",
    "\n",
    "answer = run_shot_scale()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T00:24:01.993498Z",
     "start_time": "2019-02-10T00:24:01.953664Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.filter(lambda i:i.t[0]==120401).get_allintervals()[380].get_intervals()[0].payload.map_payload(lambda char: char.fold(lambda acc, c: acc+[c.payload[0]], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T19:39:36.083555Z",
     "start_time": "2019-02-11T19:39:36.051577Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()[32].get_intervals()[0].payload[0].get_intervals()[0].payload.get_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T22:33:45.964208Z",
     "start_time": "2019-02-11T22:33:19.090364Z"
    }
   },
   "outputs": [],
   "source": [
    "def payload_to_vgrid_objects(payload):\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    # Frame_IS<(Scale, Face_IS, Pose_IS)>\n",
    "    scale, frames = payload\n",
    "    def face_to_object(face):\n",
    "        return {\n",
    "            'type': 'bbox',\n",
    "            'bbox_x1': face.x[0], 'bbox_x2': face.x[1],\n",
    "            'bbox_y1': face.y[0], 'bbox_y2': face.y[1]\n",
    "        }\n",
    "    \n",
    "    def pose_to_object(pose):\n",
    "        from esper.stdlib import pose_to_dict\n",
    "        return pose_to_dict(pose.payload['pose'])\n",
    "    \n",
    "    def face_objects_at_scale(faces, scale):\n",
    "        faces = faces.filter(P(lambda p:p==scale))\n",
    "        def update(acc, face):\n",
    "            acc.append(face_to_object(face))\n",
    "            return acc\n",
    "        return faces.fold(update, [])\n",
    "    \n",
    "    def pose_objects_at_scale(poses, scale):\n",
    "        poses = poses.filter(P(lambda p:p['scale']==scale))\n",
    "        def update(acc, pose):\n",
    "            acc.append(pose_to_object(pose))\n",
    "            return acc\n",
    "        return poses.fold(update, [])\n",
    "    \n",
    "    frames = frames.filter(P(lambda p:p[0]==scale))\n",
    "    def update(acc, frame):\n",
    "        _, faces, poses = frame.payload\n",
    "        return acc + face_objects_at_scale(faces, scale) + pose_objects_at_scale(poses, scale)\n",
    "    return frames.fold(update, [])\n",
    "\n",
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects)), display_payload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:42:15.510233Z",
     "start_time": "2019-02-14T05:42:15.436150Z"
    }
   },
   "outputs": [],
   "source": [
    "qs=Face.objects.all()[:3]\n",
    "[q.id for q in qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:33:35.694562Z",
     "start_time": "2019-02-14T05:33:35.497049Z"
    }
   },
   "outputs": [],
   "source": [
    "import esper.face_landmarks_wrapper as flw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T05:33:55.830761Z",
     "start_time": "2019-02-14T05:33:55.797716Z"
    }
   },
   "outputs": [],
   "source": [
    "flw.get_from_face_ids([3,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T07:36:54.585992Z",
     "start_time": "2019-02-14T07:36:39.400298Z"
    }
   },
   "outputs": [],
   "source": [
    "from django.db.models import Count\n",
    "from query.models import Face\n",
    "Face.objects.values(\"frame__video_id\").annotate(num_faces=Count('id')).order_by('num_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T21:50:08.195355Z",
     "start_time": "2019-02-19T21:50:08.155611Z"
    }
   },
   "outputs": [],
   "source": [
    "from query.models import Frame, Video\n",
    "v = Video.objects.get(id=1)\n",
    "Frame.objects.filter(video=v, number=v.num_frames-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T01:46:42.160154Z",
     "start_time": "2019-02-20T01:46:41.064610Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.shot_scale import ShotScale as ShotScaleEnum\n",
    "from rekall.interval_set_3d_utils import P\n",
    "display_result(convert_to_1d_collection(answer.filter(P(lambda p: p==ShotScaleEnum.EXTREME_LONG))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:42:24.161519Z",
     "start_time": "2019-02-21T08:37:46.756154Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(answer.map_payload(payload_to_vgrid_objects, profile=True, parallel=True)), display_payload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:12:21.060332Z",
     "start_time": "2019-02-22T08:12:21.021705Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c=ipp.Client(profile='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:16:05.614487Z",
     "start_time": "2019-02-22T08:16:05.355703Z"
    }
   },
   "outputs": [],
   "source": [
    "for h in c.history:\n",
    "    a = c.get_result(h)\n",
    "    print(h,a.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T06:42:12.455825Z",
     "start_time": "2019-03-06T06:42:09.729097Z"
    }
   },
   "outputs": [],
   "source": [
    "from rekall.interval_set_3d_utils import P\n",
    "a = answer.add_domain_to_payload().filter(P(lambda p: p[1]==640))\n",
    "display_result(convert_to_1d_collection(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:07:53.535904Z",
     "start_time": "2019-03-06T07:07:53.517091Z"
    }
   },
   "outputs": [],
   "source": [
    "\"{0:03d}\".format(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:29:05.497152Z",
     "start_time": "2019-03-06T07:29:05.249465Z"
    }
   },
   "outputs": [],
   "source": [
    "Shot.objects.filter(cinematic=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T07:41:36.378347Z",
     "start_time": "2019-03-06T07:41:36.345539Z"
    }
   },
   "outputs": [],
   "source": [
    "kissing_answer.get_flattened_intervalset().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1219px",
    "left": "0px",
    "right": "2348px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
