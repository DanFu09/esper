{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak labels for timeseries model\n",
    "\n",
    "To use Shiori's timeseries model for shot detection, we need to make the following changes to the label matrix:\n",
    "* Each window of 16 frames is a single datapoint\n",
    "* The windows are **not** overlapping, so the first window is frames `[1, 2, ..., 16]`, second is `[17, 18, ..., 32]`, etc\n",
    "* Ground truth: our annotated shot boundaries are the first frames of new shots, so a window contains a shot boundary f only if frames f and f - 1 are in the window\n",
    "* Frames are 0-indexed!\n",
    "\n",
    "For this notebook, we want the validation and test sets to come from the same movies. So for each clip in each movie (a clip is a sequence of frames that we have GT labels for), the first half of the frames make up the validation set, and the second half make up the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sparse\n",
    "import pickle\n",
    "import rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import IntervalList\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.logical_predicates import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load manually annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/manually_annotated_shots.pkl', 'rb') as f:\n",
    "    shots = VideoIntervalCollection(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_folds.pkl', 'rb') as f:\n",
    "    shot_detection_folds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 9208.85it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 19398.83it/s]\n"
     ]
    }
   ],
   "source": [
    "clips = shots.dilate(1).coalesce().dilate(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_boundaries = shots.map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    ").set_union(\n",
    "    shots.map(lambda intrvl: (intrvl.end + 1, intrvl.end + 1, intrvl.payload))\n",
    ").coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_frames = {\n",
    "    video_id: [\n",
    "        intrvl.start\n",
    "        for intrvl in shot_boundaries.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    for video_id in shot_boundaries.get_allintervals()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = sorted(list(clips.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_video = {\n",
    "    video_id: sorted([\n",
    "        f\n",
    "        for interval in clips.get_intervallist(video_id).get_intervals()\n",
    "        for f in range(interval.start, interval.end + 2)\n",
    "    ])\n",
    "    for video_id in video_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {\n",
    "    video_id: [\n",
    "        1 if f in boundary_frames[video_id] else 2\n",
    "        for f in frames_per_video[video_id]\n",
    "    ] \n",
    "    for video_id in video_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_mod_16(frame_num):\n",
    "    return int(frame_num - (frame_num % 16))\n",
    "validation_clips = clips.map(\n",
    "    lambda clip: (clip.start, clip_to_mod_16(clip.end - clip.length() / 2), clip.payload)\n",
    ")\n",
    "test_clips = clips.map(\n",
    "    lambda clip: (clip_to_mod_16(clip.end - clip.length() / 2), clip.end, clip.payload)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label matrix with all the frames in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/all_labels.pkl', 'rb') as f:\n",
    "    weak_labels_all_movies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load videos and number of frames per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/frame_counts.pkl', 'rb') as f:\n",
    "    frame_counts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_all = sorted(list(frame_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_train = sorted(list(set(video_ids_all).difference(set(video_ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct windows for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct windows of 16 frames for each video\n",
    "windows = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 16)\n",
    "    ]\n",
    "    for video_id in video_ids_all\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Test Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_windows = windows.filter_against(\n",
    "    validation_clips,\n",
    "    predicate=or_pred(\n",
    "        overlaps_before(),\n",
    "        or_pred(during(), finishes(), arity=2),\n",
    "        arity=2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows = windows.filter_against(\n",
    "    test_clips,\n",
    "    predicate=or_pred(\n",
    "        overlaps_after(),\n",
    "        or_pred(during(), starts(), arity=2),\n",
    "        arity=2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_ids = sorted(list(val_windows.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_ids = sorted(list(test_windows.get_allintervals().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ground truth labels for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, intersect the windows with ground truth and get ground truth labels for the windows\n",
    "windows_intersecting_ground_truth = windows.filter_against(\n",
    "    clips,\n",
    "    predicate=overlaps()\n",
    ").map(lambda intrvl: (intrvl.start, intrvl.end, 2))\n",
    "windows_with_shot_boundaries = windows_intersecting_ground_truth.filter_against(\n",
    "    shot_boundaries,\n",
    "    predicate = lambda window, shot_boundary:\n",
    "        shot_boundary.start - 1 >= window.start and shot_boundary.start <= window.end\n",
    ").map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.end, 1)\n",
    ")\n",
    "windows_with_labels = windows_with_shot_boundaries.set_union(\n",
    "    windows_intersecting_ground_truth\n",
    ").coalesce(\n",
    "    predicate = equal(),\n",
    "    payload_merge_op = lambda p1, p2: min(p1, p2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_windows_with_labels = windows_with_labels.filter_against(val_windows, predicate=equal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows_with_labels = windows_with_labels.filter_against(test_windows, predicate=equal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weak labels for all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label windows with the weak labels in our labeling functions\n",
    "def label_window(per_frame_weak_labels):\n",
    "    if 1 in per_frame_weak_labels:\n",
    "        return 1\n",
    "    if len([l for l in per_frame_weak_labels if l == 2]) >= len(per_frame_weak_labels) / 2:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "windows_with_weak_labels = windows.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_windows_with_weak_labels = windows_with_weak_labels.filter_against(val_windows, predicate=equal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows_with_weak_labels = windows_with_weak_labels.filter_against(test_windows, predicate=equal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = np.array([\n",
    "    intrvl.payload\n",
    "    for video_id in val_video_ids\n",
    "    for intrvl in val_windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array([\n",
    "    intrvl.payload\n",
    "    for video_id in test_video_ids\n",
    "    for intrvl in test_windows_with_labels.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L_val, L_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_val = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in val_video_ids\n",
    "    for intrvl in val_windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in test_video_ids\n",
    "    for intrvl in test_windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 2, 2],\n",
       "        [2, 2, 1, 0, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [2, 2, 1, 0, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [2, 2, 2, 0, 0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_val[:10].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2, 2, 2, 2, 1],\n",
       "        [1, 2, 1, 0, 0],\n",
       "        [2, 2, 1, 0, 0],\n",
       "        [2, 2, 1, 0, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [2, 2, 1, 0, 0],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [2, 2, 2, 2, 1],\n",
       "        [2, 2, 2, 0, 1],\n",
       "        [2, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_test[:10].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846, 5)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L_train 100 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load train split\n",
    "with open('../../data/shot_detection_weak_labels/train_split_100.pkl', 'rb') as f:\n",
    "    train_split_100 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_100 = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in train_split_100\n",
    "    for intrvl in windows_with_weak_labels.get_intervallist(\n",
    "        video_id\n",
    "    ).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L_train all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_all = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in video_ids_train\n",
    "    for intrvl in windows_with_weak_labels.get_intervallist(\n",
    "        video_id\n",
    "    ).get_intervals()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5879519, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Validation and Test Windows to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/validation_windows_same_val_test.pkl', 'wb') as f:\n",
    "    val_windows_pickle = [\n",
    "        (video_id, interval.start, interval.end)\n",
    "        for video_id in sorted(list(val_windows.get_allintervals().keys()))\n",
    "        for interval in val_windows.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    pickle.dump(val_windows_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/test_windows_same_val_test.pkl', 'wb') as f:\n",
    "    test_windows_pickle = [\n",
    "        (video_id, interval.start, interval.end)\n",
    "        for video_id in sorted(list(test_windows.get_allintervals().keys()))\n",
    "        for interval in test_windows.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    pickle.dump(test_windows_pickle, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save them all to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/Y_val_windows_downsampled_same_val_test.npy', 'wb') as f:\n",
    "    np.save(f, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/Y_test_windows_downsampled_same_val_test.npy', 'wb') as f:\n",
    "    np.save(f, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_val_windows_downsampled_same_val_test.npz', 'wb') as f:\n",
    "    sparse.save_npz(f, L_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_test_windows_downsampled_same_val_test.npz', 'wb') as f:\n",
    "    sparse.save_npz(f, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_train_100_windows_downsampled.npz', 'wb') as f:\n",
    "    sparse.save_npz(f, L_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_train_all_windows_downsampled.npz', 'wb') as f:\n",
    "    sparse.save_npz(f, L_train_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
