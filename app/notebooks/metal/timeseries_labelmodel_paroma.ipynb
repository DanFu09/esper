{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, pickle, csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "sys.path.append('/lfs/1/danfu/metal')\n",
    "sys.path.append('/lfs/1/danfu/sequential_ws')\n",
    "from metal.metrics import metric_score\n",
    "from torch.nn.functional import normalize\n",
    "from DP.label_model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/L_train_100_windows.npz'\n",
    "L_dev_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/L_dev_windows.npz'\n",
    "Y_dev_path = '/lfs/1/danfu/esper/app/data/shot_detection_weak_labels/Y_dev_windows.npy'\n",
    "\n",
    "stride = 1\n",
    "L_train_raw = sp.sparse.load_npz(L_train_path).todense()[::stride]\n",
    "L_dev_raw = sp.sparse.load_npz(L_dev_path).todense()\n",
    "Y_dev_raw = np.load(Y_dev_path)\n",
    "\n",
    "T = 5\n",
    "m_per_task = 5\n",
    "\n",
    "L_train = torch.FloatTensor(L_train_raw[:L_train_raw.shape[0] - (L_train_raw.shape[0] % T)]).to(device)\n",
    "L_dev = torch.FloatTensor(L_dev_raw[:L_dev_raw.shape[0] - (L_dev_raw.shape[0] % T)]).to(device)\n",
    "Y_dev = torch.FloatTensor(Y_dev_raw[:Y_dev_raw.shape[0] - (Y_dev_raw.shape[0] % T)]).to(device)\n",
    "m_per_task = L_train.size(1)\n",
    "n_frames_train = L_train.size(0)\n",
    "n_patients_train = n_frames_train//T\n",
    "n_frames_dev = L_dev.size(0)\n",
    "n_patients_dev = n_frames_dev//T\n",
    "\n",
    "# MRI_data_naive = {'Li_train': (L_train.unsqueeze(2) == torch.FloatTensor([-1,1,0]).to(device).unsqueeze(0).unsqueeze(0)).argmax(2),\n",
    "#                   'Li_dev': (L_dev.unsqueeze(2) == torch.FloatTensor([-1,1,0]).to(device).unsqueeze(0).unsqueeze(0)).argmax(2),\n",
    "#                   'R_dev': (Y_dev.unsqueeze(1) == torch.FloatTensor([-1,1]).to(device).unsqueeze(0)).argmax(1),\n",
    "#                   'm':m_per_task, 'T':1,\n",
    "#                  }\n",
    "\n",
    "# don't need to transform the raw data\n",
    "MRI_data_naive = {'Li_train': L_train.long().to(device),\n",
    "                  'Li_dev': L_dev.long().to(device),\n",
    "                  'R_dev': Y_dev.long().to(device),\n",
    "                  'm':m_per_task, 'T':1,\n",
    "                 }\n",
    "MRI_data_naive['class_balance'] = normalize((MRI_data_naive['R_dev'].unsqueeze(1)==torch.arange(2, device=device).unsqueeze(0)).sum(0).float(), \n",
    "                                            dim=0, p=1)\n",
    "MRI_data_temporal = {'Li_train': MRI_data_naive['Li_train'].view(n_patients_train, (m_per_task*T)),\n",
    "                     'Li_dev': MRI_data_naive['Li_dev'].view(n_patients_dev, (m_per_task*T)),\n",
    "                     'R_dev': MRI_data_naive['R_dev']*(2**T-1),\n",
    "                     'm': m_per_task * T, 'T': T,\n",
    "                    } \n",
    "MRI_data_temporal['class_balance'] = normalize((MRI_data_temporal['R_dev'].unsqueeze(1)==torch.arange(2**T, device=device).unsqueeze(0)).sum(0).float(), \n",
    "                                                dim=0, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "iteration=0 loss=57.88106918334961\n",
      "iteration=500 loss=0.24769733846187592\n",
      "iteration=1000 loss=0.2150215357542038\n",
      "iteration=1500 loss=0.20939819514751434\n",
      "iteration=2000 loss=0.20730239152908325\n",
      "iteration=2500 loss=0.20622797310352325\n",
      "iteration=3000 loss=0.20558057725429535\n",
      "iteration=3500 loss=0.2051495462656021\n",
      "iteration=4000 loss=0.20484158396720886\n",
      "iteration=4500 loss=0.2046094685792923\n",
      "iteration=4999 loss=0.20442740619182587\n",
      "Accuracy: 0.005\n",
      "F1: 0.016\n",
      "Recall: 0.029\n",
      "Precision: 0.011\n",
      "Flipping Parameters\n",
      "Accuracy: 0.108\n",
      "F1: 0.353\n",
      "Recall: 0.611\n",
      "Precision: 0.248\n",
      "Accuracy: 0.176\n",
      "F1: 0.299\n",
      "Recall: 1.000\n",
      "Precision: 0.176\n",
      "12\n",
      "iteration=0 loss=41.46357727050781\n",
      "iteration=500 loss=0.2453763782978058\n",
      "iteration=1000 loss=0.22044265270233154\n",
      "iteration=1500 loss=0.21405556797981262\n",
      "iteration=2000 loss=0.21120427548885345\n",
      "iteration=2500 loss=0.2096126824617386\n",
      "iteration=3000 loss=0.2086034119129181\n",
      "iteration=3500 loss=0.2079012393951416\n",
      "iteration=4000 loss=0.2073746621608734\n",
      "iteration=4500 loss=0.2069547474384308\n",
      "iteration=4999 loss=0.20660381019115448\n",
      "Accuracy: 0.005\n",
      "F1: 0.016\n",
      "Recall: 0.029\n",
      "Precision: 0.011\n",
      "Flipping Parameters\n",
      "Accuracy: 0.129\n",
      "F1: 0.408\n",
      "Recall: 0.732\n",
      "Precision: 0.283\n",
      "Accuracy: 0.176\n",
      "F1: 0.299\n",
      "Recall: 1.000\n",
      "Precision: 0.176\n",
      "123\n",
      "iteration=0 loss=38.89482116699219\n",
      "iteration=500 loss=0.23349329829216003\n",
      "iteration=1000 loss=0.20476827025413513\n",
      "iteration=1500 loss=0.19929976761341095\n",
      "iteration=2000 loss=0.1972903311252594\n",
      "iteration=2500 loss=0.1962207555770874\n",
      "iteration=3000 loss=0.1955343782901764\n",
      "iteration=3500 loss=0.1950540989637375\n",
      "iteration=4000 loss=0.19470392167568207\n",
      "iteration=4500 loss=0.1944429576396942\n",
      "iteration=4999 loss=0.19424626231193542\n",
      "Accuracy: 0.107\n",
      "F1: 0.353\n",
      "Recall: 0.611\n",
      "Precision: 0.248\n",
      "Flipping Parameters\n",
      "Accuracy: 0.028\n",
      "F1: 0.083\n",
      "Recall: 0.161\n",
      "Precision: 0.056\n",
      "Accuracy: 0.176\n",
      "F1: 0.299\n",
      "Recall: 1.000\n",
      "Precision: 0.176\n",
      "1234\n",
      "iteration=0 loss=46.179969787597656\n",
      "iteration=500 loss=0.2412208914756775\n",
      "iteration=1000 loss=0.2162775993347168\n",
      "iteration=1500 loss=0.2106979340314865\n",
      "iteration=2000 loss=0.20839951932430267\n",
      "iteration=2500 loss=0.2071651816368103\n",
      "iteration=3000 loss=0.2063981294631958\n",
      "iteration=3500 loss=0.2058734893798828\n",
      "iteration=4000 loss=0.20548872649669647\n",
      "iteration=4500 loss=0.20519137382507324\n",
      "iteration=4999 loss=0.20495277643203735\n",
      "Accuracy: 0.005\n",
      "F1: 0.016\n",
      "Recall: 0.029\n",
      "Precision: 0.011\n",
      "Flipping Parameters\n",
      "Accuracy: 0.129\n",
      "F1: 0.408\n",
      "Recall: 0.732\n",
      "Precision: 0.283\n",
      "Accuracy: 0.176\n",
      "F1: 0.299\n",
      "Recall: 1.000\n",
      "Precision: 0.176\n",
      "12345\n",
      "iteration=0 loss=40.818302154541016\n",
      "iteration=500 loss=0.24775567650794983\n",
      "iteration=1000 loss=0.2225291132926941\n",
      "iteration=1500 loss=0.21528202295303345\n",
      "iteration=2000 loss=0.21193146705627441\n",
      "iteration=2500 loss=0.2100481390953064\n",
      "iteration=3000 loss=0.2088600993156433\n",
      "iteration=3500 loss=0.2080426812171936\n",
      "iteration=4000 loss=0.20743845403194427\n",
      "iteration=4500 loss=0.20696449279785156\n",
      "iteration=4999 loss=0.20657522976398468\n",
      "Accuracy: 0.005\n",
      "F1: 0.016\n",
      "Recall: 0.029\n",
      "Precision: 0.011\n",
      "Flipping Parameters\n",
      "Accuracy: 0.129\n",
      "F1: 0.408\n",
      "Recall: 0.732\n",
      "Precision: 0.283\n",
      "Accuracy: 0.176\n",
      "F1: 0.299\n",
      "Recall: 1.000\n",
      "Precision: 0.176\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,12,123,1234,12345]:\n",
    "    print(seed)\n",
    "    naive_model = DPLabelModel(m=m_per_task, \n",
    "                               T=1,\n",
    "                               edges=[],\n",
    "                               coverage_sets=[[0,]]*m_per_task,\n",
    "                               mu_sharing=[[i,] for i in range(m_per_task)],\n",
    "                               phi_sharing=[],\n",
    "                               device=device,\n",
    "                               class_balance=torch.FloatTensor([0.6,0.4]).to(device), \n",
    "                               seed=seed)\n",
    "    optimize(naive_model, L_hat=MRI_data_naive['Li_train'], num_iter=5000, lr=1e-3,\n",
    "             momentum=0.8, clamp=False, seed=seed)\n",
    "    #4.087885261759692e-05\n",
    "\n",
    "    R_pred = naive_model.predict(MRI_data_naive['Li_dev'])\n",
    "    for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        score = metric_score(MRI_data_naive['R_dev'].cpu(), R_pred.cpu(), metric)\n",
    "        print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "\n",
    "    # Flipping params\n",
    "    print(\"Flipping Parameters\")\n",
    "    naive_model.flip_params()\n",
    "    R_pred_flipped = naive_model.predict(MRI_data_naive['Li_dev'])\n",
    "    for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        score = metric_score(MRI_data_naive['R_dev'].cpu(), R_pred_flipped.cpu(), metric)\n",
    "        print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "        \n",
    "    #FLipping Labels\n",
    "    R_pred_flipped[R_pred_flipped == 1.0] = -1.0\n",
    "    R_pred_flipped[R_pred_flipped == 0.0] = 1.0\n",
    "    R_pred_flipped[R_pred_flipped == -1.0] = 1.0\n",
    "    \n",
    "    for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        score = metric_score(MRI_data_naive['R_dev'].cpu(), R_pred_flipped.cpu(), metric)\n",
    "        print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Accuracy: 0.901\n",
      "F1: 0.738\n",
      "Recall: 0.789\n",
      "Precision: 0.693\n",
      "\n",
      "Accuracy: 0.157\n",
      "F1: 0.184\n",
      "Recall: 0.540\n",
      "Precision: 0.111\n",
      "\n",
      "Accuracy: 0.880\n",
      "F1: 0.619\n",
      "Recall: 0.555\n",
      "Precision: 0.700\n",
      "\n",
      "Accuracy: 0.939\n",
      "F1: 0.827\n",
      "Recall: 0.836\n",
      "Precision: 0.819\n",
      "\n",
      "Accuracy: 0.244\n",
      "F1: 0.089\n",
      "Recall: 0.211\n",
      "Precision: 0.057\n",
      "\n",
      "Accuracy: 0.777\n",
      "F1: 0.163\n",
      "Recall: 0.123\n",
      "Precision: 0.239\n",
      "\n",
      "Accuracy: 0.608\n",
      "F1: 0.239\n",
      "Recall: 0.349\n",
      "Precision: 0.181\n",
      "\n",
      "Accuracy: 0.238\n",
      "F1: 0.008\n",
      "Recall: 0.018\n",
      "Precision: 0.005\n",
      "\n",
      "Accuracy: 0.232\n",
      "F1: 0.041\n",
      "Recall: 0.092\n",
      "Precision: 0.026\n",
      "\n",
      "Accuracy: 0.880\n",
      "F1: 0.552\n",
      "Recall: 0.420\n",
      "Precision: 0.805\n",
      "\n",
      "[50, 3, DPLabelModel(), 0.9385665529010239, 0.8271889400921659, 0.8355314197051978, 0.8190114068441064]\n",
      "CPU times: user 2min 22s, sys: 3.34 s, total: 2min 25s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best = None\n",
    "for iterations in [50]:\n",
    "    print(iterations)\n",
    "    max_seed = 10\n",
    "    temporal_models = [None,]*max_seed\n",
    "    for seed in range(max_seed):\n",
    "        markov_model = DPLabelModel(m=m_per_task*T, \n",
    "                                    T=T,\n",
    "                                    edges=[(i,i+m_per_task) for i in range((T-1)*m_per_task)],\n",
    "                                    coverage_sets=[[t,] for t in range(T) for _ in range(m_per_task)],\n",
    "                                    mu_sharing=[[t*m_per_task+i for t in range(T)] for i in range(m_per_task)],\n",
    "                                    phi_sharing=[[(t*m_per_task+i, (t+1)*m_per_task+i)\n",
    "                                                  for t in range(T-1)] for i in range(m_per_task)],\n",
    "                                    device=device,\n",
    "                                    # class_balance=MRI_data_temporal['class_balance'],\n",
    "                                    seed=seed)\n",
    "        optimize(markov_model, L_hat=MRI_data_temporal['Li_train'], num_iter=iterations,\n",
    "                 lr=1e-5, momentum=0.8, clamp=True, \n",
    "                 verbose=False, seed=seed)\n",
    "        temporal_models[seed] = markov_model\n",
    "    \n",
    "    for seed, model in enumerate(temporal_models):\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "        Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "        R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "        #find sequence label config. with highest prob.\n",
    "        config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "        R_pred_config = model.feasible_y[config_index]\n",
    "        R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "        R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "        for idx in range(R_pred_config.shape[0]):\n",
    "            R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "        R_pred_probs = R_pred_probs.numpy()\n",
    "        R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "        R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "        R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "        scores = [iterations, seed, model]\n",
    "        for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "            score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "            print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "            \n",
    "            scores.append(score)\n",
    "        \n",
    "        if best == None or scores[4] > best[4]:\n",
    "            best = scores\n",
    "        print()\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.939\n",
      "F1: 0.827\n",
      "Recall: 0.836\n",
      "Precision: 0.819\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "#find sequence label config. with highest prob.\n",
    "config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "R_pred_config = model.feasible_y[config_index]\n",
    "R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "#for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "for idx in range(R_pred_config.shape[0]):\n",
    "    R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "R_pred_probs = R_pred_probs.numpy()\n",
    "R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "#find sequence label config. with highest prob.\n",
    "config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "R_pred_config = model.feasible_y[config_index]\n",
    "R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "#for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "for idx in range(R_pred_config.shape[0]):\n",
    "    R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "R_pred_probs = R_pred_probs.numpy()\n",
    "R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "scores = [iterations]\n",
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/ts_labelmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/ts_labelmodel.pth').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions for everything and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sparse\n",
    "import pickle\n",
    "import rekall\n",
    "from rekall.video_interval_collection import VideoIntervalCollection\n",
    "from rekall.interval_list import IntervalList\n",
    "from rekall.temporal_predicates import *\n",
    "from metal.label_model.baselines import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load manually annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 18585.30it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 58985.69it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/manually_annotated_shots.pkl', 'rb') as f:\n",
    "    shots = VideoIntervalCollection(pickle.load(f))\n",
    "with open('../../data/shot_detection_folds.pkl', 'rb') as f:\n",
    "    shot_detection_folds = pickle.load(f)\n",
    "clips = shots.dilate(1).coalesce().dilate(-1)\n",
    "shot_boundaries = shots.map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.start, intrvl.payload)\n",
    ").set_union(\n",
    "    shots.map(lambda intrvl: (intrvl.end + 1, intrvl.end + 1, intrvl.payload))\n",
    ").coalesce()\n",
    "boundary_frames = {\n",
    "    video_id: [\n",
    "        intrvl.start\n",
    "        for intrvl in shot_boundaries.get_intervallist(video_id).get_intervals()\n",
    "    ]\n",
    "    for video_id in shot_boundaries.get_allintervals()\n",
    "}\n",
    "video_ids = sorted(list(clips.get_allintervals().keys()))\n",
    "frames_per_video = {\n",
    "    video_id: sorted([\n",
    "        f\n",
    "        for interval in clips.get_intervallist(video_id).get_intervals()\n",
    "        for f in range(interval.start, interval.end + 2)\n",
    "    ])\n",
    "    for video_id in video_ids\n",
    "}\n",
    "ground_truth = {\n",
    "    video_id: [\n",
    "        1 if f in boundary_frames[video_id] else 2\n",
    "        for f in frames_per_video[video_id]\n",
    "    ] \n",
    "    for video_id in video_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label matrix with all frames in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/all_labels.pkl', 'rb') as f:\n",
    "    weak_labels_all_movies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load videos and number of frames per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/frame_counts.pkl', 'rb') as f:\n",
    "    frame_counts = pickle.load(f)\n",
    "video_ids_all = sorted(list(frame_counts.keys()))\n",
    "video_ids_train = sorted(list(set(video_ids_all).difference(set(video_ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct windows for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct windows of 16 frames for each video\n",
    "windows = VideoIntervalCollection({\n",
    "    video_id: [\n",
    "        (f, f + 16, video_id)\n",
    "        for f in range(0, frame_counts[video_id] - 16, 8)\n",
    "    ]\n",
    "    for video_id in video_ids_all\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ground truth labels for all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, intersect the windows with ground truth and get ground truth labels for the windows\n",
    "windows_intersecting_ground_truth = windows.filter_against(\n",
    "    clips,\n",
    "    predicate=overlaps()\n",
    ").map(lambda intrvl: (intrvl.start, intrvl.end, 2))\n",
    "windows_with_shot_boundaries = windows_intersecting_ground_truth.filter_against(\n",
    "    shot_boundaries,\n",
    "    predicate = lambda window, shot_boundary:\n",
    "        shot_boundary.start >= window.start and shot_boundary.start < window.end\n",
    ").map(\n",
    "    lambda intrvl: (intrvl.start, intrvl.end, 1)\n",
    ")\n",
    "windows_with_labels = windows_with_shot_boundaries.set_union(\n",
    "    windows_intersecting_ground_truth\n",
    ").coalesce(\n",
    "    predicate = equal(),\n",
    "    payload_merge_op = lambda p1, p2: min(p1, p2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weak labels for all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label windows with the weak labels in our labeling functions\n",
    "def label_window(per_frame_weak_labels):\n",
    "    if 1 in per_frame_weak_labels:\n",
    "        return 1\n",
    "    if len([l for l in per_frame_weak_labels if l == 2]) >= len(per_frame_weak_labels) / 2:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "windows_with_weak_labels = windows.map(\n",
    "    lambda window: (\n",
    "        window.start,\n",
    "        window.end,\n",
    "        [\n",
    "            label_window([\n",
    "                lf[window.payload][f-1]\n",
    "                for f in range(window.start, window.end)\n",
    "            ])\n",
    "            for lf in weak_labels_all_movies\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_everything_windows = csr_matrix([\n",
    "    intrvl.payload\n",
    "    for video_id in sorted(list(video_ids_all))\n",
    "    for intrvl in windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_everything_windows.npy', 'wb') as f:\n",
    "    np.save(f, L_everything_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/L_everything_windows.npy', 'rb') as f:\n",
    "    L_everything_windows = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert L matrix to timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 5\n",
    "m_per_task = L_everything_windows.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_unlabelled = torch.FloatTensor(L_everything_windows[:L_everything_windows.shape[0] -\n",
    "                                                      (L_everything_windows.shape[0] % T)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_per_task_unlabelled = L_unlabelled.size(1)\n",
    "n_frames_unlabelled = L_unlabelled.size(0)\n",
    "n_patients_unlabelled = n_frames_unlabelled//T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_unlabelled_ts = torch.LongTensor(\n",
    "    L_unlabelled.view(n_patients_unlabelled, (m_per_task*T)).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_unlabelled_ts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n"
     ]
    }
   ],
   "source": [
    "predictions_everything = []\n",
    "for i in range(0, L_unlabelled_ts.shape[0], 100000):\n",
    "    print(i)\n",
    "    start = i\n",
    "    end = i + 100000\n",
    "    labels = L_unlabelled_ts[start:end] if end < L_unlabelled_ts.shape[0] else L_unlabelled_ts[start:]\n",
    "    predictions_for_labels = model.eval().predict_proba(labels.to(device))\n",
    "    predictions_everything.append(predictions_for_labels.detach().cpu())\n",
    "    del predictions_for_labels\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_everything_together = torch.cat(predictions_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred_frame = predictions_everything_together\n",
    "\n",
    "#find sequence label config. with highest prob.\n",
    "config_index = np.argmax(R_pred_frame, axis=1)\n",
    "R_pred_config = model.feasible_y[config_index].detach().cpu()\n",
    "R_pred_max = torch.FloatTensor(np.max(R_pred_frame.numpy(), axis=1))\n",
    "\n",
    "#for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "for idx in range(R_pred_config.shape[0]):\n",
    "    R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:]).float()*R_pred_max[idx]\n",
    "\n",
    "R_pred_probs = R_pred_probs.numpy()\n",
    "R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "R_pred_probs_per_frame = R_pred_probs.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_nums = [\n",
    "    (video_id, intrvl.start, intrvl.end)\n",
    "    for video_id in sorted(list(video_ids_all))\n",
    "    for intrvl in windows_with_weak_labels.get_intervallist(video_id).get_intervals()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_save_windows = [\n",
    "    (window_info, np.array([prediction, 1. - prediction]))\n",
    "    for window_info, prediction in zip(window_nums, R_pred_probs_per_frame)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we needed to cut the predictions to a multiple of T\n",
    "last_preds = []\n",
    "for window_info in window_nums[len(predictions_to_save_windows):]:\n",
    "    last_preds.append((window_info, np.array([0., 1.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_save_windows += last_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np_windows = np.array(predictions_to_save_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to disk\n",
    "with open('../../data/shot_detection_weak_labels/ts_weak_labels_all_windows.npy', 'wb') as f:\n",
    "    np.save(f, preds_np_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution compared to Metal LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(1, 0, 16), array([0., 1.])],\n",
       "       [(1, 8, 24), array([0., 1.])],\n",
       "       [(1, 16, 32), array([0., 1.])],\n",
       "       [(1, 24, 40), array([0., 1.])],\n",
       "       [(1, 32, 48), array([0., 1.])],\n",
       "       [(1, 40, 56), array([0.01515144, 0.98484856])],\n",
       "       [(1, 48, 64), array([0.98484856, 0.01515144])],\n",
       "       [(1, 56, 72), array([0.98484856, 0.01515144])],\n",
       "       [(1, 64, 80), array([0.01515144, 0.98484856])],\n",
       "       [(1, 72, 88), array([0.01515144, 0.98484856])]], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np_windows[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12350523, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/noisy_labels_all_windows.npy', 'rb') as f:\n",
    "    preds_np_windows_metal = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(1, 0, 16), array([0.0032828, 0.9967172])],\n",
       "       [(1, 8, 24), array([0.0032828, 0.9967172])],\n",
       "       [(1, 16, 32), array([0.0032828, 0.9967172])],\n",
       "       [(1, 24, 40), array([0.0032828, 0.9967172])],\n",
       "       [(1, 32, 48), array([0.0032828, 0.9967172])],\n",
       "       [(1, 40, 56), array([0.24933879, 0.75066121])],\n",
       "       [(1, 48, 64), array([0.98051349, 0.01948651])],\n",
       "       [(1, 56, 72), array([0.36412127, 0.63587873])],\n",
       "       [(1, 64, 80), array([0.0032828, 0.9967172])],\n",
       "       [(1, 72, 88), array([0.0032828, 0.9967172])]], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np_windows_metal[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12350523, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np_windows_metal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Distribution across all data, timeseries LabelModel')\n",
    "ax.hist([\n",
    "    i[1][0]\n",
    "    for i in preds_np_windows\n",
    "])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Distribution across all data, Metal LabelModel')\n",
    "ax.hist([\n",
    "    i[1][0]\n",
    "    for i in preds_np_windows_metal\n",
    "])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/shot_detection_weak_labels/majority_vote_labels_all_windows.npy', 'rb') as f:\n",
    "    preds_np_windows_mv = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Distribution across all data, Majority Vote')\n",
    "ax.hist([\n",
    "    i[1][0]\n",
    "    for i in preds_np_windows_mv\n",
    "])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff (bad class balance, wrong R_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 s, sys: 1.6 s, total: 43.4 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "max_seed = 10\n",
    "temporal_models = [None,]*max_seed\n",
    "for seed in range(max_seed):\n",
    "    markov_model = DPLabelModel(m=m_per_task*T, \n",
    "                                T=T,\n",
    "                                edges=[(i,i+m_per_task) for i in range((T-1)*m_per_task)],\n",
    "                                coverage_sets=[[t,] for t in range(T) for _ in range(m_per_task)],\n",
    "                                mu_sharing=[[t*m_per_task+i for t in range(T)] for i in range(m_per_task)],\n",
    "                                phi_sharing=[[(t*m_per_task+i, (t+1)*m_per_task+i) for t in range(T-1)] for i in range(m_per_task)],\n",
    "                                device=device,\n",
    "                                # class_balance=MRI_data_temporal['class_balance'],\n",
    "                                seed=seed)\n",
    "    optimize(markov_model, L_hat=MRI_data_temporal['Li_train'], num_iter=10, lr=1e-5, momentum=0.8, clamp=True, \n",
    "             verbose=False, seed=seed)\n",
    "    temporal_models[seed] = markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7325,)\n",
      "Accuracy: 0.357\n",
      "F1: 0.090\n",
      "Recall: 0.182\n",
      "Precision: 0.060\n",
      "(7325,)\n",
      "Accuracy: 0.369\n",
      "F1: 0.184\n",
      "Recall: 0.404\n",
      "Precision: 0.119\n",
      "(7325,)\n",
      "Accuracy: 0.523\n",
      "F1: 0.218\n",
      "Recall: 0.377\n",
      "Precision: 0.153\n",
      "(7325,)\n",
      "Accuracy: 0.388\n",
      "F1: 0.225\n",
      "Recall: 0.506\n",
      "Precision: 0.145\n",
      "(7325,)\n",
      "Accuracy: 0.375\n",
      "F1: 0.234\n",
      "Recall: 0.542\n",
      "Precision: 0.149\n",
      "(7325,)\n",
      "Accuracy: 0.668\n",
      "F1: 0.344\n",
      "Recall: 0.494\n",
      "Precision: 0.263\n",
      "(7325,)\n",
      "Accuracy: 0.580\n",
      "F1: 0.086\n",
      "Recall: 0.112\n",
      "Precision: 0.069\n",
      "(7325,)\n",
      "Accuracy: 0.509\n",
      "F1: 0.154\n",
      "Recall: 0.254\n",
      "Precision: 0.111\n",
      "(7325,)\n",
      "Accuracy: 0.277\n",
      "F1: 0.024\n",
      "Recall: 0.050\n",
      "Precision: 0.015\n",
      "(7325,)\n",
      "Accuracy: 0.544\n",
      "F1: 0.279\n",
      "Recall: 0.500\n",
      "Precision: 0.193\n"
     ]
    }
   ],
   "source": [
    "for seed, model in enumerate(temporal_models):\n",
    "    Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "    R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "    #find sequence label config. with highest prob.\n",
    "    config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "    R_pred_config = model.feasible_y[config_index]\n",
    "    R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "    #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "    R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "    for idx in range(R_pred_config.shape[0]):\n",
    "        R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "    R_pred_probs = R_pred_probs.numpy()\n",
    "    R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "\n",
    "    Li_dev = torch.LongTensor(MRI_data_temporal['Li_dev'].cpu().numpy())\n",
    "    R_pred_frame = model.predict_proba(Li_dev.to(device)) #predict per sequence\n",
    "\n",
    "    #find sequence label config. with highest prob.\n",
    "    config_index = np.argmax(R_pred_frame.detach().cpu().numpy(), axis=1) \n",
    "    R_pred_config = model.feasible_y[config_index]\n",
    "    R_pred_max = torch.FloatTensor(np.max(R_pred_frame.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "    #for each 1 in config, multiply by prob. label for sequence (1-prob label otherwise)\n",
    "    R_pred_probs = torch.FloatTensor(R_pred_config.shape)\n",
    "    for idx in range(R_pred_config.shape[0]):\n",
    "        R_pred_probs[idx,:] = torch.LongTensor(R_pred_config[idx,:].cpu()).float()*R_pred_max[idx]\n",
    "\n",
    "    R_pred_probs = R_pred_probs.numpy()\n",
    "    R_pred_probs[R_pred_probs < 0] = 1+R_pred_probs[R_pred_probs < 0]\n",
    "    R_pred_frame_label = np.round(R_pred_probs.ravel())\n",
    "    R_pred_frame_label[R_pred_frame_label == 0.] = 2.\n",
    "\n",
    "    for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        score = metric_score(Y_dev.cpu(), R_pred_frame_label, metric)\n",
    "        print(f\"{metric.capitalize()}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0  accuracy=0.207  F1=0.294  precision=0.175 recall=0.931 \n",
      "seed=1  accuracy=0.208  F1=0.270  precision=0.161 recall=0.823 \n",
      "seed=2  accuracy=0.730  F1=0.168  precision=0.185 recall=0.154 \n",
      "seed=3  accuracy=0.182  F1=0.300  precision=0.177 recall=0.988 \n",
      "seed=4  accuracy=0.196  F1=0.283  precision=0.168 recall=0.892 \n",
      "seed=5  accuracy=0.674  F1=0.143  precision=0.134 recall=0.154 \n",
      "seed=6  accuracy=0.812  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=7  accuracy=0.499  F1=0.193  precision=0.135 recall=0.338 \n",
      "seed=8  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=9  accuracy=0.639  F1=0.470  precision=0.318 recall=0.904 \n"
     ]
    }
   ],
   "source": [
    "# num_iter=1 (20s wall time)\n",
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    pre = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'precision')\n",
    "    rec = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'recall')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}  precision={pre:.3f} recall={rec:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=2  accuracy=0.616  F1=0.228  precision=0.177 recall=0.319 \n",
      "seed=3  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=4  accuracy=0.174  F1=0.293  precision=0.173 recall=0.965 \n",
      "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=8  accuracy=0.739  F1=0.073  precision=0.098 recall=0.058 \n",
      "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n"
     ]
    }
   ],
   "source": [
    "# num_iter=10 (40s wall time)\n",
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    pre = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'precision')\n",
    "    rec = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'recall')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}  precision={pre:.3f} recall={rec:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=2  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=3  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=4  accuracy=0.661  F1=0.347  precision=0.263 recall=0.508 \n",
      "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=8  accuracy=0.386  F1=0.334  precision=0.207 recall=0.865 \n",
      "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n"
     ]
    }
   ],
   "source": [
    "# num_iter=50 (2 min 25s wall time)\n",
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    pre = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'precision')\n",
    "    rec = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'recall')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}  precision={pre:.3f} recall={rec:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=2  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=3  accuracy=0.621  F1=0.224  precision=0.176 recall=0.308 \n",
      "seed=4  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=8  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
      "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n"
     ]
    }
   ],
   "source": [
    "# num_iter=100 (4 min 28s wall time)\n",
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    pre = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'precision')\n",
    "    rec = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'recall')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}  precision={pre:.3f} recall={rec:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=0  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=1  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=2  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=3  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=4  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=5  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=6  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=7  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=8  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
      "seed=9  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n"
     ]
    }
   ],
   "source": [
    "# num_iter=500 (22 min 2s wall time)\n",
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    pre = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'precision')\n",
    "    rec = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'recall')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}  precision={pre:.3f} recall={rec:.3f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on runs\n",
    "\n",
    "```\n",
    "1 iteration:\n",
    "seed=0  accuracy=0.207  F1=0.294  precision=0.175 recall=0.931 \n",
    "seed=1  accuracy=0.208  F1=0.270  precision=0.161 recall=0.823 \n",
    "seed=2  accuracy=0.730  F1=0.168  precision=0.185 recall=0.154 \n",
    "seed=3  accuracy=0.182  F1=0.300  precision=0.177 recall=0.988 \n",
    "seed=4  accuracy=0.196  F1=0.283  precision=0.168 recall=0.892 \n",
    "seed=5  accuracy=0.674  F1=0.143  precision=0.134 recall=0.154 \n",
    "seed=6  accuracy=0.812  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=7  accuracy=0.499  F1=0.193  precision=0.135 recall=0.338 \n",
    "seed=8  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=9  accuracy=0.639  F1=0.470  precision=0.318 recall=0.904\n",
    "\n",
    "10 iterations:\n",
    "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=2  accuracy=0.616  F1=0.228  precision=0.177 recall=0.319 \n",
    "seed=3  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=4  accuracy=0.174  F1=0.293  precision=0.173 recall=0.965 \n",
    "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=8  accuracy=0.739  F1=0.073  precision=0.098 recall=0.058 \n",
    "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000\n",
    "\n",
    "50 iterations:\n",
    "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=2  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=3  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=4  accuracy=0.661  F1=0.347  precision=0.263 recall=0.508 \n",
    "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=8  accuracy=0.386  F1=0.334  precision=0.207 recall=0.865 \n",
    "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "\n",
    "100 iterations:\n",
    "seed=0  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=1  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=2  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=3  accuracy=0.621  F1=0.224  precision=0.176 recall=0.308 \n",
    "seed=4  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=5  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=6  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=7  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=8  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "seed=9  accuracy=0.177  F1=0.301  precision=0.177 recall=1.000 \n",
    "\n",
    "500 iterations:\n",
    "seed=0  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=1  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=2  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=3  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=4  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=5  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=6  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=7  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=8  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "seed=9  accuracy=0.823  F1=0.000  precision=0.000 recall=0.000 \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
