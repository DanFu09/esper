{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercut Template\n",
    "A notebook to copy to make supercuts from. Subject to change based on experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:14:34.760518Z",
     "start_time": "2019-01-09T20:14:33.887764Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.supercuts import *\n",
    "from query.models import Shot\n",
    "from rekall.temporal_predicates import overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:14:36.532402Z",
     "start_time": "2019-01-09T20:14:36.281802Z"
    }
   },
   "outputs": [],
   "source": [
    "def query():\n",
    "    # Takes 7min to run!\n",
    "    from query.models import Face, Shot\n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    from rekall.parsers import in_array, bbox_payload_parser, merge_dict_parsers, dict_payload_parser\n",
    "    from rekall.merge_ops import payload_plus\n",
    "    from rekall.payload_predicates import payload_satisfies\n",
    "    from rekall.spatial_predicates import scene_graph\n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    from rekall.face_landmark_predicates import looking_left, looking_right\n",
    "    from rekall.bbox_predicates import height_at_least, same_height\n",
    "    import esper.face_landmarks_wrapper as flw\n",
    "    from esper.rekall import intrvllists_to_result_with_objects, bbox_to_result_object\n",
    "    from esper.stdlib import face_landmarks_to_dict\n",
    "    import numpy as np\n",
    "    \n",
    "    MAX_MOUTH_DIFF = 0.12\n",
    "    MIN_FACE_CONFIDENCE = 0.8\n",
    "    MIN_FACE_HEIGHT = 0.5\n",
    "    MAX_FACE_HEIGHT_DIFF = 0.1\n",
    "    MIN_FACE_OVERLAP_X = 0.05\n",
    "    MIN_FACE_OVERLAP_Y = 0.2\n",
    "    MAX_FACE_OVERLAP_X_FRACTION = 0.6\n",
    "    \n",
    "    def map_payload(func):\n",
    "        def map_fn(intvl):\n",
    "            intvl.payload = func(intvl.payload)\n",
    "            return intvl\n",
    "        return map_fn\n",
    "    \n",
    "    def get_landmarks(faces):\n",
    "        ids = [face['id'] for face in faces]\n",
    "        try:\n",
    "            landmarks = flw.get(Face.objects.filter(id__in=ids))\n",
    "        except:\n",
    "            print(\"Error getting landmarks:\", ids)\n",
    "            return []\n",
    "        for face, landmark in zip(faces, landmarks):\n",
    "            face['landmarks'] = landmark\n",
    "        return faces\n",
    "\n",
    "    # Annotate face rows with start and end frames and the video ID\n",
    "    faces_qs = Face.objects.filter(probability__gte=MIN_FACE_CONFIDENCE).annotate(\n",
    "        min_frame=F('frame__number'),\n",
    "        max_frame=F('frame__number'),\n",
    "        height = F('bbox_y2')-F('bbox_y1'),\n",
    "        video_id=F('frame__video_id')).filter(height__gte=MIN_FACE_HEIGHT)\n",
    "\n",
    "    faces = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs,\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'id': 'id'})\n",
    "        ]))\n",
    "    ).coalesce(payload_merge_op=payload_plus)\n",
    "\n",
    "    graph = {\n",
    "        'nodes': [\n",
    "            { 'name': 'face_left', 'predicates': [] },\n",
    "            { 'name': 'face_right', 'predicates': [] },\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'face_left', 'end':'face_right', 'predicates': [\n",
    "                lambda f1, f2: f1['x2'] < f2['x2'] and f1['x1']<f2['x1'], # Left face on the left\n",
    "                lambda f1, f2: f1['x2'] - f2['x1'] > MIN_FACE_OVERLAP_X, # Faces overlap\n",
    "                lambda f1, f2: min(f1['y2'], f2['y2'])-max(f1['y1'], f1['y1']) > MIN_FACE_OVERLAP_Y,\n",
    "                lambda f1, f2: f1['y2'] > f2['y1'] and f1['y1'] < f2['y2'],  # No face is entirely above another\n",
    "                same_height(MAX_FACE_HEIGHT_DIFF),\n",
    "                lambda f1, f2: (f1['x2']-f2['x1'])/max(f1['x2']-f1['x1'], f2['x2']-f2['x1']) < MAX_FACE_OVERLAP_X_FRACTION\n",
    "\n",
    "            ]},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    def mouths_are_close(lm1, lm2):\n",
    "        select_outer=[2,3,4,8,9,10]\n",
    "        select_inner=[1,2,3,5,6,7]\n",
    "        mouth1 = np.concatenate((lm1.outer_lips()[select_outer], lm1.inner_lips()[select_inner]))\n",
    "        mouth2 = np.concatenate((lm2.outer_lips()[select_outer], lm2.inner_lips()[select_inner]))\n",
    "        mean1 = np.mean(mouth1, axis=0)\n",
    "        mean2 = np.mean(mouth2, axis=0)\n",
    "        return np.linalg.norm(mean1-mean2) <= MAX_MOUTH_DIFF\n",
    "\n",
    "    # Face is profile if both eyes are on the same side of the nose bridge horizontally.\n",
    "    def is_left_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = min(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] >= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] >= nose_x)\n",
    "        return left and right\n",
    "    def is_right_profile(f):\n",
    "        lm = f['landmarks']\n",
    "        nose_x = max(lm.nose_bridge()[:,0])\n",
    "        left = np.all(lm.left_eye()[:,0] <= nose_x)\n",
    "        right = np.all(lm.right_eye()[:,0] <= nose_x)\n",
    "        return left and right\n",
    "        \n",
    "    graph2 = {\n",
    "        'nodes': [\n",
    "            {'name': 'left', 'predicates': [is_right_profile]},\n",
    "            {'name': 'right', 'predicates': [is_left_profile]},\n",
    "        ],\n",
    "        'edges': [\n",
    "            {'start': 'left', 'end':'right', 'predicates':[\n",
    "                lambda l, r: mouths_are_close(l['landmarks'], r['landmarks'])\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    mf_up_close = faces.filter(payload_satisfies(\n",
    "        scene_graph(graph, exact=True))).map(map_payload(get_landmarks)).filter(\n",
    "        payload_satisfies(scene_graph(graph2, exact=True)))\n",
    "\n",
    "    vids = mf_up_close.get_allintervals().keys()\n",
    "    # Merge with shots\n",
    "    shots_qs = Shot.objects.filter(\n",
    "        video_id__in = vids,\n",
    "        labeler=Labeler.objects.get(name='shot-hsvhist-face')\n",
    "    ).all()\n",
    "    total = shots_qs.count()\n",
    "    print(\"Total shots:\", total)\n",
    "    # use emtpy list as payload\n",
    "    shots = VideoIntervalCollection.from_django_qs(\n",
    "        shots_qs,\n",
    "        with_payload=lambda row:[],\n",
    "        progress=True,\n",
    "        total=total\n",
    "    )\n",
    "    kissing_shots = mf_up_close.join(\n",
    "      shots,\n",
    "      lambda kiss, shot: [(kiss.get_start(), shot.get_end(), kiss.get_payload())],\n",
    "      predicate=overlaps(),\n",
    "      working_window=1\n",
    "    ).coalesce()\n",
    "\n",
    "    # Getting faces in the shot\n",
    "    print(\"Getting faces...\")\n",
    "    def wrap_in_list(intvl):\n",
    "        intvl.payload = [intvl.payload]\n",
    "        return intvl\n",
    "\n",
    "    faces_qs2 = Face.objects.filter(frame__video_id__in=vids,probability__gte=MIN_FACE_CONFIDENCE)\n",
    "    total = faces_qs2.count()\n",
    "    faces2 = VideoIntervalCollection.from_django_qs(\n",
    "        faces_qs2.annotate(\n",
    "            min_frame=F('frame__number'),\n",
    "            max_frame=F('frame__number'),\n",
    "            video_id=F('frame__video_id')\n",
    "        ),\n",
    "        with_payload=in_array(merge_dict_parsers([\n",
    "            bbox_payload_parser(VideoIntervalCollection.django_accessor),\n",
    "            dict_payload_parser(VideoIntervalCollection.django_accessor, {'frame': 'min_frame'})\n",
    "        ])),\n",
    "        progress=True,\n",
    "        total = total\n",
    "    ).coalesce(payload_merge_op=payload_plus).map(wrap_in_list)\n",
    "    \n",
    "    def clip_to_last_frame_with_two_faces(intvl):\n",
    "        faces = intvl.get_payload()[1]\n",
    "        frame = [f[0]['frame'] for f in faces if len(f)==2]\n",
    "        if len(frame) > 0:\n",
    "            intvl.end = frame[-1]\n",
    "        return intvl\n",
    "    \n",
    "    clipped_kissing_shots = kissing_shots.merge(\n",
    "        faces2,\n",
    "        payload_merge_op = lambda p1, p2: (p1, p2),\n",
    "        predicate=overlaps(),\n",
    "        working_window=1\n",
    "    ).coalesce(payload_merge_op=lambda p1, p2: (p1[0], p1[1]+p2[1])).map(\n",
    "        clip_to_last_frame_with_two_faces)\n",
    "    \n",
    "    return clipped_kissing_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:28:38.620897Z",
     "start_time": "2019-01-09T20:28:38.560626Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_supercut_intervals(\n",
    "    interval_collection,\n",
    "    dilation=0,\n",
    "    snap_to_cinematic_shots=False,\n",
    "    limit=None,\n",
    "    stride=1,\n",
    "    max_length=None\n",
    "):\n",
    "    '''\n",
    "    Generates supercut intervals for the supercut pipeline.\n",
    "    Dilates interval_collection by dilation.\n",
    "    If dilation > 0, snaps the dilations to cinematic shot boundaries.\n",
    "    '''\n",
    "    if dilation > 0:\n",
    "        if snap_to_cinematic_shots:\n",
    "            shots = VideoIntervalCollection.from_django_qs(\n",
    "                Shot.objects.filter(\n",
    "                    video_id__in=list(interval_collection.get_allintervals().keys()),\n",
    "                    labeler__name=\"shot-hsvhist-face\"\n",
    "                )\n",
    "            ).filter_against(interval_collection, predicate=overlaps())\n",
    "        interval_collection = interval_collection.dilate(dilation).coalesce()\n",
    "        if snap_to_cinematic_shots:\n",
    "            interval_collection = interval_collection.overlaps(shots)\n",
    "    \n",
    "    supercut_intervals = []\n",
    "    for video_id in sorted(list(interval_collection.get_allintervals().keys())):\n",
    "        intervallist = interval_collection.get_intervallist(video_id)\n",
    "        for intrvl in intervallist.get_intervals():\n",
    "            if max_length is None:\n",
    "                supercut_intervals.append((video_id, intrvl.get_start(), intrvl.get_end()))\n",
    "            else:\n",
    "                supercut_intervals.append((video_id, intrvl.get_start(), min(intrvl.get_end(), intrvl.get_start() + max_length)))\n",
    "            \n",
    "    if limit is not None:\n",
    "        return supercut_intervals[:limit * stride:stride]\n",
    "    \n",
    "    return supercut_intervals[::stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:14:44.853498Z",
     "start_time": "2019-01-09T20:14:44.814610Z"
    }
   },
   "outputs": [],
   "source": [
    "# output path\n",
    "OUTPUT_PATH = '/app/result/supercut/kissing.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:18:48.755128Z",
     "start_time": "2019-01-09T20:14:45.821240Z"
    }
   },
   "outputs": [],
   "source": [
    "query_results = query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:36:37.227760Z",
     "start_time": "2019-01-09T20:36:33.814499Z"
    }
   },
   "outputs": [],
   "source": [
    "supercut_intervals = generate_supercut_intervals(\n",
    "    query_results, limit=None, stride=1, dilation=12, snap_to_cinematic_shots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:42:10.018781Z",
     "start_time": "2019-01-09T20:36:50.955109Z"
    }
   },
   "outputs": [],
   "source": [
    "stitch_video_temporal(\n",
    "    supercut_intervals,\n",
    "    out_path=OUTPUT_PATH, width=640, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
