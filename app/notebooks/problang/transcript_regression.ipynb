{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:13:13.587230Z",
     "start_time": "2018-12-03T19:13:03.538310Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "import pyro.infer as infer\n",
    "from torch.utils.data import DataLoader\n",
    "from transcript_utils import *\n",
    "from timeit import default_timer as now\n",
    "from custom_mlp import MLP, Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:17:51.365869Z",
     "start_time": "2018-12-03T22:17:49.721485Z"
    }
   },
   "outputs": [],
   "source": [
    "mi_dict = {ngram: score for [ngram, score] in mutual_info('immigration')}\n",
    "mi_priors = torch.tensor([mi_dict[ngram] if ngram in mi_dict else 0 for ngram in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:17:51.394645Z",
     "start_time": "2018-12-03T22:17:51.368488Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in ['immigration', 'border', 'healthcare']:\n",
    "    print('{} {:.4f}'.format(k, mi_priors[vocabulary.index(k)].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:28.625805Z",
     "start_time": "2018-12-03T05:06:28.597004Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute_vectors(video_list(), vocabulary, SEGMENT_SIZE, SEGMENT_STRIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:18:01.038558Z",
     "start_time": "2018-12-03T22:18:00.970853Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "    \n",
    "    def model(self, x, y):\n",
    "        # Create unit normal priors over the parameters\n",
    "        loc, scale = mi_priors, torch.ones(self.p) * 10\n",
    "        bias_loc, bias_scale = torch.zeros(1), torch.ones(1) * 10\n",
    "        w_prior = dist.Normal(loc, scale).independent(1)\n",
    "        b_prior = dist.Normal(bias_loc, bias_scale).independent(1)\n",
    "        priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "        # lift module parameters to random variables sampled from the priors\n",
    "        lifted_module = pyro.random_module(\"module\", self, priors)\n",
    "        # sample a regressor (which also samples w and b)\n",
    "        lifted_reg_model = lifted_module()\n",
    "        with pyro.iarange(\"map\", x.shape[0]):\n",
    "            # run the regressor forward conditioned on data\n",
    "            prediction_mean = lifted_reg_model(x).squeeze(-1)\n",
    "            # condition on the observed data\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(prediction_mean), obs=y)                                                  \n",
    "\n",
    "    def guide(self, x, y):\n",
    "        # define our variational parameters\n",
    "        w_loc = torch.tensor(mi_priors)\n",
    "        # note that we initialize our scales to be pretty narrow\n",
    "        w_log_sig = torch.tensor(-3.0 * torch.ones(1, self.p) + 0.05 * torch.randn(1, self.p))\n",
    "        b_loc = torch.tensor(0.5) + 0.05 * torch.randn(1)\n",
    "        b_log_sig = torch.tensor(-3.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
    "        # register learnable params in the param store\n",
    "        mw_param = pyro.param(\"guide_mean_weight\", w_loc)\n",
    "        sw_param = self.softplus(pyro.param(\"guide_log_scale_weight\", w_log_sig))\n",
    "        mb_param = pyro.param(\"guide_mean_bias\", b_loc)\n",
    "        sb_param = self.softplus(pyro.param(\"guide_log_scale_bias\", b_log_sig))\n",
    "        # guide distributions for w and b\n",
    "        w_dist = dist.Normal(mw_param, sw_param).independent(1)\n",
    "        b_dist = dist.Normal(mb_param, sb_param).independent(1)\n",
    "        dists = {'linear.weight': w_dist, 'linear.bias': b_dist}\n",
    "        # overload the parameters in the module with random samples\n",
    "        # from the guide distributions\n",
    "        lifted_module = pyro.random_module(\"module\", self, dists)\n",
    "        # sample a regressor (which also samples w and b)\n",
    "        return lifted_module()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:13:42.455348Z",
     "start_time": "2018-12-03T19:13:42.209046Z"
    }
   },
   "outputs": [],
   "source": [
    "unsup_dataset = SegmentVectorDataset(video_list(), vocab_size=vocab_size)\n",
    "sup_dataset = LabeledSegmentDataset(unsup_dataset, pcache.get('labeled_segments'), categories=2)\n",
    "loader_params = {'shuffle': True}\n",
    "unsup_loader = DataLoader(unsup_dataset, batch_size=8, **loader_params)\n",
    "sup_loader = DataLoader(sup_dataset, batch_size=8, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:13:52.659669Z",
     "start_time": "2018-12-03T19:13:52.628446Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model_gen, x, y, iters=100):\n",
    "    samples = []\n",
    "    for _ in range(iters):\n",
    "        model = model_gen()\n",
    "        y_pred = model(x).squeeze(-1).round()\n",
    "        fp = torch.sum((y_pred != y) & (y_pred == 1)).item()\n",
    "        fn =  torch.sum((y_pred != y) & (y_pred == 0)).item()\n",
    "        acc = torch.sum(y_pred == y).item()\n",
    "        n = float(y_pred.shape[0])\n",
    "        samples.append(torch.tensor([acc/n, fp/n, fn/n]))\n",
    "    return torch.mean(torch.stack(samples), dim=0).tolist(), torch.std(torch.stack(samples), dim=0).tolist(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:14:09.408150Z",
     "start_time": "2018-12-03T19:14:08.111627Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data, y_data = unzip(list(sup_dataset))\n",
    "y_data = torch.tensor([y[1] for y in y_data])\n",
    "x_data = torch.stack(x_data)\n",
    "\n",
    "split = int(len(x_data) / 2)\n",
    "\n",
    "(train_x, val_x) = (x_data[:split], x_data[split:])\n",
    "(train_y, val_y) = (y_data[:split], y_data[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:12:29.756842Z",
     "start_time": "2018-12-03T22:12:29.724112Z"
    }
   },
   "outputs": [],
   "source": [
    "mi_priors_raw = torch.tensor([mi_dict[ngram] if ngram in mi_dict else 0 for ngram in vocabulary])\n",
    "def baseline_model(x):\n",
    "    return torch.mm(x, mi_priors_raw.unsqueeze(0).t()).squeeze()\n",
    "acc = get_accuracy(lambda: baseline_model,\n",
    "             x_data, y_data, iters=2)[0][0]\n",
    "\n",
    "print('Baseline accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:18:24.471714Z",
     "start_time": "2018-12-03T22:18:05.071568Z"
    }
   },
   "outputs": [],
   "source": [
    "regression_model = RegressionModel(vocab_size)\n",
    "\n",
    "def torch_trainer():\n",
    "    loss_fn = nn.MSELoss(size_average=False)\n",
    "    optim = torch.optim.Adam(regression_model.parameters(), lr=0.05)\n",
    "    \n",
    "    def train(x, y):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        return loss.item()\n",
    "        \n",
    "    return train, lambda: regression_model\n",
    "\n",
    "def pyro_trainer():\n",
    "    pyro.clear_param_store()\n",
    "    opt = optim.Adam({\"lr\": 0.01})\n",
    "    svi = infer.SVI(regression_model.model, regression_model.guide, opt, loss=infer.Trace_ELBO())\n",
    "    \n",
    "    def train(x, y):\n",
    "        return svi.step(x, y)\n",
    "    \n",
    "    return train, lambda: regression_model.guide(None, None)\n",
    "        \n",
    "num_iterations = 500\n",
    "train, model_gen = pyro_trainer()\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train(train_x, train_y)\n",
    "    if (j + 1) % 10 == 0:\n",
    "        [tacc, tfp, tfn], _ = get_accuracy(model_gen, train_x, train_y) \n",
    "        [vacc, vfp, vfn], [vaccstd, vfpstd, vfnstd] = get_accuracy(model_gen, val_x, val_y)\n",
    "        print(\"[iteration %04d] loss: %.0f, train: acc %.3f, val: acc %.3f (+/- %.3f) fp %.3f (+/- %.3f) fn %.3f (+/ %.3f)\" % \n",
    "              (j + 1, loss, tacc, vacc, vaccstd, vfp, vfpstd, vfn, vfnstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:17:30.902335Z",
     "start_time": "2018-12-03T22:17:30.872732Z"
    }
   },
   "outputs": [],
   "source": [
    "data = regression_model.guide(None, None)(x_data).squeeze(-1)\n",
    "print(data)\n",
    "print(data.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:07:54.922355Z",
     "start_time": "2018-12-03T22:07:54.883478Z"
    }
   },
   "outputs": [],
   "source": [
    "list(regression_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:29.045214Z",
     "start_time": "2018-12-03T05:06:18.342Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary.index('immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:29.046312Z",
     "start_time": "2018-12-03T05:06:18.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in regression_model.named_parameters():\n",
    "    if name == 'linear.weight':\n",
    "        weights = param.data.numpy().squeeze()\n",
    "        idx = np.argsort(weights)[::-1]\n",
    "        print(weights[idx])\n",
    "        print(np.array(vocabulary)[idx][:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
