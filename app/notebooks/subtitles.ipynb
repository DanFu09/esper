{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from query.datasets.prelude import *\n",
    "import pysrt\n",
    "import textacy\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcripts and compute time offsets for captions\n",
    "videos = list(Video.objects.all())\n",
    "\n",
    "def load_transcript(video):\n",
    "    base = os.path.split(os.path.splitext(video.path)[0])[1]\n",
    "    path = '/app/subs/{}.cc5.srt'.format(base)\n",
    "    if not os.path.isfile(path):\n",
    "        return None\n",
    "    subs = pysrt.open(path)\n",
    "    subs.shift(seconds=-5)\n",
    "    offsets = []\n",
    "    transcript = ''\n",
    "    for sub in subs:\n",
    "        offsets.append((len(transcript), sub.start, sub.end))\n",
    "        transcript += sub.text.replace('\\n', ' ').replace('>', ' ') + ' '\n",
    "    return (video, transcript, offsets)\n",
    "\n",
    "transcripts = par_for(load_transcript, videos[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transcripts into textacy Docs (implicitly performing various NLP tasks)\n",
    "texts, metadatas = unzip([\n",
    "    (t[1], {'path': t[0].path, 'offsets': t[2]})\n",
    "    for t in tqdm(transcripts)\n",
    "    if t is not None\n",
    "])\n",
    "\n",
    "with Timer('Creating corpus of {} docs'.format(len(texts))):\n",
    "    corpus = textacy.Corpus(u'en')\n",
    "    corpus.add_texts(texts, metadatas, n_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def token_time(doc, tok):\n",
    "    tok_offset = tok.idx\n",
    "    for i, (offset, start, end) in enumerate(doc.metadata['offsets']):\n",
    "        if tok_offset < offset:\n",
    "            return (start, end)\n",
    "    raise Exception(\"No token time?\")\n",
    "    \n",
    "def compute_tfidf(corpus):\n",
    "    gensim_dict = gensim.corpora.Dictionary(corpus)\n",
    "    gensim_corpus = [gensim_dict.doc2bow(text) for text in transcript_words]\n",
    "    tfidf_model = gensim.models.tfidfmodel.TfidfModel(gensim_corpus, normalize=True)\n",
    "    return {gensim_dict.get(id): value for doc in tfidf[gensim_corpus] for id, value in doc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def video_url(path):\n",
    "    return sp.check_output(\n",
    "        \"gsutil signurl -d 1m /app/service-key.json gs://esper/{} | awk 'FNR==2{{print $5}}'\".format(path), shell=True).strip()\n",
    "    \n",
    "\n",
    "def precise_time(doc, tokens):\n",
    "    transcript = ' '.join(\n",
    "        [t.text for t in list(doc.tokens)[tokens[0].i-50:tokens[-1].i+50]])\n",
    "    start, _ = token_time(doc, tokens[0])\n",
    "    _, end = token_time(doc, tokens[-1])\n",
    "\n",
    "    path = doc.metadata['path']\n",
    "    url = video_url(path)\n",
    "  \n",
    "    def tmpname():\n",
    "        return '/tmp/{}'.format(''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)))\n",
    "\n",
    "    def fmt_time(t):\n",
    "        return '{:02d}:{:02d}:{:02d}'.format(t.hours, t.minutes, t.seconds)\n",
    "\n",
    "    faudio = tmpname() + '.aac'\n",
    "    ftext = tmpname()\n",
    "\n",
    "    start2 = start - {'seconds': 3}\n",
    "    end2 = end + {'seconds': 3}\n",
    "    sp.check_call('ffmpeg -ss {} -i \"{}\" -t {} {}'.format(\n",
    "        fmt_time(start2), url, fmt_time(end2-start2), faudio), shell=True)\n",
    "\n",
    "    try:\n",
    "        with open(ftext, 'wb') as f:\n",
    "            s = transcript.encode('utf-8')\n",
    "            if len(s) == 0:\n",
    "                raise Exception(\"WTF\", doc.metadata['path'], token)\n",
    "            f.write(s)\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    aligned = json.loads(sp.check_output(\n",
    "        'curl -F \"audio=@{}\" -F \"transcript=@{}\" \"http://gentle:8765/transcriptions?async=false\"'.format(\n",
    "            faudio, ftext), shell=True))\n",
    "    \n",
    "    os.remove(faudio)\n",
    "    os.remove(ftext)\n",
    "    \n",
    "    word = None\n",
    "    words = aligned['words']\n",
    "    for i in range(len(words)-len(tokens)+1):\n",
    "        match = True\n",
    "        for j in range(len(tokens)):\n",
    "            if words[i+j]['word'] != tokens[j].text or words[i+j]['case'] == 'not-found-in-audio':\n",
    "                match = False\n",
    "                break\n",
    "            \n",
    "        if match:\n",
    "            start_sec = start2.hours * 3600 + start2.minutes * 60 + start2.seconds\n",
    "            return start_sec + words[i]['start'], start_sec + words[i+len(tokens)-1]['end']\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment((i, (path, start, end))):\n",
    "    url = video_url(path)\n",
    "     \n",
    "    def fmt_time(t):\n",
    "        return '{:02d}:{:02d}:{:02d}.{:03d}'.format(\n",
    "            int(t / 3600), int(t / 60 % 60), int(t % 60), int(t * 1000 % 1000))\n",
    "    \n",
    "    seg_path = '/tmp/segment{:04d}.mp4'.format(i)\n",
    "    if os.path.isfile(seg_path):\n",
    "        os.remove(seg_path)\n",
    "    sp.check_call('ffmpeg -ss {} -i \"{}\" -t {} -vf \"scale=640:360:force_original_aspect_ratio\" -r 30 {}'.format(fmt_time(start), url, fmt_time(end - start), seg_path), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# words = ['crooked hillary']\n",
    "# N=100\n",
    "# ngram=2\n",
    "# output_path='/app/supercut.mp4'\n",
    "\n",
    "def supercut(words, ngram=1, N=300, output_path='/app/supercut.mp4'):\n",
    "    log.debug('Finding tokens')\n",
    "    instances = []\n",
    "    for doc in tqdm(docs):\n",
    "        tokens = list(doc.tokens)\n",
    "        for i in range(len(tokens)-ngram+1):\n",
    "            if ' '.join([tok.lemma_ for tok in tokens[i:i+ngram]]) in words:\n",
    "                instances.append((doc, tokens[i:i+ngram]))\n",
    "\n",
    "    def get_time(inst):\n",
    "        tup = precise_time(*inst)\n",
    "        if tup is not None:\n",
    "            return (inst[0].metadata['path'], tup[0], tup[1])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    log.debug('Aliging to audio')\n",
    "    random.shuffle(instances)\n",
    "    frames = par_for(get_time, instances[:N])\n",
    "    frames2 = [f for f in frames if f is not None]\n",
    "    with open('/app/frames.json', 'wb') as f:\n",
    "        f.write(json.dumps(frames2))    \n",
    "\n",
    "    log.debug('Fetching video segments')\n",
    "    par_for(get_segment, list(enumerate(frames2)))\n",
    "\n",
    "    log.debug('Concatenating {} segments'.format(len(frames2)))\n",
    "    if os.path.isfile(output_path):\n",
    "        os.remove(output_path)\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "        f.write('\\n'.join([\"file '{}'\".format(p) for p in glob.glob('/tmp/segment*.mp4')]))\n",
    "        f.flush()\n",
    "\n",
    "        sp.check_call(\n",
    "            \"ffmpeg -f concat -safe 0 -i {} {}\".format(f.name, output_path),\n",
    "            shell=True)\n",
    "\n",
    "    sp.check_call('rm /tmp/segment*.mp4', shell=True)\n",
    "    \n",
    "supercut(['crooked hillary'], ngram=2, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/app/deps/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "def sim_score(a, b):\n",
    "    try:\n",
    "        return model.wv.similarity(a, b)\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('economy', 'jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: incorporate TFIDF segments\n",
    "\n",
    "topics = ['immigration', 'china', 'syria', 'terrorism', 'economy', 'election']\n",
    "transcript_tokens = [\n",
    "    list(textacy.extract.words(doc, filter_nums=True, include_pos=['PROPN', 'NOUN'])) \n",
    "    for doc in corpus.docs]\n",
    "  \n",
    "N = len(topics)    \n",
    "#fig, ax = plt.subplots(2, N / 2, figsize=(18, 16))\n",
    "#ax = ax.flatten()\n",
    "W = 30\n",
    "MENTION_THRESHOLD = 3\n",
    "PEAK_DURATION_THRESHOLD = 5\n",
    "\n",
    "def topic_peaks(topic, tokens):\n",
    "    scores = np.array([sim_score(token.text.lower(), topic) for token in tokens])\n",
    "    scores = scores > 0.6\n",
    "    sums = np.array([np.sum(scores[j:j+W]) for j in range(W, len(scores) - W)]) >= MENTION_THRESHOLD\n",
    "    start = None\n",
    "    peaks = []\n",
    "    for j in range(len(sums)):\n",
    "        if sums[j] and start is None:\n",
    "            start = j\n",
    "        elif not sums[j] and start is not None:\n",
    "            idx = (start + j) / 2 + W\n",
    "            peak_duration = j - start\n",
    "            if peak_duration > PEAK_DURATION_THRESHOLD:\n",
    "                peaks.append((tokens[idx], peak_duration))\n",
    "            start = None\n",
    "\n",
    "    #ax[i].set_ylim([0, 1])\n",
    "    #ax[i].set_title(topic)\n",
    "    #ax[i].plot(sums)\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "topic_labeler, _ = Labeler.objects.get_or_create(name='word2vec')\n",
    "topic_tracks = []\n",
    "for tokens, doc in zip(transcript_tokens, corpus.docs):\n",
    "    print(doc.metadata['path'])\n",
    "    video = Video.objects.get(path=doc.metadata['path'])\n",
    "    for i, topic in enumerate(topics): \n",
    "        peaks = topic_peaks(topic, tokens)\n",
    "        print(topic, peaks)\n",
    "        for (token, _) in peaks:\n",
    "            (start, end) = token_time(doc, token)\n",
    "            start = start.to_time()\n",
    "            seconds = (((start.hour * 60) + start.minute) * 60 + start.second)\n",
    "            \n",
    "            # Naively assume 4 minute segment size\n",
    "            min_time = max(seconds - 2 * 60, 0)\n",
    "            max_time = min(seconds + 2 * 60, int(video.num_frames / video.fps))\n",
    "            \n",
    "            topic_model, _ = Topic.objects.get_or_create(name=topic)\n",
    "            track = TopicTrack(\n",
    "                video=video, min_frame=min_time*video.fps, max_frame=max_time*video.fps, topic=topic_model,\n",
    "                labeler=topic_labeler)\n",
    "            topic_tracks.append(track)\n",
    "#_ = TopicTrack.objects.bulk_create(topic_tracks)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
